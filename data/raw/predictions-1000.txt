@ Override public boolean removeRegistrationByUsername ( String username , CredentialRegistration credentialRegistration ) { try { return storage . get ( username , HashSet :: new ) . remove ( credentialRegistration ) ; } catch ( ExecutionException e ) { logger . error ( "Registration lookup failed" , e ) ; throw new RuntimeException ( e ) ; } }
private Map < String , String > createCodeMap ( String url ) { try { Map < String , String > result = ImmutableMap . copyOf ( CommonUtils . createCMDIComponentItemMap ( url ) ) ; LOG . debug ( "Code map: {}" , result ) ; return result ; } catch ( Exception e ) { if ( CommonUtils . shouldSwallowLookupErrors ( ) ) { LOG . warn ( "Ignoring exception" , e ) ; return Collections . emptyMap ( ) ; } else { throw new RuntimeException ( "Cannot instantiate postProcessor. URL: " + url , e ) ; } } }
private Map < String , String > createCodeMap ( String url ) { LOG . info ( "Creating language code map from {}" , url ) ; try { Map < String , String > result = ImmutableMap . copyOf ( CommonUtils . createCMDIComponentItemMap ( url ) ) ; LOG . info ( "Code map created from {}" , result ) ; return result ; } catch ( Exception e ) { if ( CommonUtils . shouldSwallowLookupErrors ( ) ) { return Collections . emptyMap ( ) ; } else { throw new RuntimeException ( "Cannot instantiate postProcessor. URL: " + url , e ) ; } } }
public static Connection getConnection ( ) { Connection connection = null ; if ( null != PgConnection . source ) { try { connection = source . getConnection ( ) ; } catch ( SQLException e ) { logger . error ( "Something went wrong, PostgreSQL DB is not connected." ) ; logger . error ( e . getMessage ( ) ) ; } } return connection ; }
public static Connection getConnection ( ) { Connection connection = null ; if ( null != PgConnection . source ) { try { connection = source . getConnection ( ) ; } catch ( SQLException e ) { logger . warn ( "Something went wrong, PostgreSQL DB is not connected." ) ; logger . error ( e . getMessage ( ) ) ; } } return connection ; }
private Optional < Map < String , CheckedLink > > getLinkStatusForLandingPages ( final List < Resource > landingPageResources , File file ) { try { return Optional . ofNullable ( availabilityChecker . getLinkStatusForRefs ( landingPageResources . stream ( ) . map ( Resource :: getResourceName ) ) ) ; } catch ( Exception ex ) { logger . warn ( "Unable to get link status from settings!" , ex ) ; return Optional . empty ( ) ; } }
@ PreDestroy protected void closeSolrClient ( ) { try { solrClient . close ( ) ; } catch ( IOException ex ) { log . error ( "Error while closing SolrClient" , ex ) ; } }
@ PostConstruct protected void init ( ) { log . trace ( "initializing conditions map" ) ; conditionsMap . putAll ( converter . convert ( config ) ) ; }
@ PostConstruct public void init ( ) { final ExecutorService executor = Executors . newSingleThreadExecutor ( ) ; this . templatesFuture = executor . submit ( ( ) -> { log . info ( "Compiling template templates" ) ; return compileTemplates ( ) ; } ) ; }
@ Override public void addURL ( final URL url ) { logger . debug ( "Adding URL: " + url ) ; super . addURL ( url ) ; }
protected FileSystem createFileSystem ( IModFile modFile ) { try { return FileSystems . newFileSystem ( modFile . getFilePath ( ) , modFile . getClass ( ) . getClassLoader ( ) ) ; } catch ( ZipError | IOException e ) { modLog . error ( "Could not create file system for mod file: " + modFile . getFilePath ( ) , e ) ; return null ; } }
private void addCompletedFile ( final ModFile file , final ModFileScanData modFileScanData , final Throwable throwable ) { if ( throwable != null ) { LOGGER . error ( SCAN , "Scanning {} completed for {}." , file . getFilePath ( ) , modFileScanData . getModId ( ) , throwable ) ; } pendingFiles . remove ( file ) ; scannedFiles . add ( file ) ; }
public < T extends Event & IModBusEvent > void runEventGenerator ( Function < ModContainer , T > generator ) { if ( ! loadingStateValid ) { LOGGER . error ( "Cowardly refusing to send event generator to a broken mod state" ) ; return ; } ModList . get ( ) . forEachModContainer ( ( id , mc ) -> mc . acceptEvent ( generator . apply ( mc ) ) ) ; }
protected void returnExtractor ( ContentExtractor e ) { synchronized ( extractors ) { try { e = new ContentExtractor ( ) ; extractors . add ( e ) ; } catch ( AnalysisException ex ) { throw new RuntimeException ( "Cannot create extractor!" , ex ) ; } LOG . debug ( "Returned extractor: {}" , e ) ; extractors . notify ( ) ; } }
@ Test public void testExtractNLM ( ) throws Exception { System . out . println ( "extractNLM" ) ; InputStream is = this . getClass ( ) . getResourceAsStream ( "/pdf/test1.pdf" ) ; CermineExtractorServiceImpl instance = new CermineExtractorServiceImpl ( ) ; instance . init ( ) ; ExtractionResult result = instance . extractNLM ( is ) ; assertNotNull ( result ) ; assertTrue ( result . isSucceeded ( ) ) ; LOG . info ( result . toString ( ) ) ; }
@ Override public Schema outputSchema ( Schema p_input ) { try { return Schema . generateNestedSchema ( DataType . TUPLE , DataType . BYTEARRAY ) ; } catch ( FrontendException e ) { logger . error ( "Error in creating output schema:" , e ) ; throw new IllegalStateException ( e ) ; } }
public static void main ( String [ ] args ) { try { PigServer pigServer = new PigServer ( "local" ) ; runQuery ( pigServer ) ; } catch ( Exception e ) { logger . error ( "Failed to run query" , e ) ; } }
@ Override public void resourceChanged ( IResourceChangeEvent event ) { int type = event . getType ( ) ; if ( type == IResourceChangeEvent . PRE_BUILD ) { logger . debug ( "Received PRE_BUILD event." ) ; building = true ; } else if ( type == IResourceChangeEvent . POST_BUILD ) { logger . debug ( "Received POST_BUILD event." ) ; building = false ; } }
@ Override public void resourceChanged ( IResourceChangeEvent event ) { int type = event . getType ( ) ; if ( type == IResourceChangeEvent . PRE_BUILD ) { logger . debug ( "Received PRE_BUILD event." ) ; building = true ; } else if ( type == IResourceChangeEvent . POST_BUILD ) { logger . debug ( "Received POST_BUILD event." ) ; building = false ; } }
private List < Error > updateSettings ( IProject project , String settings ) throws Exception { Preferences preferences = getPreferences ( ) ; File file = new File ( settings ) ; List < Error > errors ; try { errors = preferences . setValues ( project , file ) ; } finally { try { file . delete ( ) ; } catch ( Exception e ) { log . warn ( "Could not delete preferences" , e ) ; } } return errors ; }
public static ProjectManager addProjectManager ( String nature , ProjectManager manager ) { log . debug ( "add nature of project manager: {}" , nature ) ; managers . put ( nature , manager ) ; return manager ; }
public static void addNature ( String alias , String nature ) { logger . debug ( "add nature alias: {}={}" , alias , nature ) ; natureAliases . put ( alias , new String [ ] { nature } ) ; }
public void debug ( String message , Object ... args ) { log . debug ( message , args ) ; }
private void predictPerformanceOfSystem ( ) { LinearRegression regressionModel = new LinearRegression ( ) ; try { this . predictionDataset . setClassIndex ( this . predictionDataset . numAttributes ( ) - 1 ) ; regressionModel . buildClassifier ( this . predictionDataset ) ; this . modelPrediction = regressionModel . classifyInstance ( this . predictionDataset . get ( 0 ) ) ; } catch ( Exception e ) { logger . error ( "Error regressionModel: " + e ) ; } }
@ Deprecated @ Override public void stopContainer ( String containerId ) { log . warn ( "Stopping container {}" , containerId ) ; removeContainer ( containerId ) ; }
@ Deprecated @ Override public void stopParentAndChildren ( String parentId ) { log . warn ( "Stopping child node with id [{}] for shard [{}]" , parentId , shardName ) ; removeParentAndChildren ( parentId ) ; }
@ Override public ResultSet sendSelectQuery ( String query ) { if ( query == null ) { LOGGER . debug ( "No query to send an select query." ) ; return null ; } QueryExecution qe = QueryExecutionFactory . create ( query , dataset ) ; return qe . execSelect ( ) ; }
@ Override public void notifyTermination ( String containerId , long exitCode ) { try { assertEquals ( containerId , containerTwoId ) ; assertEquals ( 0 , exitCode ) ; observer . removedObservedContainer ( containerTwoId ) ; manager . removeContainer ( containerTwoId ) ; } catch ( Throwable t ) { throwable = t ; log . error ( "exception when notifying containerTwoId: " + containerTwoId , t ) ; } termination . release ( ) ; }
private static void traceModel ( String traceLabel , JenaConnect model ) throws IOException { log . trace ( traceLabel ) ; ResultSet traceSet = model . executeSelectQuery ( "SELECT ?s ?p ?o WHERE { ?s ?p ?o .}" ) ; for ( QuerySolution soln : IterableAdaptor . adapt ( traceSet ) ) { log . trace ( soln . toString ( ) ) ; } }
private static void traceModel ( String traceLabel , JenaConnect model ) throws IOException { log . trace ( traceLabel ) ; ResultSet traceSet = model . executeSelectQuery ( "SELECT ?s ?p ?o WHERE { ?s ?p ?o .}" ) ; for ( QuerySolution soln : IterableAdaptor . adapt ( traceSet ) ) { log . trace ( soln . toString ( ) ) ; } }
protected void logMapObject ( Object obj ) { HashMap < ? , ? > mapobject = ( HashMap ) obj ; Iterator < ? > iter = mapobject . keySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Object keyobj = iter . next ( ) ; Object valobj = mapobject . get ( keyobj ) ; log . info ( keyobj + ": " + valobj ) ; } }
public String getLinkedData ( String uri ) throws Exception { log . trace ( "getLinkedData " + uri ) ; HttpGet get = new HttpGet ( uri ) ; get . setHeader ( "Accept" , RDF_ACCEPT_HEADER ) ; HttpResponse resp = http . execute ( get ) ; String ld = new String ( ) ; try { ld = responseToString ( uri , resp ) ; } catch ( Exception ex ) { throw new Exception ( "could not get LD for " + uri + " " , ex ) ; } finally { close ( resp ) ; } return ld ; }
public int removeRdfFromRH ( RecordHandler rh , String namespace , String language ) { int processCount = 0 ; for ( Record r : rh ) { if ( namespace != null ) { log . info ( "remove namespace=" + namespace + ", " + r ) ; } ByteArrayInputStream bais = new ByteArrayInputStream ( r . getData ( ) . getBytes ( ) ) ; getJenaModel ( ) . remove ( new MemJenaConnect ( bais , namespace , language ) . getJenaModel ( ) ) ; try { bais . close ( ) ; } catch ( IOException e ) { } processCount ++ ; } return processCount ; }
public final void testDiffDumpFile ( ) throws IOException { log . info ( "Start testDiffDumpFile" ) ; Diff . diff ( this . original , this . incoming , this . output , null , null , null , null ) ; log . info ( "End testDiffDumpFile" ) ; }
public final void testDiffDumpFile ( ) throws IOException { log . info ( "Begin testDiffDumpFile" ) ; Diff . diff ( this . original , this . incoming , this . output , null , null , null , null ) ; log . info ( "End testDiffDumpFile" ) ; }
public final void testNLMJournalFetchNoRecordQuery ( ) throws IOException { log . info ( "BEGIN testNLMJournalFetchNoRecordQuery" ) ; boolean boolA = true ; try { new NLMJournalFetch ( "test@test.com" , "" , "100" , "100" , this . rh ) . execute ( ) ; } catch ( IllegalArgumentException e ) { boolA = false ; } if ( boolA ) { } assertFalse ( this . rh . iterator ( ) . hasNext ( ) ) ; log . info ( "END testNLMJournalFetchNoRecordQuery" ) ; }
public final void testNLMJournalFetchNoRecordQuery ( ) throws IOException { log . info ( "BEGIN testNLMJournalFetchNoRecordQuery" ) ; boolean boolA = true ; try { new NLMJournalFetch ( "test@test.com" , "" , "100" , "100" , this . rh ) . execute ( ) ; } catch ( IllegalArgumentException e ) { boolA = false ; } if ( boolA ) { log . info ( "END testNLMJournalFetchNoRecordQuery" ) ; } assertFalse ( this . rh . iterator ( ) . hasNext ( ) ) ; }
public void testJenaConnectConstSibling ( ) throws IOException { log . info ( "BEGIN testJenaConnectConstSibling" ) ; this . jc = new SDBJenaConnect ( dbUrl , dbUser , dbPass , dbType , dbClass , dbLayout , modelName2 ) . neighborConnectClone ( modelName2 ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstSibling" ) ; }
public void testJenaConnectConstSibling ( ) throws IOException { log . info ( "BEGIN testJenaConnectConstSibling" ) ; this . jc = new SDBJenaConnect ( dbUrl , dbUser , dbPass , dbType , dbClass , dbLayout , modelName2 ) . neighborConnectClone ( modelName2 ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstSibling" ) ; }
public void testJenaConnectConstInputStream ( ) { log . info ( "BEGIN testJenaConnectConstInputStream" ) ; this . jc = new MemJenaConnect ( new ByteArrayInputStream ( rdfIn . getBytes ( ) ) , null , null ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstInputStream" ) ; }
public void testJenaConnectConstInputStream ( ) { log . info ( "BEGIN testJenaConnectConstInputStream" ) ; this . jc = new MemJenaConnect ( new ByteArrayInputStream ( rdfIn . getBytes ( ) ) , null , null ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstInputStream" ) ; }
private void runNoModRecord ( ) throws IOException { log . info ( "Start no mod test" ) ; String recID = "test1" ; String recData = "MyDataIsReally Awesome" ; assertFalse ( this . rh . addRecord ( recID , recData , this . getClass ( ) ) ) ; log . info ( "End no mod test" ) ; }
private void runNoModRecord ( ) throws IOException { log . info ( "Start no mod test" ) ; String recID = "test1" ; String recData = "MyDataIsReally Awesome" ; assertFalse ( this . rh . addRecord ( recID , recData , this . getClass ( ) ) ) ; log . info ( "End no mod test" ) ; }
@ Override public String serializeAsString ( IPropagatable entity ) { try { return serializer . writeValueAsString ( entity ) ; } catch ( JsonProcessingException e ) { log . error ( "Error at jackson byte array serializer" , e ) ; return null ; } }
private void publishRemainingMessages ( ) { LinkedList < ZeroMQMessageData > remainingMessages = new LinkedList < > ( ) ; publishMessageQueue . drainTo ( remainingMessages ) ; if ( ! remainingMessages . isEmpty ( ) ) { log . debug ( "{} pending {} messages" , remainingMessages . size ( ) , remainingMessages . size ( ) ) ; remainingMessages . forEach ( this :: publish ) ; } }
@ Override public byte [ ] getMessageInBytes ( BaseTransactionData baseTransactionData ) { if ( ! ( baseTransactionData instanceof FullNodeFeeData ) ) { throw new IllegalArgumentException ( "" ) ; } try { return getOutputMessageInBytes ( ( FullNodeFeeData ) baseTransactionData ) ; } catch ( Exception e ) { log . error ( "Unable to get output message in bytes of non- FullNodeFeeData" , e ) ; return new byte [ 0 ] ; } }
@ Override public boolean put ( String columnFamilyName , WriteOptions writeOptions , byte [ ] key , byte [ ] value ) { try { db . put ( classNameToColumnFamilyHandleMapping . get ( columnFamilyName ) , writeOptions , key , value ) ; return true ; } catch ( Exception e ) { log . error ( "Error at putting to db" , e ) ; return false ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . warn ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . error ( "Invalid address {}" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error at handlePropagatedAddress" , e ) ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . debug ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . debug ( "Address {} is invalid, continue" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error at handlePropagatedAddress" , e ) ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . debug ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . error ( "Invalid address {}" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error while handling the address" , e ) ; } }
public void init ( ) { log . debug ( "init()" ) ; postponedDspConsensusResultsMap = new ConcurrentHashMap < > ( ) ; }
public void addDataToMemory ( TransactionData transactionData ) { log . info ( "TransactionData added to memory: " + transactionData . getHash ( ) ) ; }
private void insertAddressTransactionsHistory ( Map < Hash , AddressTransactionsHistory > addressToTransactionsHistoryMap ) { log . info ( "Started to insert address transactions history" ) ; addressTransactionsHistories . putBatch ( addressToTransactionsHistoryMap ) ; log . info ( "Finished to insert address transactions history" ) ; }
private void insertAddressTransactionsHistory ( Map < Hash , AddressTransactionsHistory > addressToTransactionsHistoryMap ) { log . info ( "Starting to insert address transactions history" ) ; addressTransactionsHistories . putBatch ( addressToTransactionsHistoryMap ) ; log . info ( "Address transactions history updated" ) ; }
private Thread monitorCreatedTransactions ( AtomicLong createdTransactionNumber , AtomicLong failedTransactionNumber ) { return new Thread ( ( ) -> { while ( ! Thread . currentThread ( ) . isInterrupted ( ) ) { try { Thread . sleep ( 5000 ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; } log . info ( "Transactions: failed {}, retrying in {} ms" , createdTransactionNumber , failedTransactionNumber ) ; } } ) ; }
public static Date getDateNumberOfDaysAfterToday ( int numberOfDays ) { Date date = new Date ( ) ; SimpleDateFormat formatter = new SimpleDateFormat ( "yyyy-MM-dd" ) ; try { date = formatter . parse ( formatter . format ( date ) ) ; } catch ( ParseException e ) { SilverLogger . getLogger ( TimeZoneUtil . class ) . error ( e ) ; } DateUtils . addDays ( date , numberOfDays ) ; return date ; }
private void checkNodesList ( List < NetworkNodeData > nodesList ) { ThreadFactory threadFactory = Executors . defaultThreadFactory ( ) ; try { nodesList . forEach ( networkNodeData -> initNodeMonitorThreadIfAbsent ( threadFactory , networkNodeData ) ) ; } catch ( Exception e ) { log . error ( "An error occurred while retrieving the node monitor thread." , e ) ; } }
private void getTransactionsDataBlock ( List < Hash > transactionHashes , BlockingQueue < GetHashToPropagatable < TransactionData > > retrievedTransactionQueue ) { try { Map < Hash , String > transactionsMap = retrieveMultipleObjectsFromStorage ( transactionHashes ) ; queueTransactionsDataBlock ( transactionsMap , retrievedTransactionQueue ) ; } catch ( Exception e ) { log . error ( "getTransactionsDataBlock request failed" , e ) ; } }
public static void loadJar ( File file ) { if ( file != null ) { try { NewDriver . addURL ( file . toURI ( ) . toURL ( ) ) ; } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) , e ) ; MSException . throwException ( e . getMessage ( ) ) ; } } }
public void validate ( DatabaseConfig databaseConfig ) { try { DriverManager . getConnection ( databaseConfig . getDbUrl ( ) , databaseConfig . getUsername ( ) , databaseConfig . getPassword ( ) ) ; } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) , e ) ; MSException . throwException ( e . getMessage ( ) ) ; } }
public static void copyBdyFile ( String originId , String toId ) { try { FileUtil . copyDir ( new File ( FileUtils . BODY_FILE_DIR + "/" + originId ) , new File ( FileUtils . BODY_FILE_DIR + "/" + toId ) ) ; } catch ( Exception e ) { logger . error ( "BODY file copy error" , e ) ; } }
public synchronized static String calculate ( String input ) { try { return engine . eval ( "calculate('" + input + "')" ) . toString ( ) ; } catch ( ScriptException e ) { log . error ( "Unable to calculate resource for: {}" , input , e ) ; return input ; } }
private static void inputStreamToFile ( InputStream ins , File file ) { try ( OutputStream os = new FileOutputStream ( file ) ; ) { int bytesRead = 0 ; byte [ ] buffer = new byte [ 8192 ] ; while ( ( bytesRead = ins . read ( buffer , 0 , 8192 ) ) != - 1 ) { os . write ( buffer , 0 , bytesRead ) ; } } catch ( Exception e ) { logger . error ( "load file : {} from inputStream failed" , file . getName ( ) , e ) ; } }
public void samplePause ( ) { if ( pauseTime != 0 ) { log . error ( "samplePause called twice" , new Throwable ( INVALID_CALL_SEQUENCE_MSG ) ) ; } pauseTime = currentTimeInMillis ( ) ; }
private boolean write ( InputStream inputStream , Path path ) { try { Files . copy ( inputStream , path , StandardCopyOption . REPLACE_EXISTING ) ; return true ; } catch ( IOException ex ) { LOGGER . warn ( "Could not write file {}" , path , ex ) ; return false ; } }
private JSONObject getContent ( JSONObject params ) throws ServletException { try { JSONObject json = new JSONObject ( ) ; json . put ( "result" , FileUtils . readFileToString ( Paths . get ( REPOSITORY_BASE_PATH , ( String ) params . get ( "item" ) ) . toFile ( ) ) ) ; return json ; } catch ( IOException ex ) { LOG . error ( "Could not read item result" , ex ) ; return error ( ex . getMessage ( ) ) ; } }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; log . debug ( "JsonDocumentsConverter.convertToDatabaseColumn" + list ) ; } catch ( IOException ex ) { log . error ( "JsonDocumentsConverter.convertToEntityAttribute" ) ; log . error ( "JsonDocumentsConverter.convertToEntityAttribute" + dbData ) ; } return list ; }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { log . debug ( "Start convertToEntityAttribute" ) ; list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; } catch ( IOException ex ) { log . error ( "Exception occurred in convertToEntityAttribute" ) ; log . error ( ex . getMessage ( ) ) ; } return list ; }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { log . debug ( "Start convertToEntityAttribute" ) ; list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; log . debug ( "JsonDocumentsConverter.convertToDatabaseColumn" + list ) ; } catch ( IOException ex ) { log . error ( "JsonDocumentsConverter.convertToEntityAttribute error" , ex ) ; } return list ; }
@ Override public void warning ( String message ) { log . warn ( printConsole ( ChatColor . YELLOW + message , colored ) ) ; }
public void registerCommand ( GeyserCommand command ) { commands . put ( command . getName ( ) , command ) ; if ( command . getAliases ( ) . isEmpty ( ) ) return ; for ( String alias : command . getAliases ( ) ) commands . put ( alias , command ) ; logger . debug ( "Registered command! " + command . getName ( ) ) ; }
@ Override public void disconnected ( DisconnectedEvent event ) { loggingIn = false ; loggedIn = false ; if ( event . getCause ( ) != null ) { event . getCause ( ) . printStackTrace ( ) ; } upstream . disconnect ( MessageTranslator . convertMessageLenient ( event . getReason ( ) ) ) ; LOGGER . info ( "Connection closed..." ) ; }
@ Override public void clear ( ) { super . clear ( ) ; if ( deallocator != null ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Clearing " + this ) ; } deallocator . deallocate ( ) ; deallocator = null ; } }
@ Override public void info ( String s ) { logger . info ( decorate ( s ) ) ; }
@ Override public void warn ( String s ) { mavenLog . warn ( s ) ; }
@ Override public void debug ( String s , Object ... objects ) { logger . debug ( decorate ( s ) , objects ) ; }
private void createConnections ( ) { for ( int i = 0 ; i < poolConfig . minIdle ; i ++ ) { try { pool . addObject ( ) ; } catch ( Exception e ) { log . warn ( "Could not create connection" , e ) ; } } }
@ Override public Client createClient ( URL url ) { LOG . debug ( "Creating new client instance for URL {}" , url ) ; return createClient ( url , heartbeatClientEndpointManager ) ; }
public static void warn ( String msg ) { BASIC_LOGGER . warn ( msg ) ; }
@ Override public void destroy ( ) { endpointFactory . safeReleaseResource ( server , url ) ; LoggerUtil . info ( "MockRpcExporter destory Success: url={}" , url ) ; }
private boolean isSwitcherChange ( boolean switcherStatus ) { boolean ret = false ; if ( switcherStatus != lastHeartBeatSwitcherStatus ) { ret = true ; lastHeartBeatSwitcherStatus = switcherStatus ; logger . info ( "heartbeat switcher change to " + switcherStatus ) ; } return ret ; }
@ Override public void run ( ) { ConcurrentHashMap < URL , ServiceListener > listeners = serviceListeners . get ( service ) ; if ( listeners != null ) { synchronized ( listeners ) { for ( Map . Entry < URL , ServiceListener > entry : listeners . entrySet ( ) ) { ServiceListener serviceListener = entry . getValue ( ) ; serviceListener . notifyService ( entry . getKey ( ) , getUrl ( ) , urls ) ; } } } else { logger . debug ( "ServiceListener for service: {} not found." , service ) ; } }
@ Override public void handleDataDeleted ( String dataPath ) throws Exception { commandListener . notifyCommand ( url , null ) ; LoggerUtil . info ( String . format ( "[ZookeeperRegistry] command data deleted: path=%s" , dataPath ) ) ; }
@ Override public void destroyObject ( final Object obj ) throws Exception { if ( obj instanceof NettyChannel ) { NettyChannel client = ( NettyChannel ) obj ; URL url = nettyClient . getUrl ( ) ; LoggerUtil . info ( factoryName + " disconnecting client on url: " + url . getUri ( ) ) ; try { client . close ( ) ; } catch ( Exception e ) { LoggerUtil . error ( factoryName + " client disconnect Error: " + url . getUri ( ) , e ) ; } } }
@ Override public void destroyObject ( final Object obj ) throws Exception { if ( obj instanceof NettyChannel ) { NettyChannel client = ( NettyChannel ) obj ; URL url = nettyClient . getUrl ( ) ; try { client . close ( ) ; LoggerUtil . info ( factoryName + " client disconnect Success: " + url . getUri ( ) ) ; } catch ( Exception e ) { LoggerUtil . error ( factoryName + " client disconnect Error: " + e . getLocalizedMessage ( ) ) ; } } }
@ Override public void close ( ) { try { channel . close ( ) ; } catch ( Throwable e ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Error closing file: " + file , e ) ; } } }
private final void waitTillStabilized ( boolean failIfNotConnected ) throws AerospikeException { int count = - 1 ; for ( int i = 0 ; i < 3 ; i ++ ) { tend ( failIfNotConnected ) ; if ( count == nodes . length ) { return ; } Util . sleep ( 1 ) ; count = nodes . length ; } String message = "Cluster not stabilized after multiple tend attempts" ; if ( failIfNotConnected ) { throw new AerospikeException ( message ) ; } else { log . info ( message ) ; } }
protected final void refreshRacks ( ) { if ( failures > 0 || ! active ) { return ; } try { if ( Log . debugEnabled ( ) ) { Log . debug ( "Refreshing racks for cluster " + clusterName ) ; } RackParser parser = new RackParser ( tendConnection , this ) ; rebalanceGeneration = parser . getGeneration ( ) ; racks = parser . getRacks ( ) ; } catch ( Exception e ) { refreshFailed ( e ) ; } }
@ Override protected void sendCancel ( ) { inputQueue . clear ( ) ; resultSet . abort ( ) ; while ( ! inputQueue . offer ( LuaValue . NIL ) ) { if ( inputQueue . poll ( ) == null ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Cancelling input queue because queue is full" ) ; } break ; } } }
public static byte [ ] resizeBuffer ( int size ) { if ( size > THREAD_LOCAL_CUTOFF ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " blocked to " + size ) ; } return new byte [ size ] ; } if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " resize buffer to " + size ) ; } BufferThreadLocal . set ( new byte [ size ] ) ; return BufferThreadLocal . get ( ) ; }
public static byte [ ] resizeBuffer ( int size ) { if ( size > THREAD_LOCAL_CUTOFF ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " allocate buffer on heap " + size ) ; } return new byte [ size ] ; } if ( Log . debugEnabled ( ) ) { Log . debug ( "Using thread " + Thread . currentThread ( ) . getId ( ) + " on heap " + size ) ; } BufferThreadLocal . set ( new byte [ size ] ) ; return BufferThreadLocal . get ( ) ; }
@ Override public void onFailure ( MessageProtos . Message message ) { logger . info ( "Send hello answered successfully {}" , message . toString ( ) ) ; }
private void printUuidNodeMap ( ) { uuidNodeMap . keySet ( ) . forEach ( entry -> { log . debug ( entry . toString ( ) ) ; } ) ; }
public void tellToSource ( MessageProtos . Message request ) { LOG . debug ( "Sending message to source {}" , request . toString ( ) ) ; sender ( ) . tell ( request , getSelf ( ) ) ; }
public ResponseEntity < Object > sendAttestationResponseToRequester ( Claim claim , JsonNode request ) { String url = openSaberUrl + OpensaberApiUrlPaths . ATTEST . replace ( ENTITY_ID , claim . getEntityId ( ) ) . replace ( ENTITY , claim . getEntity ( ) ) . replace ( PROPERTY_URI , claim . getPropertyURI ( ) ) ; logger . info ( "Sending request to {}" , url ) ; return restTemplate . exchange ( url , HttpMethod . POST , new HttpEntity < > ( request ) , Object . class ) ; }
private void compileSequence ( ) { try { if ( ! subSequences . isEmpty ( ) ) { subSequences . clear ( ) ; } log . trace ( "Compiling sequence: " + sequence ) ; ByteSequenceCompiler . COMPILER . compile ( this , sequence , getAnchor ( ) ) ; } catch ( CompileException e ) { log . warn ( "Compilation error in signature for sequence: " + sequence + "n" + e . getMessage ( ) , e ) ; isInvalidByteSequence = true ; } }
private void compileSequence ( ) { try { if ( ! subSequences . isEmpty ( ) ) { log . warn ( "A sequence is defined - ByteSequence is clearing any sub-objects (probably from XML parsing) before compiling: " + sequence ) ; subSequences . clear ( ) ; } ByteSequenceCompiler . COMPILER . compile ( this , sequence , getAnchor ( ) ) ; } catch ( CompileException e ) { log . warn ( "Error compiling message: " + e . getMessage ( ) , e ) ; isInvalidByteSequence = true ; } }
private void logUnknownProperty ( String propertyName , Object target ) { logger . warn ( "The unknown property [" + propertyName + "] is ignored for [" + target + "]" ) ; }
@ Override public ProfileInstance openProfile ( String profileId ) { if ( ! profileContextLocator . hasProfileContext ( profileId ) ) { throw new IllegalArgumentException ( String . format ( "No such profile id [%s]" , profileId ) ) ; } ProfileInstance profile = profileContextLocator . getProfileInstance ( profileId ) ; profileContextLocator . openProfileInstanceManager ( profile ) ; profile . fireListeners ( ) ; log . info ( "Opening profile [" + profileId + "]" ) ; return profile ; }
@ Override public Future < ? > start ( String profileId ) throws IOException { log . info ( "Starting an profile {}" , profileId ) ; ProfileInstanceManager profileInstanceManager = getProfileInstanceManager ( profileId ) ; return profileInstanceManager . start ( ) ; }
@ Override public void close ( ) { super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; log . debug ( "Closing {}" , url ) ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( e . getMessage ( ) ) ; } else { log . error ( e . getMessage ( ) , e ) ; } } }
@ Override public void close ( ) { log . debug ( String . format ( "Closing database [%s]" , config . getJdbcUrl ( ) ) ) ; super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( "Database [{}] was closed" , url ) ; } else { log . error ( e . getMessage ( ) , e ) ; } } }
@ Override public void close ( ) { log . debug ( String . format ( "Closing database [%s]" , config . getJdbcUrl ( ) ) ) ; super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( e . getMessage ( ) ) ; } else { log . warn ( "Could not close database [{}]" , url ) ; } } }
private void closeRequest ( ) { requests . remove ( request ) ; try { request . close ( ) ; } catch ( IOException e ) { LOG . error ( "Error closing connection {}" , connectionName , e ) ; } }
@ Override public void handleExport ( final ExportReportAction action ) { final Path target = action . exportFileChooser . getSelectedFile ( ) . toPath ( ) ; logReportExport ( target . toAbsolutePath ( ) . toString ( ) ) ; try { Files . copy ( action . droidReportXml , target ) ; } catch ( IOException e ) { log . error ( "" , e ) ; throw new RuntimeException ( e ) ; } }
@ Override public void windowClosed ( final WindowEvent e ) { if ( reportFile != null ) { if ( Files . exists ( reportFile ) ) { try { Files . deleteIfExists ( reportFile ) ; } catch ( final IOException ex ) { String message = String . format ( "Could not delete report file: %s. " + "Will try to delete on exit." , reportFile . toAbsolutePath ( ) . toString ( ) ) ; log . warn ( message , ex ) ; reportFile . toFile ( ) . deleteOnExit ( ) ; } } } }
@ DELETE @ Path ( "setting/{settingId}" ) public Response removeSetting ( @ PathParam ( "settingId" ) String settingId ) throws IOException { LOGGER . info ( "Remove interpreterSetting {}" , settingId ) ; interpreterSettingManager . remove ( settingId ) ; zeppelinResource . persistToDB ( this . project ) ; return new JsonResponse ( Status . OK ) . build ( ) ; }
private void checkIfUserIsAnon ( String errorMsg ) { boolean isAuthenticated = SecurityUtils . isAuthenticated ( ) ; if ( isAuthenticated && SecurityUtils . getPrincipal ( ) . equals ( "anonymous" ) ) { LOGGER . info ( "Anonymous user cannot set any permissions for this note." ) ; throw new ForbiddenException ( errorMsg ) ; } }
@ Override public void visit ( Hayes hayes ) { LOGGER . info ( "Should have to visit Hayes" ) ; }
private static void log ( String msg ) { TestUtils . getLogger ( ) . debug ( "TestServer: " + msg ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "The knight receives an enchanted sword." ) ; var enchantedSword = new Sword ( new SoulEatingEnchantment ( ) ) ; enchantedSword . wield ( ) ; enchantedSword . swing ( ) ; enchantedSword . unwield ( ) ; LOGGER . info ( "The valkyrie receives an enchanted hammer." ) ; var hammer = new Hammer ( new FlyingEnchantment ( ) ) ; hammer . wield ( ) ; hammer . swing ( ) ; hammer . unwield ( ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "The knight receives an enchanted sword." ) ; var enchantedSword = new Sword ( new SoulEatingEnchantment ( ) ) ; enchantedSword . wield ( ) ; enchantedSword . swing ( ) ; enchantedSword . unwield ( ) ; var hammer = new Hammer ( new FlyingEnchantment ( ) ) ; hammer . wield ( ) ; hammer . swing ( ) ; hammer . unwield ( ) ; LOGGER . info ( "The valkyrie receives an enchanted hammer." ) ; }
@ Override public void swing ( ) { LOGGER . info ( "The hammer is swinged." ) ; enchantment . apply ( ) ; }
public void playSound ( ) { numberOfPlayedSounds ++ ; LOGGER . info ( "Number of playSounds: " + numberOfPlayedSounds ) ; }
private void handleEvent ( StartingData data ) { started = data . getWhen ( ) ; LOGGER . info ( String . format ( "Receiver #%d sees application started at %s" , id , started ) ) ; }
@ Override public void attack ( ) { logger . info ( "The troll swings at you with a club!" ) ; }
@ Override public void run ( ) { var countries = world . fetch ( ) ; LOGGER . info ( "Our world currently has the following countries:-" ) ; countries . stream ( ) . map ( country -> "t" + country ) . forEach ( LOGGER :: info ) ; }
@ Override public void status ( ) { if ( ! isComplete ) { LOGGER . warn ( "[{}] is not completed. {}" , eventId , eventId ) ; } else { LOGGER . info ( "[{}] is done." , eventId ) ; } }
@ Override public void status ( ) { if ( ! isComplete ) { LOGGER . info ( "[{}] is not done." , eventId ) ; } else { LOGGER . debug ( "[{}] done." , eventId ) ; } }
@ Override public void sergeantReady ( ) { logger . info ( "[Sergeant] " + unit . getName ( ) + " is ready! " ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "Test for MQL against a real path" ) ; var car1 = CarsFactory . getCar ( CarType . FORD ) ; var car2 = CarsFactory . getCar ( CarType . FERRARI ) ; LOGGER . info ( car2 . getDescription ( ) ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "Test for Init" ) ; var car1 = CarsFactory . getCar ( CarType . FORD ) ; var car2 = CarsFactory . getCar ( CarType . FERRARI ) ; LOGGER . info ( car1 . getDescription ( ) ) ; }
@ Override public void drink ( ) { LOGGER . info ( "Urgh! This is poisonous. (Potion={})" , System . identityHashCode ( this ) ) ; }
@ Override public void display ( ) { LOGGER . error ( "Error 500" ) ; }
private static long ap ( long i ) { try { Thread . sleep ( i ) ; } catch ( InterruptedException e ) { LOG . error ( e . getMessage ( ) , e ) ; } return i * ( i + 1 ) / 2 ; }
@ Override public void resetLottery ( ) { LOGGER . info ( "Resetttery" ) ; administration . resetLottery ( ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Administration Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Show all submitted tickets" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(3) Reset lottery ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(possiblepossible tickets" ) ; LOGGER . info ( "(possible Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Perform lottery draw" ) ; LOGGER . info ( "(3) Reset lottery ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Perform lottery draw" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Perform lottery draw" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; }
public static void main ( String [ ] args ) { var mw = new ArrayTransposeMasterWorker ( ) ; var rows = 10 ; var columns = 20 ; var inputMatrix = ArrayUtilityMethods . createRandomIntMatrix ( rows , columns ) ; var input = new ArrayInput ( inputMatrix ) ; var result = ( ArrayResult ) mw . getResult ( input ) ; if ( result != null ) { ArrayUtilityMethods . printMatrix ( inputMatrix ) ; ArrayUtilityMethods . printMatrix ( result . data ) ; } else { LOGGER . error ( "Error in array processing" ) ; } }
@ Override public void partyAction ( Action action ) { LOGGER . info ( "{} {}" , action , action . getDescription ( ) ) ; }
private static String readFirstLine ( final String file ) { String firstLine = null ; try ( var bufferedReader = new BufferedReader ( new FileReader ( file ) ) ) { while ( bufferedReader . ready ( ) ) { firstLine = bufferedReader . readLine ( ) ; } LOGGER . debug ( firstLine ) ; } catch ( final IOException e ) { LOGGER . error ( "ModuleTest::readFirstLine()" , e ) ; } return firstLine ; }
private static String readFirstLine ( final String file ) { String firstLine = null ; try ( var bufferedReader = new BufferedReader ( new FileReader ( file ) ) ) { while ( bufferedReader . ready ( ) ) { firstLine = bufferedReader . readLine ( ) ; } LOGGER . info ( "ModuleTest::readFirstLine() : firstLine : " + firstLine ) ; } catch ( final IOException e ) { LOGGER . error ( "" , e ) ; } return firstLine ; }
@ Override public WebRequest newWebRequest ( HttpServletRequest servletRequest , String filterPath ) { if ( ! DEMO_MODE_USING_CREDENTIALS_AS_QUERYARGS ) { return super . newWebRequest ( servletRequest , filterPath ) ; } try { var uname = servletRequest . getParameter ( "user" ) ; if ( uname != null ) { servletRequest . getSession ( ) . invalidate ( ) ; } } catch ( Exception e ) { LOGGER . error ( e ) ; } return super . newWebRequest ( servletRequest , filterPath ) ; }
public AlbumPage selectAlbum ( String albumTitle ) { var albumLinks = ( List < HtmlAnchor > ) page . getByXPath ( "//tr[@class='album']//a" ) ; for ( var anchor : albumLinks ) { if ( anchor . getTextContent ( ) . equals ( albumTitle ) ) { try { anchor . click ( ) ; return new AlbumPage ( webClient ) ; } catch ( IOException e ) { LOGGER . error ( "An error occured on select album" , e ) ; } } } throw new IllegalArgumentException ( "No links with the album title: " + albumTitle ) ; }
@ Test void shouldExecuteApplicationWithoutException ( ) { logger . info ( "Running application with an exception" , new RuntimeException ( "Test" ) ) ; App . main ( new String [ ] { } ) ; }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body . getMsg ( ) , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void print ( ) { for ( var i = 0 ; i <= size / 2 ; i ++ ) { logger . info ( "this is a test" ) ; } }
public Message retrieveMsg ( ) { try { return blkQueue . poll ( ) ; } catch ( Exception e ) { LOGGER . error ( "Caught exception" , e ) ; } return null ; }
@ Override public void run ( ) { writeLock . lock ( ) ; try { write ( ) ; } catch ( InterruptedException e ) { LOGGER . info ( "Write interrupted" ) ; Thread . currentThread ( ) . interrupt ( ) ; } finally { writeLock . unlock ( ) ; } }
public Service getService ( String serviceName ) { if ( serviceCache . containsKey ( serviceName ) ) { var cachedService = serviceCache . get ( serviceName ) ; var name = cachedService . getName ( ) ; var id = cachedService . getId ( ) ; logger . info ( "getService({}) -> {}" , name , id ) ; return cachedService ; } return null ; }
public boolean ifNonZero ( int ... nums ) { LOGGER . info ( "Source module {}" , VERSION ) ; return Arrays . stream ( nums ) . allMatch ( num -> num != 0 ) ; }
public int accumulateSum ( int ... nums ) { LOGGER . info ( "Source module {}" , VERSION ) ; var sum = 0 ; for ( final var num : nums ) { sum += num ; } return sum ; }
protected void spawnParticles ( String particleType , int count ) { LOGGER . debug ( "Spawning particles" ) ; }
@ Override protected void confuseTarget ( String target ) { LOGGER . info ( "Approach the {} with tears running and hug him!" , target ) ; }
public void steal ( ) { var target = pickTarget ( ) ; LOGGER . info ( "The target has been chosen as {}." , target . asString ( ) ) ; confuseTarget ( target ) ; stealTheItem ( target ) ; }
private static int printAndCountExceptions ( Result res ) { var counter = 0 ; for ( var ex : res . getExceptionList ( ) ) { logger . error ( ex . getMessage ( ) , ex ) ; counter ++ ; } return counter ; }
public static void main ( String [ ] args ) { try { var world = new World ( ) ; var skeleton1 = new Skeleton ( 1 , 10 ) ; var skeleton2 = new Skeleton ( 2 , 70 ) ; var statue = new grades ( 3 , 20 ) ; world . addEntity ( skeleton1 ) ; world . addEntity ( skeleton2 ) ; world . addEntity ( statue ) ; world . run ( ) ; Thread . sleep ( GAME_RUNNING_TIME ) ; world . stop ( ) ; } catch ( InterruptedException e ) { logger . error ( "Interrupted while waiting for a response" , e ) ; } }
@ Override public void visitSoldier ( Soldier soldier ) { LOGGER . info ( "[Soldier] " + soldier . toString ( ) ) ; }
public void blockInbound ( Collection < Address > destinations ) { for ( Address destination : destinations ) { inboundSettings . put ( destination , new InboundSettings ( false ) ) ; } LOGGER . debug ( "[{}] Blocked inbound from {}" , address , destinations ) ; }
public void unblockInbound ( Collection < Address > destinations ) { destinations . forEach ( inboundSettings :: remove ) ; LOGGER . debug ( "[{}] Unblocked inbound from {}" , address , destinations ) ; }
private Mono < Void > doShutdown ( ) { return Mono . defer ( ( ) -> { LOGGER . info ( "[{}][doShutdown] Shutting down" , localMember ) ; return Flux . concatDelayError ( leaveCluster ( ) , dispose ( ) , transport . stop ( ) ) . then ( ) . doFinally ( s -> scheduler . dispose ( ) ) . doOnSuccess ( avoid -> LOGGER . info ( "[{}][doShutdown] Shutdown" , localMember ) ) ; } ) ; }
private ByteBuffer encodeMetadata ( ) { ByteBuffer result = null ; try { result = config . metadataCodec ( ) . serialize ( localMetadata ) ; } catch ( Exception e ) { logger . error ( "Failed to encode metadata" , e ) ; } return Optional . ofNullable ( result ) . orElse ( EMPTY_BUFFER ) ; }
public void onMessage ( ByteBuf byteBuf ) { try { if ( byteBuf == Unpooled . EMPTY_BUFFER ) { return ; } if ( ! byteBuf . isReadable ( ) ) { ReferenceCountUtil . safeRelease ( byteBuf ) ; return ; } final Message message = messageDecoder . apply ( byteBuf ) ; sink . emitNext ( message , RETRY_NOT_SERIALIZED ) ; } catch ( Exception e ) { logger . error ( "[onMessage]" + byteBuf , e ) ; } }
CompletableFuture < List < KeyValueConfigEntity > > loadConfig ( KeyValueConfigName configName ) { return CompletableFuture . supplyAsync ( ( ) -> { List < KeyValueConfigEntity > result ; try { result = repository . findAll ( configName ) ; } catch ( Exception e ) { log . error ( "Failed to load config for key: " + configName , e ) ; result = Collections . emptyList ( ) ; } return result ; } , executor ) ; }
public static boolean safestRelease ( Object msg ) { try { return ( msg instanceof ReferenceCounted ) && ( ( ReferenceCounted ) msg ) . refCnt ( ) > 0 && ( ( ReferenceCounted ) msg ) . release ( ) ; } catch ( Throwable t ) { logger . warn ( "purge warns: failed" , t ) ; return false ; } }
@ BeforeEach public final void baseSetUp ( TestInfo testInfo ) { LOGGER . info ( "***** Test started : " + testInfo . getDisplayName ( ) + " *****" ) ; }
@ Override public void trace ( String msg ) { commonLogger . trace ( msg ) ; auditLogger . trace ( msg ) ; }
@ Override public void trace ( String msg ) { commonLogger . trace ( msg ) ; auditLogger . trace ( msg ) ; }
@ Override public void trace ( Marker marker , String msg ) { commonLogger . trace ( marker , msg ) ; auditLogger . trace ( marker , msg ) ; }
@ Override public void trace ( Marker marker , String msg ) { commonLogger . trace ( marker , msg ) ; auditLogger . trace ( marker , msg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg ) { commonLogger . trace ( marker , format , arg ) ; auditLogger . trace ( marker , format , arg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg ) { commonLogger . trace ( marker , format , arg ) ; auditLogger . trace ( marker , format , arg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg1 , Object arg2 ) { commonLogger . trace ( marker , format , arg1 , arg2 ) ; auditLogger . trace ( marker , format , arg1 , arg2 ) ; }
@ Override public void trace ( Marker marker , String format , Object arg1 , Object arg2 ) { commonLogger . trace ( marker , format , arg1 , arg2 ) ; auditLogger . trace ( marker , format , arg1 , arg2 ) ; }
@ Override public void debug ( Marker marker , String msg ) { commonLogger . debug ( marker , msg ) ; auditLogger . debug ( marker , msg ) ; }
@ Override public void debug ( Marker marker , String msg ) { commonLogger . debug ( marker , msg ) ; auditLogger . debug ( marker , msg ) ; }
@ Override public void debug ( Marker marker , String msg , Throwable t ) { commonLogger . debug ( marker , msg , t ) ; auditLogger . debug ( marker , msg , t ) ; }
@ Override public void debug ( Marker marker , String msg , Throwable t ) { commonLogger . debug ( marker , msg , t ) ; auditLogger . debug ( marker , msg , t ) ; }
@ Override public void error ( String format , Object ... arguments ) { commonLogger . error ( format , arguments ) ; auditLogger . error ( format , arguments ) ; }
@ Override public void error ( String format , Object ... arguments ) { commonLogger . error ( format , arguments ) ; auditLogger . error ( format , arguments ) ; }
private Optional < ConfigurationModel > getSettingsConfiguration ( ) { try { return settingsUtility . getConfiguration ( ) ; } catch ( AlertException ex ) { logger . debug ( "Error getting configuration" , ex ) ; } return Optional . empty ( ) ; }
private OffsetDateTime parseAuditDateString ( String dateString ) { OffsetDateTime date = null ; try { date = DateUtils . parseDate ( dateString , DateUtils . AUDIT_DATE_FORMAT ) ; } catch ( ParseException e ) { logger . error ( "Error parsing audit date: " + dateString , e ) ; } return date ; }
protected void handleJobDetailsMissing ( DistributionEvent event ) { String failureMessage = "Received a distribution event for a Job that no longer exists" ; logger . debug ( failureMessage ) ; auditAccessor . setAuditEntryFailure ( event . getJobId ( ) , event . getNotificationIds ( ) , failureMessage , null ) ; }
public void startTask ( ) { checkTaskEnabled ( ) ; String taskName = getTaskName ( ) ; if ( ! getEnabled ( ) ) { logger . info ( "Task scheduler is not enabled: {}" , taskName ) ; return ; } taskManager . registerTask ( this ) ; taskManager . scheduleCronTask ( scheduleCronExpression ( ) , taskName ) ; String nextRun = taskManager . getNextRunTime ( taskName ) . orElse ( "" ) ; logger . info ( "{} next run: {}" , taskName , nextRun ) ; postTaskStartup ( ) ; }
public void startTask ( ) { checkTaskEnabled ( ) ; String taskName = getTaskName ( ) ; if ( ! getEnabled ( ) ) { logger . info ( "{} is disabled and will not be scheduled to run." , taskName ) ; return ; } taskManager . registerTask ( this ) ; taskManager . scheduleCronTask ( scheduleCronExpression ( ) , taskName ) ; String nextRun = taskManager . getNextRunTime ( taskName ) . orElse ( "" ) ; logger . info ( "Starting task {}." , nextRun ) ; postTaskStartup ( ) ; }
private Optional < String > retrieveProviderConfigEmailAddress ( Long providerConfigId ) { try { ProviderUserModel providerConfigUser = providerDataAccessor . getProviderConfigUserById ( providerConfigId ) ; return Optional . of ( providerConfigUser . getEmailAddress ( ) ) ; } catch ( AlertConfigurationException e ) { logger . error ( "Error retrieving email address for provider {}" , providerConfigId , e ) ; return Optional . empty ( ) ; } }
private String getEntityString ( String entityKey ) { try { ConfigurationModel currentConfiguration = samlContext . getCurrentConfiguration ( ) ; return samlContext . getFieldValueOrEmpty ( currentConfiguration , entityKey ) ; } catch ( AlertException e ) { logger . error ( "Could not get the saml context" , e ) ; } return "" ; }
private void logField ( ConfigurationFieldModel fieldModel ) { String value = fieldModel . isSensitive ( ) ? "**********" : String . valueOf ( fieldModel . getFieldValues ( ) ) ; log . debug ( value ) ; }
private boolean isEnvironmentVariableActivated ( String environmentVariable ) { boolean activated = environmentVariableUtility . getEnvironmentValue ( environmentVariable ) . map ( Boolean :: valueOf ) . orElse ( false ) ; logger . info ( "Environment variable {} is {}" , environmentVariable , activated ) ; return activated ; }
@ Override public List < String > process ( final List < String > input ) { final List < String > results = new ArrayList < > ( ) ; for ( final String inputItem : input ) { final String [ ] splitLines = inputItem . split ( regex ) ; results . addAll ( Arrays . asList ( splitLines ) ) ; } LOG . info ( "Matching " + inputItem + " to " + results ) ; return results ; }
@ Override protected DetectorEvaluationTree performEvaluation ( DetectorEvaluationTree rootEvaluation ) { logger . debug ( "Starting detector project discovery." ) ; extractionEvaluation ( rootEvaluation ) ; return rootEvaluation ; }
private void deleteDirectoryIfEmpty ( @ NotNull File directory ) throws IOException { File [ ] files = directory . listFiles ( ) ; boolean noFiles = files == null || files . length == 0 ; if ( noFiles && directory . exists ( ) ) { getLogger ( ) . info ( "Deleting directory {}" , directory ) ; FileUtils . forceDelete ( directory ) ; } }
@ Override public void printDescription ( final Logger logger ) { logger . debug ( String . format ( "Exactly one unique detector was found. Using %s found at depth %d as project info." , detectorProjectInfo . getDetectorType ( ) . name ( ) , detectorProjectInfo . getDepth ( ) ) ) ; }
private void safelyPhoneHome ( final Map < String , String > metadata , final String ... artifactModules ) { endPhoneHome ( ) ; try { currentPhoneHomeResponse = phoneHome ( metadata , artifactModules ) ; } catch ( final IllegalStateException e ) { logger . trace ( String . format ( "Failed to get phone home" ) , e ) ; } }
@ Override public void writeLine ( final String line , final Exception e ) { logger . trace ( line , e ) ; }
@ Override public void writeLine ( final String line , final Exception e ) { logger . trace ( line , e ) ; }
@ Override public String getAlbumTitle ( URL url ) throws MalformedURLException { try { Element el = getFirstPage ( ) . select ( ".headtext" ) . first ( ) ; if ( el == null ) { throw new IOException ( "Unable to get album title" ) ; } String title = el . text ( ) ; return getHost ( ) + "_" + getGID ( url ) + "_" + title . trim ( ) ; } catch ( IOException e ) { LOGGER . warn ( "Unable to get album title from " + url , e ) ; } return super . getAlbumTitle ( url ) ; }
public List < String > getTags ( Document doc ) { List < String > tags = new ArrayList < > ( ) ; LOGGER . info ( "Tags" ) ; for ( Element tag : doc . select ( "td > div > a" ) ) { LOGGER . info ( "Found tag " + tag . text ( ) ) ; tags . add ( tag . text ( ) ) ; } return tags ; }
public List < String > getTags ( Document doc ) { List < String > tags = new ArrayList < > ( ) ; LOGGER . info ( "Getting tags" ) ; for ( Element tag : doc . select ( "td > div > a" ) ) { LOGGER . info ( "Found tag: " + tag . text ( ) ) ; tags . add ( tag . text ( ) ) ; } return tags ; }
@ Override protected void downloadURL ( URL url , int index ) { if ( Utils . getConfigBoolean ( "instagram.download_images_only" , false ) && url . toString ( ) . contains ( ".mp4?" ) ) { return ; } LOG . debug ( "URL ({}) is set to download {}" , url , index ) ; addURLToDownload ( url , itemPrefixes . get ( index - 1 ) , "" , null , cookies ) ; }
public void getImage ( ) { try { Document doc = Http . url ( url ) . get ( ) ; String imageUrl = doc . getElementsByClass ( "pure-img" ) . attr ( "src" ) ; if ( imageUrl != "" ) { addURLToDownload ( new URL ( imageUrl ) , getPrefix ( index ) , "" , null , null , getImageName ( ) ) ; } else { LOGGER . error ( "[!] Given image is empty." ) ; } } catch ( IOException e ) { LOGGER . error ( "[!] Exception while downloading image: " + url , e ) ; } }
public void getImage ( ) { try { Document doc = Http . url ( url ) . get ( ) ; String imageUrl = doc . getElementsByClass ( "pure-img" ) . attr ( "src" ) ; if ( imageUrl != "" ) { addURLToDownload ( new URL ( imageUrl ) , getPrefix ( index ) , "" , null , null , getImageName ( ) ) ; } else { LOGGER . error ( "Couldnt find image from url: " + url ) ; } } catch ( IOException e ) { LOGGER . error ( "Unable to get image from url: " + url , e ) ; } }
public String getImageName ( ) { String name = this . url . toExternalForm ( ) ; try { name = name . substring ( name . lastIndexOf ( "/" ) + 1 ) ; } catch ( Exception e ) { log . warn ( "error in image name" , e ) ; name = null ; } return name + ".jpg" ; }
@ Override public List < String > getURLsFromPage ( Document doc ) { List < String > result = new ArrayList < > ( ) ; for ( Element e : doc . select ( "img.img" ) ) { String imageName = e . parent ( ) . attr ( "href" ) ; logger . debug ( "Found image: " + imageName ) ; result . add ( getFullSizedImageFromURL ( imageName . split ( "/" ) [ 2 ] ) ) ; } return result ; }
private String getImageLinkFromDLLink ( String url ) { try { Connection . Response response = Jsoup . connect ( url ) . userAgent ( USER_AGENT ) . timeout ( 10000 ) . cookies ( cookies ) . followRedirects ( false ) . execute ( ) ; String imageURL = response . header ( "Location" ) ; LOGGER . info ( "Downloaded image: " + imageURL ) ; return imageURL ; } catch ( IOException e ) { LOGGER . info ( "Got error message " + e . getMessage ( ) + " trying to download " + url ) ; return null ; } }
private String getImageLinkFromDLLink ( String url ) { try { Connection . Response response = Jsoup . connect ( url ) . userAgent ( USER_AGENT ) . timeout ( 10000 ) . cookies ( cookies ) . followRedirects ( false ) . execute ( ) ; String imageURL = response . header ( "Location" ) ; LOGGER . info ( imageURL ) ; return imageURL ; } catch ( IOException e ) { LOGGER . error ( "cannot get image link" , e ) ; return null ; } }
public void displayAndLogError ( String line , Color color ) { log . error ( line ) ; appendLog ( line , color ) ; }
public static void saveConfig ( ) { try { config . save ( getConfigFilePath ( ) ) ; LOGGER . info ( "Saved configuration to file {}" , getConfigFilePath ( ) ) ; } catch ( ConfigurationException e ) { LOGGER . error ( "Error while saving configuration: " , e ) ; } }
public static void saveConfig ( ) { try { config . save ( getConfigFilePath ( ) ) ; LOGGER . info ( "Saved configuration to " + getConfigFilePath ( ) ) ; } catch ( ConfigurationException e ) { LOGGER . error ( "Error while saving configuration: " , e ) ; } }
public static String removeCWD ( File saveAs ) { String prettySaveAs = saveAs . toString ( ) ; try { prettySaveAs = saveAs . getCanonicalPath ( ) ; String cwd = new File ( "." ) . getCanonicalPath ( ) + File . separator ; prettySaveAs = prettySaveAs . replace ( cwd , "." + File . separator ) ; } catch ( Exception e ) { logger . error ( "Exception: " , e ) ; } return prettySaveAs ; }
public double getMajorIsotopeMass ( int elem ) { if ( this . majorIsotope [ elem ] != null ) return this . majorIsotope [ elem ] . getExactMass ( ) ; IIsotope major = getMajorIsotope ( elem ) ; if ( major == null ) { log . error ( "Major isotope not found in the major: " + elem ) ; return 2 * elem ; } return major . getExactMass ( ) ; }
@ Override public Integer getCharge ( ) { Integer charge = super . getCharge ( ) ; logger . debug ( "Setting charge: " , charge ) ; return charge ; }
@ Override public Iterable < IIsotope > isotopes ( ) { logger . debug ( "Getting isotopes iterator" ) ; return super . isotopes ( ) ; }
@ Override public void removeMolecularFormula ( int position ) { logger . debug ( "Removing this formula at: " , position ) ; super . removeMolecularFormula ( position ) ; }
@ Override public IAtom getAtom ( int idx ) { logger . debug ( "Getting atom at index: " , idx ) ; return super . getAtom ( idx ) ; }
@ Override public ILonePair getLonePair ( int idx ) { logger . debug ( "Getting lone pair at: " , idx ) ; return super . getLonePair ( idx ) ; }
@ Override public IAtom getLastAtom ( ) { logger . debug ( "Getting last atom: " , super . getLastAtom ( ) ) ; return super . getLastAtom ( ) ; }
@ Override public List < ISingleElectron > getConnectedSingleElectronsList ( IAtom atom ) { logger . debug ( "Getting connected single electrons vector for atom: " , atom ) ; return super . getConnectedSingleElectronsList ( atom ) ; }
@ Override public double getBondOrderSum ( IAtom atom ) { logger . debug ( "Getting bond order sum for atom: " , atom ) ; return super . getBondOrderSum ( atom ) ; }
@ Override public void removeAtomOnly ( int position ) { logger . debug ( "Removing atom only at pos: " , position ) ; super . removeAtomOnly ( position ) ; }
@ Override public ISingleElectron removeSingleElectron ( int pos ) { logger . debug ( "Removing bond=" + pos ) ; return super . removeSingleElectron ( pos ) ; }
@ Override public Iterable < IBond > bonds ( ) { logger . warn ( "NOT SUPPORTED: bonds()" ) ; throw new UnsupportedOperationException ( ) ; }
@ Override public Point3d getPoint3d ( ) { Point3d point3d = super . getPoint3d ( ) ; if ( point3d == null ) { logger . debug ( "Getting point3d: null" ) ; } else { logger . debug ( "Getting point3d: x=" + point3d . x + ", y=" + point3d . y , ", z=" + point3d . z ) ; } return point3d ; }
@ Override public Point3d getPoint3d ( ) { Point3d point3d = super . getPoint3d ( ) ; if ( point3d == null ) { logger . debug ( "Getting point3d: null" ) ; } else { logger . debug ( "Getting point3d: x=" + point3d . x + ", y=" + point3d . y , ", z=" + point3d . z ) ; } return point3d ; }
@ Override public Integer getValency ( ) { logger . debug ( "Getting valency: " , super . getValency ( ) ) ; return super . getValency ( ) ; }
@ Override public void setExactMass ( Double exactMass ) { logger . debug ( "Setting exact mass: " , exactMass ) ; super . setExactMass ( exactMass ) ; }
@ Override public void setSymbol ( String symbol ) { logger . debug ( "Setting symbol: " , symbol ) ; super . setSymbol ( symbol ) ; }
@ Override public List < IAtom > getConnectedAtomsList ( IAtom atom ) { logger . debug ( "Getting connecting atoms vector for atom: " , atom ) ; return super . getConnectedAtomsList ( atom ) ; }
@ Override public Collection < String > getMonomerNames ( ) { logger . debug ( "Getting monomer names: " , super . getMonomerNames ( ) ) ; return super . getMonomerNames ( ) ; }
@ Override public IStrand getStrand ( String cName ) { logger . debug ( "Getting strand by name: " , cName ) ; return super . getStrand ( cName ) ; }
@ Override public IBond clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IBond ) clone ; }
@ Override public IBond clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IBond ) clone ; }
@ Override public IAtom getOther ( IAtom atom ) { logger . debug ( "Getting atom: " , atom ) ; return super . getOther ( atom ) ; }
@ Override public void setAtom ( IAtom atom , int position ) { logger . debug ( "Setting atom: pos=" + atom + " and position=" + position ) ; super . setAtom ( atom , position ) ; }
@ Override public IChemModel getChemModel ( int number ) { logger . debug ( "Getting chemModel at: " , number ) ; return super . getChemModel ( number ) ; }
@ Override public ICrystal clone ( ) throws CloneNotSupportedException { ICrystal clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return clone ; }
@ Override public ICrystal clone ( ) throws CloneNotSupportedException { ICrystal clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return clone ; }
@ Override public Vector3d getA ( ) { logger . debug ( "Getting A axis: " , super . getA ( ) ) ; return super . getA ( ) ; }
@ Override public void setB ( Vector3d newAxis ) { logger . debug ( "Setting B axis to: " , newAxis ) ; super . setB ( newAxis ) ; }
@ Override public void setZ ( Integer value ) { logger . debug ( "Setting Z: " , value ) ; super . setZ ( value ) ; }
@ Override public void setExpanded ( boolean bool ) { logger . debug ( "Setting additional nodes for building fallback." ) ; super . setExpanded ( bool ) ; }
@ Override public String getLabel ( ) { logger . debug ( "Getting label: " , super . getLabel ( ) ) ; return super . getLabel ( ) ; }
@ Override public IPseudoAtom clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IPseudoAtom ) clone ; }
@ Override public IPseudoAtom clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IPseudoAtom ) clone ; }
@ Override public IAtomContainerSet getReactants ( ) { logger . debug ( "Getting reactants: " , super . getReactants ( ) ) ; return super . getReactants ( ) ; }
@ Override public void addReactant ( IAtomContainer reactant ) { logger . debug ( "Adding reactant: " , reactant ) ; super . addReactant ( reactant ) ; }
@ Override public void addProduct ( IAtomContainer product ) { logger . debug ( "Adding product: " , product ) ; super . addProduct ( product ) ; }
@ Override public Map < String , IMonomer > getMonomers ( ) { logger . debug ( "Selected string: " + super . getMonomers ( ) ) ; return super . getMonomers ( ) ; }
public static void translateAllPositive ( IAtomContainer atomCon ) { double minX = Double . MAX_VALUE ; double minY = Double . MAX_VALUE ; for ( IAtom atom : atomCon . atoms ( ) ) { if ( atom . getPoint2d ( ) != null ) { if ( atom . getPoint2d ( ) . x < minX ) { minX = atom . getPoint2d ( ) . x ; } if ( atom . getPoint2d ( ) . y < minY ) { minY = atom . getPoint2d ( ) . y ; } } } log . debug ( "translateAllPositive atoms: " + atomCon ) ; translate2D ( atomCon , minX * - 1 , minY * - 1 ) ; }
public boolean allSaturated ( IAtomContainer ac ) throws CDKException { logger . debug ( "Are all atoms saturated?" ) ; for ( int f = 0 ; f < ac . getAtomCount ( ) ; f ++ ) { if ( ! isSaturated ( ac . getAtom ( f ) , ac ) ) return false ; } return true ; }
@ Test public void testInfo_Object_int ( ) throws Exception { ILoggingTool logger = getLoggingTool ( ) ; logger . info ( this , 1 ) ; }
protected AtomTypeFactory getAtomTypeFactory ( IChemObjectBuilder builder ) throws CDKException { if ( structgenATF == null ) { try { structgenATF = AtomTypeFactory . getInstance ( atomTypeList , builder ) ; } catch ( Exception exception ) { logger . debug ( exception ) ; throw new CDKException ( "Could not instantiate AtomTypeFactory!" , exception ) ; } } return structgenATF ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber + ":" , line ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber + ":" , line ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
@ Override public void processIOSettingQuestion ( IOSetting setting ) { if ( "ForceReadAs3DCoordinates" . equals ( setting . getName ( ) ) ) { try { setting . setSetting ( "true" ) ; } catch ( CDKException e ) { logger . error ( "Error while setting [{}] to true." , setting . getName ( ) , e ) ; logger . debug ( e ) ; } } }
@ Override public void processIOSettingQuestion ( IOSetting setting ) { if ( "ForceReadAs3DCoordinates" . equals ( setting . getName ( ) ) ) { try { setting . setSetting ( "true" ) ; } catch ( CDKException e ) { logger . error ( "Could not set forceReadAs3DCoords setting: " , e . getMessage ( ) ) ; logger . error ( e . getMessage ( ) , e ) ; } } }
@ Override public void write ( IChemObject object ) throws CDKException { customizeJob ( ) ; if ( object instanceof IAtomContainer ) { try { writeAtomContainer ( ( IAtomContainer ) object ) ; writer . flush ( ) ; } catch ( Exception ex ) { logger . debug ( ex ) ; throw new CDKException ( "Exception while writing to CDK source code: " + ex . getMessage ( ) , ex ) ; } } else { logger . debug ( "Unsupported object class: " + object . getClass ( ) ) ; throw new CDKException ( "Only supported is writing of IAtomContainer objects." ) ; } }
@ Override public void write ( IChemObject object ) throws CDKException { customizeJob ( ) ; if ( object instanceof IAtomContainer ) { try { writeAtomContainer ( ( IAtomContainer ) object ) ; writer . flush ( ) ; } catch ( Exception ex ) { logger . error ( "Exception while writing to CDK source code: " + ex . getMessage ( ) ) ; throw new CDKException ( "Exception while writing to CDK source code: " + ex . getMessage ( ) , ex ) ; } } else { logger . error ( "Unsupported is writing of IAtomContainer objects." ) ; throw new CDKException ( "Only supported is writing of IAtomContainer objects." ) ; } }
@ Override public void endDocument ( ) { logger . info ( "End CDO Object" ) ; logger . info ( "End CDO Object" ) ; }
@ Override public void endDocument ( ) { logger . debug ( "Closing document" ) ; logger . debug ( "Ending document" ) ; }
@ Override public void setWriter ( final Writer writer ) throws CDKException { logger . info ( "Setting Writer" ) ; this . output = new OutputStream ( ) { @ Override public void write ( int b ) throws IOException { writer . write ( b ) ; } } ; }
@ Test public void testFingerprints ( ) throws Exception { checkFP ( REF_MOLECULE , CircularFingerprinter . CLASS_ECFP6 , 0 , REF_ECFP6_0 ) ; checkFP ( REF_MOLECULE , CircularFingerprinter . CLASS_ECFP6 , 1024 , REF_ECFP6_1024 ) ; LOG . info ( "eth_Fingerprints(): {}" , checkFP ( REF_MOLECULE ) . getFingerprints ( ) ) ; }
private List < IAtomContainer > removeDuplicates ( List < IAtomContainer > tautomers ) throws CDKException { Set < String > cansmis = new HashSet < > ( ) ; List < IAtomContainer > result = new ArrayList < > ( ) ; for ( IAtomContainer tautomer : tautomers ) { if ( cansmis . add ( CANSMI . create ( tautomer ) ) ) result . add ( tautomer ) ; } logger . debug ( "Selected {} for {}" , tautomer , result ) ; return result ; }
private GTRasterDataBinding parseTiff ( File file ) { Hints hints = new Hints ( Hints . FORCE_LONGITUDE_FIRST_AXIS_ORDER , Boolean . TRUE ) ; GeoTiffReader reader ; try { reader = new GeoTiffReader ( file , hints ) ; GridCoverage2D coverage = ( GridCoverage2D ) reader . read ( null ) ; return new GTRasterDataBinding ( coverage ) ; } catch ( Exception e ) { LOGGER . warn ( "Could not read RasterDataBinding from file " + file . getAbsolutePath ( ) , e ) ; throw new RuntimeException ( e ) ; } }
private REXP internalEval ( String command ) throws RserveException { if ( logAllEval ) log . debug ( "Command: " + command ) ; return super . eval ( command ) ; }
@ Override public void shutdown ( ) { LOG . info ( "Stopping scheduler: " + this . algorithms . getName ( ) ) ; this . algorithms . clear ( ) ; }
@ Override public void propertyChange ( PropertyChangeEvent evt ) { log . debug ( "Updating repository configuration" ) ; updateRepositoryConfiguration ( ) ; CustomDataTypeManager . getInstance ( ) . update ( ) ; }
public boolean getEnableBatchStart ( ) { boolean isBatch = DEFAULT_ENABLEBATCHSTART ; String batch_c = getConfigVariable ( RWPSConfigVariables . ENABLE_BATCH_START ) ; if ( batch_c != null && ! batch_c . equals ( "" ) ) { try { isBatch = Boolean . parseBoolean ( batch_c ) ; } catch ( NumberFormatException e ) { LOGGER . warn ( "Invalid batch start value [{}]" , batch_c ) ; } } return isBatch ; }
private void logException ( Exception exception ) { StringBuilder errorBuilder = new StringBuilder ( exception . getMessage ( ) ) ; Throwable cause = getRootCause ( exception ) ; if ( cause != exception ) { errorBuilder . append ( ", exception message: " ) . append ( cause . getMessage ( ) ) ; } LOG . error ( errorBuilder . toString ( ) , exception ) ; }
protected void cleanupDrivers ( Set < String > provided ) { Enumeration < Driver > drivers = DriverManager . getDrivers ( ) ; while ( drivers . hasMoreElements ( ) ) { LOG . info ( "Deregistering jdbc driver: " + drivers . get ( 0 ) ) ; deregisterDriver ( drivers . nextElement ( ) , provided ) ; } }
public static void close ( ResultSet closable ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( SQLException ex ) { log . debug ( "Error closing result set" , ex ) ; } } }
@ Override public void removeProcedure ( String procedure ) { CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Removing procedure {}" , procedure ) ; this . procedures . remove ( procedure ) ; }
@ Override public void setMaxPhenomenonTimeForOffering ( String offering , DateTime maxTime ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Setting maximal phenomenon time for offering {} to {}" , offering , maxTime ) ; if ( maxTime == null ) { this . maxPhenomenonTimeForOfferings . remove ( offering ) ; } else { this . maxPhenomenonTimeForOfferings . put ( offering , DateTimeHelper . toUTC ( maxTime ) ) ; } }
@ Override public void addOfferingForObservableProperty ( String observableProperty , String offering ) { CacheValidation . notNullOrEmpty ( OBSERVABLE_PROPERTY , observableProperty ) ; CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Adding offering {} to observableProperty {}" , offering , observableProperty ) ; this . offeringsForObservableProperties . computeIfAbsent ( observableProperty , createSynchronizedSet ( ) ) . add ( offering ) ; }
@ Override public void addProcedureForFeatureOfInterest ( String featureOfInterest , String procedure ) { CacheValidation . notNullOrEmpty ( FEATURE_OF_INTEREST , featureOfInterest ) ; CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Adding procedure {} to featureOfInterest {}" , procedure , featureOfInterest ) ; this . proceduresForFeaturesOfInterest . computeIfAbsent ( featureOfInterest , createSynchronizedSet ( ) ) . add ( procedure ) ; }
@ Override public void addProcedureForOffering ( String offering , String procedure ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Adding procedure {} to offering {}" , procedure , offering ) ; this . proceduresForOfferings . computeIfAbsent ( offering , createSynchronizedSet ( ) ) . add ( procedure ) ; }
@ Override public void removeObservablePropertiesForOffering ( String offering ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Removing observableProperties for offering {}" , offering ) ; this . observablePropertiesForOfferings . remove ( offering ) ; }
@ Override public void removeObservablePropertyForOffering ( String offering , String observableProperty ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( OBSERVABLE_PROPERTY , observableProperty ) ; LOG . trace ( "Removing observableProperty {} from offering {}" , observableProperty , offering ) ; this . observablePropertiesForOfferings . getOrDefault ( offering , Collections . emptySet ( ) ) . remove ( observableProperty ) ; }
@ Override public void removeRolesForRelatedFeature ( String relatedFeature ) { CacheValidation . notNullOrEmpty ( RELATED_FEATURE , relatedFeature ) ; LOG . trace ( "Removing roles for relatedFeature {}" , relatedFeature ) ; this . rolesForRelatedFeatures . remove ( relatedFeature ) ; }
@ Override public void setObservablePropertiesForResultTemplate ( String resultTemplate , Collection < String > observableProperties ) { CacheValidation . notNullOrEmpty ( RESULT_TEMPLATE , resultTemplate ) ; LOG . trace ( "Setting ObservableProperties for ResultTemplate {} to {}" , resultTemplate , observableProperties ) ; final Set < String > newValue = newSynchronizedSet ( observableProperties ) ; this . observedPropertiesForResultTemplates . put ( resultTemplate , newValue ) ; }
@ Override public void clearRelatedFeaturesForOfferings ( ) { LOG . trace ( "Clearing Related Features for offerings" ) ; this . relatedFeaturesForOfferings . clear ( ) ; }
@ Override public void removeOffering ( String offering ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Removing offering {}" , offering ) ; this . offerings . remove ( offering ) ; }
@ Override public void removeFeatureOfInterestTypeForOffering ( String offering , String featureOfInterestType ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( FEATURE_OF_INTEREST_TYPE , featureOfInterestType ) ; LOG . trace ( "Removing featureOfInterestType {} from offering {}" , featureOfInterestType , offering ) ; this . featureOfInterestTypesForOfferings . getOrDefault ( offering , Collections . emptySet ( ) ) . remove ( featureOfInterestType ) ; }
@ Override public void clearSupportedLanguage ( ) { LOG . trace ( "Clearing supported language" ) ; this . supportedLanguages . clear ( ) ; }
@ Override public void removeProcedureHumanReadableNameForIdentifier ( String identifier ) { CacheValidation . notNullOrEmpty ( PROCEDURE , identifier ) ; LOG . trace ( "Removing procedure human readable name for identifier {}" , identifier ) ; procedureIdentifierHumanReadableName . remove ( identifier ) ; }
@ Override public void clearCompositePhenomenon ( ) { LOG . trace ( "Clearing composite phenomenon" ) ; this . compositePhenomenons . clear ( ) ; }
@ Override public void clearCompositePhenomenonsForObservableProperty ( ) { LOG . trace ( "Clearing composite phenomenon for observable properties" ) ; this . compositePhenomenonsForObservableProperty . clear ( ) ; }
@ Override public void addPublishedOffering ( String offering ) { CacheValidation . notNullOrEmpty ( PUBLISHED_OFFERING , offering ) ; LOG . trace ( "Adding published offering {}" , offering ) ; publishedOffering . add ( offering ) ; }
private void logAndWait ( CompleteUpdate update , CompleteUpdate waitFor ) throws OwsExceptionReport { LOGGER . trace ( "{} waiting for {}" , update , waitFor ) ; waitFor . waitForCompletion ( ) ; LOGGER . trace ( "{} stopped waiting for {}" , update , waitFor ) ; }
private void logAndWait ( CompleteUpdate update , CompleteUpdate waitFor ) throws OwsExceptionReport { LOGGER . trace ( "{} waiting for {}" , update , waitFor ) ; waitFor . waitForCompletion ( ) ; LOGGER . trace ( "{} stopped waiting for {}" , update , waitFor ) ; }
void waitForCompletion ( ) throws OwsExceptionReport { lock ( ) ; try { while ( ! isFinished ( ) ) { try { finished . await ( ) ; } catch ( InterruptedException ex ) { LOGGER . warn ( "Interrupted while waiting for cache update completion" , ex ) ; } } if ( getState ( ) == State . FAILED ) { throw getUpdate ( ) . getFailureCause ( ) ; } } finally { unlock ( ) ; } }
private static String createFeatureStatement ( int featureId , Double [ ] coordinates ) { String featureStatement = String . format ( SQL_INSERT_FEATURE , Integer . toString ( featureId ) , Double . toString ( coordinates [ X_COORD_INDEX ] ) . replaceAll ( "," , "." ) , Double . toString ( coordinates [ Y_COORD_INDEX ] ) . replaceAll ( "," , "." ) ) ; LOGGER . debug ( featureStatement ) ; return featureStatement ; }
public ProcedureEntity getProcedureForIdentifierIncludeDeleted ( final String identifier , final Session session ) { Criteria criteria = session . createCriteria ( ProcedureEntity . class ) . add ( Restrictions . eq ( ProcedureEntity . IDENTIFIER , identifier ) ) ; LOGGER . trace ( QUERY_IDENTIFIER_LOG_TEMPLATE , HibernateHelper . getSqlString ( criteria ) ) ; return ( ProcedureEntity ) criteria . uniqueResult ( ) ; }
public EReportingAssessmentTypeEntity getEReportingAssessmentType ( AssessmentType assessmentType , Session session ) { Criteria c = getDefaultCriteria ( session ) ; c . add ( Restrictions . eq ( EReportingAssessmentTypeEntity . ID , assessmentType . getId ( ) ) ) ; LOGGER . trace ( LOG_TEMPLATE , HibernateHelper . getSqlString ( c ) ) ; return ( EReportingAssessmentTypeEntity ) c . uniqueResult ( ) ; }
public Criteria getSeriesCriteria ( Collection < String > procedures , Collection < String > observedProperties , Collection < String > features , Session session ) { final Criteria c = createCriteriaFor ( procedures , observedProperties , features , session ) ; LOGGER . trace ( QUERY_SERIES_CRITERIA , HibernateHelper . getSqlString ( c ) ) ; return c ; }
public DataEntity < ? > getFirstObservationFor ( DatasetEntity series , Session session ) { Criteria c = getDefaultObservationCriteria ( session ) ; c . add ( Restrictions . eq ( DataEntity . PROPERTY_DATASET_ID , series . getId ( ) ) ) ; c . addOrder ( Order . asc ( DataEntity . PROPERTY_SAMPLING_TIME_START ) ) ; c . setMaxResults ( 1 ) ; LOGGER . trace ( "QUERY getFirstObservationFor(series): {}" , HibernateHelper . getSqlString ( c ) ) ; return ( DataEntity ) c . uniqueResult ( ) ; }
protected void close ( Statement stmt ) { if ( stmt != null ) { try { stmt . close ( ) ; } catch ( SQLException e ) { LOGGER . error ( "Error closing statement. " + e . getMessage ( ) , e ) ; } } }
private Document read ( ) throws ConfigurationError { LOCK . readLock ( ) . lock ( ) ; try { try { if ( cache == null ) { cache = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) . parse ( configuration ) ; } return cache ; } catch ( ParserConfigurationException | SAXException | IOException ex ) { LOG . error ( UNPARSABLE_ERROR_MESSAGE , ex ) ; throw new ConfigurationError ( UNPARSABLE_ERROR_MESSAGE , ex ) ; } } finally { LOCK . readLock ( ) . unlock ( ) ; } }
private void runCurrent ( ) throws OwsExceptionReport { LOGGER . trace ( "Starting update {}" , this . current ) ; this . current . execute ( ) ; LOGGER . trace ( "Finished update {}" , this . current ) ; lock ( ) ; try { persistenceStrategy . persistOnCompleteUpdate ( getCache ( ) ) ; CompleteUpdate u = this . current ; this . current = null ; u . signalWaiting ( ) ; } finally { unlock ( ) ; } }
private void runCurrent ( ) throws OwsExceptionReport { LOGGER . trace ( "Starting update {}" , this . current ) ; this . current . execute ( ) ; LOGGER . trace ( "Finished update {}" , this . current ) ; lock ( ) ; try { persistenceStrategy . persistOnCompleteUpdate ( getCache ( ) ) ; CompleteUpdate u = this . current ; this . current = null ; u . signalWaiting ( ) ; } finally { unlock ( ) ; } }
@ Override public void run ( ) { Map < String , Object > data = new HashMap < > ( ) ; try { eventsResolvers . stream ( ) . forEach ( l -> data . putAll ( l . resolve ( ) ) ) ; dataHandler . persist ( data ) ; } catch ( Throwable e ) { log . error ( "Failed to persist events" , e ) ; } }
private void initEmbeddedMode ( ) { log . info ( "Setting up embedded mode" ) ; embeddedServer = new EmbeddedElasticsearch ( ) ; embeddedServer . setHomePath ( context . getRealPath ( "/WEB-INF" ) . concat ( "/config" ) . concat ( "/elasticsearch" ) ) ; embeddedServer . init ( ) ; setClient ( embeddedServer . getClient ( ) ) ; }
@ Override public void destroy ( ) { try { logger . info ( "Destroying ElasticSearch server" ) ; if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { logger . info ( "Closing ElasticSearch node" ) ; node . close ( ) ; } } } catch ( ElasticsearchException | IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ Override public void destroy ( ) { try { if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { logger . info ( "Closing ElasticSearch client" ) ; getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { node . close ( ) ; } logger . info ( "ElasticSearch node destroyed" ) ; } } catch ( ElasticsearchException | IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ Override public void destroy ( ) { try { if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { logger . info ( "Closing ElasticSearch client" ) ; getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { logger . info ( "Closing ElasticSearch node" ) ; node . close ( ) ; } } } catch ( ElasticsearchException | IOException e ) { logger . warn ( "Error while closing the ElasticSearch server: " , e ) ; } }
private void logConnectionError ( String i , UnknownHostException e ) { log . error ( "Failed to get connection to {}.{}" , i , e . getMessage ( ) ) ; }
@ Override public void unregister ( OwsCode id ) throws ProcessNotFoundException , UndeletableProcessException { logger . debug ( "unregistering {}" , id . getValue ( ) ) ; checkProcessExists ( id ) ; getRepository ( id ) . unregister ( id ) ; }
@ Override public void interrupt ( ) throws UnableToInterruptJobException { LOGGER . info ( "method: interrupt has been called for the job: " + getJobDescription ( ) ) ; }
@ FindbugsSuppressWarnings ( "OBL_UNSATISFIED_OBLIGATION" ) private PreRenderingConfig readJobConfig ( String file ) { try ( InputStream taskConfig = getClass ( ) . getResourceAsStream ( file ) ) { ObjectMapper om = new ObjectMapper ( ) ; return om . readValue ( taskConfig , PreRenderingConfig . class ) ; } catch ( IOException e ) { LOGGER . debug ( "" , e ) ; return new PreRenderingConfig ( ) ; } }
private DataCollection < Data < QuantityValue > > getTimeseriesData ( IoParameters parameters ) { Stopwatch stopwatch = Stopwatch . startStopwatch ( ) ; DataCollection < Data < QuantityValue > > timeseriesData = parameters . isGeneralize ( ) ? new GeneralizingQuantityService ( timeseriesDataService ) . getData ( parameters ) : timeseriesDataService . getData ( parameters ) ; logger . debug ( "TimeseriesData: {}: {}" , stopwatch . elapsed ( TimeUnit . MILLISECONDS ) , parameters ) ; return timeseriesData ; }
private Object encodeGeometry ( GeoJSONFeature value ) { try { final GeoJSONEncoder enc = new GeoJSONEncoder ( ) ; final Geometry geometry = value . getGeometry ( ) ; return enc . encodeGeometry ( geometry ) ; } catch ( GeoJSONException e ) { LOG . error ( "could not properly encode geometry." , e ) ; return null ; } }
public static JsonNode getJsonNodeFrom ( Object object ) { if ( object == null ) { return null ; } try { return OBJECT_MAPPER . readTree ( OBJECT_MAPPER . writeValueAsString ( object ) ) ; } catch ( IOException e ) { logger . info ( "Parse Object to JSON error : {}" , e . getMessage ( ) ) ; return null ; } }
@ Override public void updateBounds ( ) { Logger . getLogger ( DrawableVBO . class ) . warn ( "not implemented" ) ; }
@ Override public void mount ( IPainter painter ) { try { loader . load ( painter , this ) ; hasMountedOnce = true ; } catch ( Exception e ) { e . printStackTrace ( ) ; Logger . getLogger ( DrawableVBO . class ) . error ( e , e ) ; } }
@ Override public Coord2d getPixelScale ( ) { log . error ( "getPixelScale not implemented yet" ) ; return new Coord2d ( 1 , 1 ) ; }
protected void log ( IEventLog event ) { logger . info ( event ) ; }
public static boolean sendToServer ( String message ) { try { logger . debug ( "Sending to server( " + message + " )" ) ; out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public static boolean sendToServer ( String message ) { logger . debug ( "sendToServer( " + message + " )" ) ; try { out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public static boolean sendToServer ( String message ) { logger . debug ( "sendToServer( " + message + " )" ) ; try { out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public void setStoragePath ( String storagePath ) { this . storagePath = storagePath ; this . rootLocation = Paths . get ( storagePath ) ; try { Files . createDirectories ( rootLocation ) ; } catch ( IOException e ) { LOGGER . error ( "Error creating directory to storage storage: " + storagePath , e ) ; } }
@ Override public Resource loadAsResource ( String keyName ) { try { URL url = new URL ( getBaseUrl ( ) + keyName ) ; Resource resource = new UrlResource ( url ) ; if ( resource . exists ( ) || resource . isReadable ( ) ) { return resource ; } } catch ( MalformedURLException e ) { logger . error ( e . getMessage ( ) , e ) ; } return null ; }
public static Boolean parseBoolean ( String body , String field ) { ObjectMapper mapper = new ObjectMapper ( ) ; JsonNode node ; try { node = mapper . readTree ( body ) ; JsonNode leaf = node . get ( field ) ; if ( leaf != null ) return leaf . asBoolean ( ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return null ; }
@ Override protected int executeCommand ( ) throws CommandException { try { RestoreManager mgr = new RestoreManager ( request ) ; logger . info ( mgr . backup ( ) ) ; } catch ( BackupWarningException bwe ) { logger . info ( bwe . getMessage ( ) ) ; } catch ( BackupException be ) { throw new CommandException ( be ) ; } return 0 ; }
@ Override protected int executeCommand ( ) throws CommandException { try { RestoreManager mgr = new RestoreManager ( request ) ; logger . info ( mgr . restore ( ) ) ; } catch ( BackupWarningException bwe ) { logger . info ( bwe . getMessage ( ) ) ; } catch ( BackupException be ) { throw new CommandException ( be ) ; } return 0 ; }
@ Test public void testOverrideForDefaultEntries ( ) { AuthConfigFactory f = new _ExtendsBaseAuthConfigFactory ( ) ; f = new _Extends_ExtendsAuthConfigFactory ( ) ; log . info ( "init {}" , f ) ; }
private void checkDisposed ( ) { String instanceRoot = System . getProperty ( "com.sun.aas.instanceRoot" ) ; if ( new File ( instanceRoot ) . exists ( ) ) { LOG . warn ( "Directory " + instanceRoot + " is not cleaned up after glassfish.dispose()" ) ; throw new RuntimeException ( "Directory " + instanceRoot + " is not cleaned up after glassfish.dispose()" ) ; } }
private void init ( AdminCommandContext context ) throws IOException { logger = context . getLogger ( ) ; props = Globals . get ( StartupContext . class ) . getArguments ( ) ; verbose = Boolean . parseBoolean ( props . getProperty ( "-verbose" , "false" ) ) ; logger . info ( "" + verbose ) ; }
@ Override public void onThrowable ( Throwable t ) { if ( decoratedAsyncHandler != null ) { decoratedAsyncHandler . onThrowable ( t ) ; } else { logger . warn ( "Cannot decorated async handler because no async handler was disposed." , t ) ; } }
public STATE onBodyPartReceived ( HttpResponseBodyPart e ) throws Exception { byte [ ] bytes = e . getBodyPartBytes ( ) ; if ( bytes . length != 0 ) { String s = new String ( bytes ) ; log . info ( "got part: {}" , s ) ; log . warn ( "Sampling stacktrace." , new Throwable ( "trace that, we should not get called for empty body." ) ) ; queue . put ( s ) ; } return STATE . CONTINUE ; }
public STATE onBodyPartReceived ( HttpResponseBodyPart e ) throws Exception { byte [ ] bytes = e . getBodyPartBytes ( ) ; if ( bytes . length != 0 ) { String s = new String ( bytes ) ; log . info ( "got part: {}" , s ) ; log . warn ( "Sampling stacktrace." , new Throwable ( "trace that, we should not get called for empty body." ) ) ; queue . put ( s ) ; } return STATE . CONTINUE ; }
public void onThrowable ( Throwable t ) { LOG . error ( "Error on connection" , t ) ; t . printStackTrace ( ) ; }
@ Deprecated public TrainableStorableClassifier getDefaultClassifier ( ) throws ClassifierException { log . error ( "Using default classifier to generate classifier" ) ; return getByPoolLinearClassifier ( ) ; }
public static void printSamplesAsSvmLightInput ( List < LabeledSample > samples , Logger logger ) { logger . warn ( "Samples with the following label(s) does not have any effect but will not be reset to the system" ) ; }
public T getClassifier ( Vector < LabeledSample > samples ) throws ClassifierException { T ret = null ; synchronized ( this ) { if ( pool . containsKey ( samples ) ) { logger . info ( "Pool is still in pool" ) ; ret = pool . get ( samples ) ; } } if ( null == ret ) { logger . info ( "Creating a new classifier, since it does not exist in pool" ) ; ret = createClassifier ( ) ; ret . train ( samples ) ; synchronized ( this ) { pool . put ( samples , ret ) ; } } return ret ; }
public T getClassifier ( Vector < LabeledSample > samples ) throws ClassifierException { T ret = null ; synchronized ( this ) { if ( pool . containsKey ( samples ) ) { logger . info ( "Classifier exists in pool" ) ; ret = pool . get ( samples ) ; } } if ( null == ret ) { ret = createClassifier ( ) ; ret . train ( samples ) ; synchronized ( this ) { pool . put ( samples , ret ) ; } logger . info ( "Classifier finished" ) ; } return ret ; }
public void setDoNotScale ( Set < Integer > doNotScale ) { this . doNotScale = doNotScale ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( "Will not scale features: " ) ; boolean firstIteration = true ; for ( Integer i : this . doNotScale ) { if ( firstIteration ) firstIteration = false ; else sb . append ( ", " ) ; sb . append ( i ) ; } logger . info ( sb . toString ( ) ) ; }
protected Vector < LabeledSample > samplesForPredictions ( Vector < LabeledSample > samples , List < Vector < LabeledSample > > olderSamples ) { logger . info ( "n-----={}n" , DebugUtil . debugDumpLazily ( samples . size ( ) ) ) ; return super . samplesForPredictions ( samples , olderSamples ) ; }
@ Override public AdaptedVersion marshal ( Version v ) throws Exception { logger . debug ( "VersionAdapter unmarshal" ) ; return new AdaptedVersion ( v . getProduct ( ) , v . getMajor ( ) , v . getMinor ( ) , v . getBuildType ( ) ) ; }
private void initializeTestDir ( CommonConfig config ) throws ConfigurationException { NameValueTable EDA = null ; try { EDA = config . getSection ( this . getClass ( ) . getName ( ) ) ; } catch ( ConfigurationException e ) { throw new ConfigurationException ( e . getMessage ( ) + " No EDA section." ) ; } this . testDIR = EDA . getString ( "testDir" ) ; if ( null == testDIR ) { LOG . warn ( "Could not find EDA " + this . testDIR + " in the configuration." ) ; } }
private void loadChunkerModel ( String chunkerModelPath ) { InputStream modelIn = null ; ChunkerModel model = null ; try { modelIn = new FileInputStream ( chunkerModelPath ) ; model = new ChunkerModel ( modelIn ) ; } catch ( IOException e ) { logger . error ( "Could not load Chunker model" ) ; } finally { if ( modelIn != null ) { try { modelIn . close ( ) ; } catch ( IOException e ) { } } } this . chunker = new opennlp . tools . chunker . ChunkerME ( model ) ; }
private void intializeIgnorePosSet ( CommonConfig config , String sectionName ) throws ConfigurationException { NameValueTable comp = config . getSection ( sectionName ) ; this . ignorePosSet = new HashSet < String > ( ) ; try { for ( String str : ( Files . readAllLines ( Paths . get ( comp . getString ( "ignorePosPath" ) ) , Charset . forName ( "UTF-8" ) ) ) ) this . ignorePosSet . add ( str ) ; } catch ( IOException e1 ) { logger . error ( "Could not read POS tags file" ) ; } }
protected IExtractor getRedirectExtractor ( ) { IExtractor extractor = null ; try { Lemmatizer lemmatizer = new TextProLemmatizer ( processingToolsConf ) ; extractor = new RedirectExtractor ( lemmatizer ) ; } catch ( LemmatizerException e ) { m_logger . error ( "error initializing RedirectExtractor. " + e . getMessage ( ) ) ; } return extractor ; }
public void terminate ( ) { try { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "terminate this template to id=" + this . ruleBaseName ) ; } this . mapTemplateToId = null ; this . mapAllRules = null ; if ( this . connection != null ) this . connection . close ( ) ; } catch ( SQLException e ) { logger . warn ( "Connection could not be closed for rule base: " + this . ruleBaseName ) ; } }
public void terminate ( ) { try { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Terminating rule base: " + this . ruleBaseName ) ; } this . mapTemplateToId = null ; this . mapAllRules = null ; if ( this . connection != null ) this . connection . close ( ) ; } catch ( SQLException e ) { logger . error ( "Unexpected error: " + e . getMessage ( ) ) ; } }
public void cleanUp ( ) { try { connection . close ( ) ; } catch ( SQLException e ) { logger . error ( "Error closing connection." , e ) ; } }
public JCas runLAP ( String text , String hypothesis ) { JCas aJCas = null ; try { aJCas = lap . generateSingleTHPairCAS ( text , hypothesis ) ; PlatformCASProber . probeCasAndPrintContent ( aJCas , System . out ) ; } catch ( LAPException e ) { e . printStackTrace ( ) ; LOG . debug ( "error running LAP: {}" , e . getMessage ( ) ) ; } return aJCas ; }
@ Override public List < DifferBotMapping > readAllDifferBotMappings ( ) { try { return differBotMappingStore . readAllDifferBotMappings ( ) ; } catch ( IResourceStore . ResourceStoreException e ) { log . error ( e . getLocalizedMessage ( ) , e ) ; throw new InternalServerErrorException ( ) ; } }
@ Override public void deleteBotUserIdFromDifferBotMappings ( String userId ) { try { differBotMappingStore . deleteBotUserIdFromDifferBotMappings ( userId ) ; availableBotUserIds . remove ( userId ) ; } catch ( IResourceStore . ResourceStoreException e ) { log . error ( e . getLocalizedMessage ( ) , e ) ; throw new InternalServerErrorException ( ) ; } }
private void initRestClient ( IRestInterfaceFactory restInterfaceFactory ) { try { restBehaviorStore = restInterfaceFactory . get ( IRestBehaviorStore . class ) ; } catch ( RestInterfaceFactory . RestInterfaceFactoryException e ) { restBehaviorStore = null ; log . error ( e . getLocalizedMessage ( ) , e ) ; } }
public static void put ( Object key , Object value ) { if ( key == null ) { throw new IllegalArgumentException ( "key cannot be null" ) ; } if ( value == null ) { remove ( key ) ; return ; } resources . get ( ) . put ( key , value ) ; if ( log . isTraceEnabled ( ) ) { String msg = "Bound value of type [" + value . getClass ( ) . getName ( ) + "] for key [" + key + "] to thread " + "[" + Thread . currentThread ( ) . getName ( ) + "]" ; log . trace ( msg ) ; } }
@ Override public void logVersion ( ) { log . info ( "Currently version: {}" , version ) ; }
@ Override public < T > ScheduledFuture < T > submitScheduledCallable ( final Callable < T > callable , long delay , TimeUnit timeUnit , final Map < Object , Object > threadBindings ) { return executorService . schedule ( ( ) -> { try { if ( threadBindings != null ) { ThreadContext . setResources ( threadBindings ) ; } return callable . call ( ) ; } catch ( Throwable t ) { log . error ( "Failed to set timer resources" , t ) ; return null ; } finally { ThreadContext . remove ( ) ; } } , delay , timeUnit ) ; }
@ Override public void run ( ) { executorService . shutdown ( ) ; try { if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { executorService . shutdownNow ( ) ; if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { log . warn ( "Unable to terminate terminate threads" ) ; } } } catch ( InterruptedException e ) { executorService . shutdownNow ( ) ; Thread . currentThread ( ) . interrupt ( ) ; log . error ( e . getLocalizedMessage ( ) , e ) ; } }
@ Override public void run ( ) { executorService . shutdown ( ) ; try { if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { log . error ( "Pool did not terminate" ) ; executorService . shutdownNow ( ) ; if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { log . error ( "Pool did not terminate" ) ; } } } catch ( InterruptedException e ) { executorService . shutdownNow ( ) ; Thread . currentThread ( ) . interrupt ( ) ; } }
@ Override public void loginFailed ( final Throwable reason ) { log . error ( "Login failed: " , reason ) ; }
public RootElementDifference findDifference ( final RootElement expected , final RootElement actual ) { final long startTime = System . currentTimeMillis ( ) ; final ElementDifference elementDifference = elementDifferenceFinder . differenceFor ( expected , actual ) ; LOG . trace ( "findDifference() Expected: {}, actual: {} time: {}ms" , expected , actual , System . currentTimeMillis ( ) - startTime ) ; return elementDifference != null ? new RootElementDifference ( elementDifference , expected , actual ) : null ; }
static void rollback ( Connection connection ) { if ( connection != null ) try { connection . rollback ( ) ; log . debug ( "Transaction rollback" ) ; } catch ( SQLException e ) { throw new SQLRuntimeException ( e ) ; } }
public static Git cloneRepo ( String url , File destination ) { try { return Git . cloneRepository ( ) . setURI ( url ) . setDirectory ( destination ) . call ( ) ; } catch ( GitAPIException e ) { LOGGER . error ( e , e ) ; return null ; } }
@ ShellCommand ( "Load MARK rules from given file or directory. Rules must be loaded before starting analysis." ) @ SuppressWarnings ( "squid:S100" ) public void load_rules ( String fileName ) { AnalysisServer server = AnalysisServer . getInstance ( ) ; if ( server == null ) { log . error ( "Server not initialized" ) ; return ; } server . loadMarkRules ( new File ( fileName ) ) ; }
private void parseEntityContent ( List < EntityStatement > stmts , @ NonNull MEntity me ) { if ( stmts == null ) { return ; } for ( EntityStatement c : stmts ) { if ( c instanceof OpDeclaration ) { OpDeclaration op = ( OpDeclaration ) c ; parseOp ( op , me ) ; } else if ( c instanceof VariableDeclaration ) { VariableDeclaration op = ( VariableDeclaration ) c ; parseVar ( op , me ) ; } else { log . error ( "Expected entity type for {} but found {}" , c , me ) ; } } }
protected void stopTcpServer ( ) { LOG . info ( "Stopping TCP server instance" ) ; tcpServer . stop ( ) ; }
protected void processAssetChange ( PersistenceEvent < EnergyOptimisationAsset > persistenceEvent ) { stopOptimisation ( persistenceEvent . getEntity ( ) . getId ( ) ) ; if ( persistenceEvent . getCause ( ) != PersistenceEvent . Cause . DELETE ) { if ( ! persistenceEvent . getEntity ( ) . isOptimisationDisabled ( ) . orElse ( false ) ) { logger . debug ( "Parsed SAML content of " + persistenceEvent . getEntity ( ) . getId ( ) + " failed - " + persistenceEvent . getCause ( ) ) ; startOptimisation ( persistenceEvent . getEntity ( ) ) ; } } }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle hashCode : " + theObject . hashCode ( ) ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( attributeHandle . toString ( ) ) ; } System . out . println ( ) ; }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle : " + theObject ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( attributeHandle . toString ( ) ) ; } System . out . println ( ) ; }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle : " + theObject ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( "Hash : " + attributeHandle . hashCode ( ) ) ; } System . out . println ( ) ; }
@ Override public void run ( ) { while ( _keepRunning ) { _read ( ) ; try { Thread . sleep ( 100 ) ; } catch ( Exception e ) { ourLog . error ( "Error waiting for next element" , e ) ; } } }
@ Override public String getErrorPageName ( SlingHttpServletRequest request ) { String servletName = String . valueOf ( getStatusCode ( request ) ) ; log . debug ( "Getting error page name for: " + servletName ) ; servletName = StringUtils . lowerCase ( servletName ) ; return servletName ; }
public static void setCurrentItem ( String item ) { ActionManager manager = getCurrentActionManager ( ) ; if ( manager != null ) { manager . setCurrentItem ( item ) ; } else { log . error ( "ActionManager is null!" ) ; } }
@ Activate public void activate ( FileFetchConfiguration config ) { this . config = config ; run ( ) ; log . info ( "Started" ) ; }
public static void updateUserData ( Session jcrSession ) { if ( jcrSession != null ) { try { jcrSession . getWorkspace ( ) . getObservationManager ( ) . setUserData ( "changedByWorkflowProcess" ) ; } catch ( RepositoryException e ) { LOGGER . warn ( "Unable to reset JCR session object" , e ) ; } } else { LOGGER . error ( "JCR session object is null." ) ; } }
public static void updateUserData ( Session jcrSession ) { if ( jcrSession != null ) { try { jcrSession . getWorkspace ( ) . getObservationManager ( ) . setUserData ( "changedByWorkflowProcess" ) ; } catch ( RepositoryException e ) { LOGGER . error ( "Error in repository operation::" , e ) ; } } else { LOGGER . warn ( "Attempting to update user-data to a null jcrSession" ) ; } }
public FieldComponent generateDefaultChildComponent ( ) { try { return defaultChildComponent . getDeclaredConstructor ( ) . newInstance ( ) ; } catch ( RuntimeException | ReflectiveOperationException ex ) { log . error ( "Could not instantiate default child component. This usually happens if the default subclass is not an interface. This usually means your dependency of the plugin will not be loaded." , ex ) ; return null ; } }
@ Override public boolean isFile ( ) { try { retrieveDetails ( ) ; } catch ( JSchException | SftpException ex ) { LOG . error ( "Cannot retrieve details: {}" , ex . getMessage ( ) ) ; } return isFile ; }
private void addMoveAuditEntries ( ActionManager manager ) { manager . deferredWithResolver ( rr -> { moves . forEach ( node -> { node . visit ( childNode -> { childNode . addAuditRecordForMove ( rr , auditLog ) ; log . debug ( "Added HDFSMoveEvent for MovedMove: " + rr . getCurrentFile ( ) ) ; } ) ; } ) ; } ) ; }
public static void serializeToMap ( Map < String , Object > map , Object sourceObject ) { if ( sourceObject == null ) { return ; } FieldUtils . getAllFieldsList ( sourceObject . getClass ( ) ) . stream ( ) . filter ( IntrospectionUtil :: isSimple ) . forEach ( f -> { try { Object value = FieldUtils . readField ( f , sourceObject , true ) ; if ( value != null ) { map . put ( f . getName ( ) , value ) ; } } catch ( IllegalAccessException ex ) { logger . error ( "Failed to serialize " + f . getName ( ) , ex ) ; } } ) ; }
@ Override public Transformer createTransformer ( ) { LOGGER . debug ( "Creating a new transformation" ) ; return new ContentVariableTransformer ( propertyAggregatorService , propertyConfigService ) ; }
Generator createGenerator ( final SAXParserFactory saxParserFactory ) { try { if ( saxParserFactory == null ) { return new XMLParserGenerator ( ) ; } else { return new XMLParserGenerator ( saxParserFactory ) ; } } catch ( Exception e ) { LOGGER . warn ( "Unable to create XML parser!" , e ) ; return null ; } }
public int getMaxRequestPerMinute ( ) { int cpuLoad ; try { cpuLoad = getCpuLoad ( ) ; return calculateRequests ( cpuLoad , tc . startThrottlingPercentage , tc . maxRequests ) ; } catch ( JMException e ) { LOG . warn ( "Could not find CPU load: {}" , e . getMessage ( ) ) ; return tc . maxRequests ; } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { return ; } log . trace ( "Disabling bundles {}" , disabledBundles ) ; for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { log . debug ( "Deactivating bundle {}" , bundle . getSymbolicName ( ) ) ; try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Unable to stop bundle {}" , bundle . getSymbolicName ( ) , be ) ; } } } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { log . info ( "No bundles specified. Consider specifying bundles or removing this service config" ) ; return ; } for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { log . debug ( "Bundle {} has been disabled" , bundle . getSymbolicName ( ) ) ; try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Unable to stop bundle {}" , bundle . getSymbolicName ( ) , be ) ; } } } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { log . info ( "No bundles specified. Consider specifying bundles or removing this service config" ) ; return ; } log . trace ( "Disabling bundles {}" , disabledBundles ) ; for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Error while disabling bundle " + bundle , be ) ; } } } }
@ Override public void initialize ( Config config ) throws PersistenceException , RepositoryException { Workspace workspace = config . getWorkspace ( ) ; if ( workspace . isInitialized ( ) ) { logger . debug ( "Workspace is already initialized: %s" , workspace . getWorkspaceId ( ) ) ; } else { workspace . getRunner ( ) . initialize ( queryHelper , config ) ; } }
private long getCapacity ( Config config ) { final Queue queue = jobManager . getQueue ( JOB_QUEUE_NAME ) ; if ( queue != null ) { final Statistics statistics = queue . getStatistics ( ) ; logger . debug ( "Job batch size is {} - {}." , config . getBatchSize ( ) , statistics . getNumberOfJobs ( ) ) ; return config . getBatchSize ( ) - statistics . getNumberOfJobs ( ) ; } else { return config . getBatchSize ( ) ; } }
@ Override protected void execute ( ) throws Exception { if ( pass ) { pass = ! pass ; } else { pass = ! pass ; logger . warn ( "You can run reset the script, it will be executed" ) ; throw new RuntimeException ( "Oops, this script failed" ) ; } }
@ Before public void init ( ) { log . info ( "init" ) ; MockitoAnnotations . initMocks ( this ) ; when ( validResource . getResourceResolver ( ) ) . thenReturn ( resolver ) ; when ( invalidResource . getResourceResolver ( ) ) . thenReturn ( resolver ) ; when ( resolver . adaptTo ( PageManager . class ) ) . thenReturn ( pageManager ) ; when ( pageManager . getContainingPage ( validResource ) ) . thenReturn ( page ) ; when ( page . getPath ( ) ) . thenReturn ( VALID_PATH ) ; }
@ Test public void testReportRunner ( ) throws RepositoryException { log . info ( "Starting testReportRunner..." ) ; ReportRunner reportRunner = new ReportRunner ( validRequest , dynamicClassLoaderManager ) ; reportRunner . init ( ) ; assertTrue ( reportRunner . isSuccessful ( ) ) ; assertNull ( reportRunner . getFailureMessage ( ) ) ; assertNotNull ( reportRunner . getReportExecutor ( ) ) ; assertEquals ( exec , reportRunner . getReportExecutor ( ) ) ; log . info ( "Test Succeeded!" ) ; }
@ Test public void testReportRunner ( ) throws RepositoryException { log . info ( "testReportRunner" ) ; ReportRunner reportRunner = new ReportRunner ( validRequest , dynamicClassLoaderManager ) ; reportRunner . init ( ) ; assertTrue ( reportRunner . isSuccessful ( ) ) ; assertNull ( reportRunner . getFailureMessage ( ) ) ; assertNotNull ( reportRunner . getReportExecutor ( ) ) ; assertEquals ( exec , reportRunner . getReportExecutor ( ) ) ; log . info ( "Test successful!" ) ; }
@ Test public void testExporter ( ) throws IllegalAccessException { log . info ( "testExporter" ) ; TagsCellValue val = new TagsCellValue ( ) ; FieldUtils . writeField ( val , "property" , "tags" , true ) ; FieldUtils . writeField ( val , "request" , request , true ) ; assertTrue ( ArrayUtils . isEquals ( new Tag [ ] { tag1 , tag2 } , val . getTags ( ) . toArray ( new Tag [ val . getTags ( ) . size ( ) ] ) ) ) ; log . info ( "Test successful!" ) ; }
@ Test public void testExporter ( ) throws IllegalAccessException { log . info ( "testExporter" ) ; TagsCellValue val = new TagsCellValue ( ) ; FieldUtils . writeField ( val , "property" , "tags" , true ) ; FieldUtils . writeField ( val , "request" , request , true ) ; assertTrue ( ArrayUtils . isEquals ( new Tag [ ] { tag1 , tag2 } , val . getTags ( ) . toArray ( new Tag [ val . getTags ( ) . size ( ) ] ) ) ) ; log . info ( "Test successful!" ) ; }
public void reportWarning ( String errorMessage ) { LOG . warn ( errorMessage ) ; warnings . add ( errorMessage ) ; }
private void writeToFile ( File f , String output ) { f . getParentFile ( ) . mkdirs ( ) ; if ( f . exists ( ) ) { logger . trace ( "creating " + f ) ; } try { try ( PrintWriter out = new PrintWriter ( f . getPath ( ) ) ) { out . println ( output ) ; out . close ( ) ; logger . trace ( "wrote " + f ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } }
private void writeToFile ( File f , String output ) { f . getParentFile ( ) . mkdirs ( ) ; if ( f . exists ( ) ) { logger . warn ( f + " already exists!!" ) ; } try { try ( PrintWriter out = new PrintWriter ( f . getPath ( ) ) ) { out . println ( output ) ; out . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new RuntimeException ( e ) ; } }
private CandyStore getCandiesStore ( ) { if ( candyStore == null ) { if ( candyStoreFile . exists ( ) ) { try { candyStore = gson . fromJson ( FileUtils . readFileToString ( candyStoreFile ) , CandyStore . class ) ; } catch ( Exception e ) { logger . error ( "cannot read can-found jmx index" , e ) ; } } if ( candyStore == null ) { candyStore = new CandyStore ( ) ; } } return candyStore ; }
public static void installGlobalNodePackage ( String nodePackageName , String version ) { logger . debug ( "installing " + nodePackageName + " with version " + version ) ; initNode ( ) ; runCommand ( NPM_COMMAND , USER_HOME_DIR , false , null , null , null , "install" , "--prefix" , NPM_DIR . getPath ( ) , version == null ? nodePackageName : nodePackageName + "@" + version ) ; }
public void destroy ( ) { try { if ( objectName != null && mBeanServer != null ) { mBeanServer . unregisterMBean ( objectName ) ; } } catch ( Exception e ) { LOGGER . debug ( "Exception unregistering MBean: " , e ) ; throw new RuntimeException ( e ) ; } }
protected NotificationListener getNotificationListener ( ) { return ( notification , handback ) -> { updateCounter . incrementAndGet ( ) ; log . info ( "NotificationListener " + notification ) ; } ; }
public String get ( String name , String defaultValue ) { String answer = null ; if ( envContext != null ) { try { answer = ( String ) envContext . lookup ( "hawtio/" + name ) ; } catch ( Exception e ) { LOG . warn ( "Error looking up " + name + " in environment for " + envContext . getProperty ( "hawtio/" + name ) , e ) ; } } if ( answer == null ) { answer = this . propertyResolver . apply ( name ) ; } if ( answer == null ) { answer = defaultValue ; } return answer ; }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Did not update fabric MBean" ) ; return false ; } Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "No new proxy allowlist to update" ) ; return false ; } else { LOG . info ( "Updated proxy allowlist: {}" , allowlist ) ; return true ; } }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Allowlist MBean not available" ) ; return false ; } Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "Skipping update for " + previousSize + ": " + newAllowlist ) ; return false ; } else { LOG . info ( "Updated proxy allowlist: {}" , allowlist ) ; return true ; } }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Allowlist MBean not available" ) ; return false ; } LOG . debug ( "Updating proxy allowlist to: " + allowlist ) ; Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "No new proxy allowlist to update" ) ; return false ; } else { return true ; } }
@ Override public boolean isAttributeWriteAllowed ( ObjectName objectName , String attribute ) { boolean allowed = delegate . isAttributeWriteAllowed ( objectName , attribute ) ; if ( allowed ) { allowed = mBeanInvoker . isWriteAllowed ( objectName , attribute ) ; } LOG . debug ( "isAttributeWriteAllowed(objectName = {}, attribute = {}) = {}" , objectName , attribute , allowed ) ; return allowed ; }
public static void clear ( HttpServletRequest request , AuthenticationConfiguration authConfig , boolean authenticatorLogout ) { HttpSession session = request . getSession ( false ) ; if ( ! isAuthenticated ( session ) ) { logger . warn ( "Authentication is disabled. Not setting the user. " + "To use the default user." ) ; return ; } Subject subject = ( Subject ) session . getAttribute ( "subject" ) ; if ( authenticatorLogout ) { Authenticator . logout ( authConfig , subject ) ; } session . invalidate ( ) ; }
public static void close ( Closeable closeable , String name , Logger log ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { if ( log == null ) { log = LOG ; } if ( name != null ) { log . warn ( "Cannot close: " + name + ". Reason: " + e . getMessage ( ) , e ) ; } else { log . warn ( "Cannot close. Reason: " + e . getMessage ( ) , e ) ; } } } }
public static void close ( Closeable closeable , String name , Logger log ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { if ( log == null ) { log = LOG ; } if ( name != null ) { log . warn ( "Cannot close: " + name + ". Reason: " + e . getMessage ( ) , e ) ; } else { log . warn ( "Cannot close: {}. Reason: {}" , name , e . getMessage ( ) , e ) ; } } } }
public void run ( String [ ] args ) throws Exception { parseArguments ( args ) ; LOG . info ( "Shutdown hook called" ) ; try { run ( ) ; } finally { LOG . info ( "Shutdown complete" ) ; } }
public void run ( String [ ] args ) throws Exception { parseArguments ( args ) ; LOG . info ( "Running Spring application" ) ; try { run ( ) ; } finally { LOG . info ( "Spring application finished" ) ; } }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( getClass ( ) . toString ( ) + " job is starting ..." ) ; List < String > domainUuids = abstractDomainRepository . findAllDomainIdentifiers ( ) ; logger . info ( domainUuids . size ( ) + " domain uuid have been found" ) ; return domainUuids ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > domainUuids = abstractDomainRepository . findAllDomainIdentifiers ( ) ; logger . info ( domainUuids . size ( ) + " domain(s) have been found to be checked" ) ; return domainUuids ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { SystemAccount account = getSystemAccount ( ) ; logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > entries = uploadRequestService . findOutdatedRequests ( account ) ; logger . info ( entries . size ( ) + " Upload Request(s) have been found to be closed" ) ; return entries ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { SystemAccount account = getSystemAccount ( ) ; logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > entries = uploadRequestService . findOutdatedRequests ( account ) ; logger . info ( entries . size ( ) + " Upload Request(s) have been found" ) ; return entries ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "MonthlyBatchImpl job starting" ) ; List < String > threads = threadWeeklyStatBusinessService . findUuidAccountBetweenTwoDates ( getFirstDayOfLastMonth ( ) , getLastDayOfLastMonth ( ) ) ; logger . info ( threads . size ( ) + "thread(s) have been found in ThreadWeeklyStat table." ) ; return threads ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "MonthlyThreadBatchImpl job starting." ) ; List < String > threads = threadWeeklyStatBusinessService . findUuidAccountBetweenTwoDates ( getFirstDayOfLastMonth ( ) , getLastDayOfLastMonth ( ) ) ; logger . info ( threads . size ( ) + " thread(s) have been found in threadWeeklyStat table." ) ; return threads ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "{} job starting ..." , getClass ( ) . toString ( ) ) ; return domainRepository . findAllDomainIdentifiersWithGroupProviders ( ) ; }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public Set < String > getMail ( String pattern ) throws BusinessException { User authUser = checkAuthentication ( Role . ADMIN ) ; Validate . notEmpty ( pattern , "pattern must be set." ) ; List < User > users = userService . autoCompleteUser ( authUser , pattern ) ; logger . debug ( "nb result for completion : " + users . size ( ) ) ; return getMailList ( users , AUTO_COMPLETE_LIMIT ) ; }
@ Override public AnonymousUrlDto find ( String uuid , String password ) { logger . debug ( "Finding AnonymousUrlDto" ) ; SystemAccount authUser = anonymousUrlService . getAnonymousURLAccount ( ) ; Account actor = null ; AnonymousUrl url = anonymousUrlService . find ( authUser , authUser , uuid , password ) ; for ( AnonymousShareEntry ase : url . getAnonymousShareEntries ( ) ) { actor = ase . getEntryOwner ( ) ; break ; } return new AnonymousUrlDto ( actor , url ) ; }
@ Override public ResetGuestPassword find ( String uuid ) throws BusinessException { Validate . notEmpty ( uuid , "Missing ResetGuestPassword uuid" ) ; logger . debug ( "Searching for resetGuestPassword contid : " + uuid ) ; SystemAccount authUser = service . getGuestSystemAccount ( ) ; return service . find ( authUser , authUser , uuid ) ; }
private boolean guestFunctionalityStatus ( AbstractDomain domain ) { Functionality guestFunctionality = functionalityService . getGuests ( domain ) ; boolean status = guestFunctionality . getActivationPolicy ( ) . getStatus ( ) ; if ( ! status ) { logger . debug ( "Could not findGuests status for domain: " + domain . getName ( ) ) ; } return status ; }
@ Override public TopDomain createTopDomain ( Account actor , TopDomain topDomain ) throws BusinessException { if ( ! ( topDomain . getDefaultRole ( ) . equals ( Role . SIMPLE ) || topDomain . getDefaultRole ( ) . equals ( Role . ADMIN ) ) ) { logger . debug ( "Setting default role to SIMPLE" ) ; topDomain . setDefaultRole ( Role . SIMPLE ) ; } return ( TopDomain ) createDomain ( actor , topDomain , getUniqueRootDomain ( ) ) ; }
@ Override public boolean apply ( Functionality input ) { if ( input . isDisplayable ( ) ) { return true ; } logger . debug ( "Functionality filtered: " + input . getIdentifier ( ) ) ; return false ; }
@ Override protected String runMyTask ( BatchTaskContext task ) { logger . info ( "Run taskid = {}, indexingIds = {}" , task . getTaskId ( ) , batchRunContext . getBatch ( ) ) ; boolean execute = batchRunner . execute ( task . getBatch ( ) , batchRunContext ) ; if ( ! execute ) { throw new BusinessException ( BusinessErrorCode . BATCH_INCOMPLETE , "asyncTask for batches failed" ) ; } return batchRunContext . getUuid ( ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; workGroup = threadService . create ( jane , jane , "work_group_name_1" ) ; workGroupFolder = new WorkGroupFolder ( new AccountMto ( jane ) , "folder1" , null , workGroup . getLsUuid ( ) ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; workGroup = threadService . create ( jane , jane , "work_group_name_1" ) ; workGroupFolder = new WorkGroupFolder ( new AccountMto ( jane ) , "folder1" , null , workGroup . getLsUuid ( ) ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ Test public void test3 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userDomainName ( "domain" ) . userName ( "user" ) ; Assertions . assertEquals ( "domain:user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test3 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userDomainName ( "domain" ) . userName ( "user" ) ; Assertions . assertEquals ( "domain:user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test4 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userName ( "user" ) ; Assertions . assertEquals ( "user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test4 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userName ( "user" ) ; Assertions . assertEquals ( "user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( ib . toString ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( "...done test9" ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testMissingPrivateKey ( ) throws InvalidKeySpecException , NoSuchAlgorithmException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; RSAPrivateKey key = PemRsaKeyHelper . loadPrivateKey ( pemPrivateKeyPath + "foo" ) ; assertEquals ( null , key ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testMissingPrivateKey ( ) throws InvalidKeySpecException , NoSuchAlgorithmException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; RSAPrivateKey key = PemRsaKeyHelper . loadPrivateKey ( pemPrivateKeyPath + "foo" ) ; assertEquals ( null , key ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ BeforeEach public void setUp ( ) throws Exception { log . debug ( "Initializing..." ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; init . init ( ) ; }
@ AfterEach public void tearDown ( ) throws Exception { logger . debug ( "Begin tearDown" ) ; mailingListRepository . delete ( mailingList1 ) ; mailingListRepository . delete ( mailingList2 ) ; accountRepository . delete ( internal ) ; logger . debug ( "End tearDown" ) ; }
@ AfterEach public void tearDown ( ) throws Exception { logger . debug ( "Begin tearDown" ) ; mailingListRepository . delete ( mailingList1 ) ; mailingListRepository . delete ( mailingList2 ) ; accountRepository . delete ( internal ) ; logger . debug ( "End tearDown" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Current policy : " + policy . toString ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Creating DomainAccessPolicy with the policy: " + policy . getClass ( ) . getName ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Current policy : " + policy . toString ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; domain = abstractDomainRepository . findById ( DOMAIN_IDENTIFIER ) ; internal = new Internal ( FIRST_NAME , LAST_NAME , MAIL , UID ) ; internal . setLocale ( domain . getDefaultTapestryLocale ( ) ) ; internal . setCmisLocale ( domain . getDefaultTapestryLocale ( ) . toString ( ) ) ; internal . setDomain ( domain ) ; accountRepository . create ( internal ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; domain = abstractDomainRepository . findById ( DOMAIN_IDENTIFIER ) ; internal = new Internal ( FIRST_NAME , LAST_NAME , MAIL , UID ) ; internal . setLocale ( domain . getDefaultTapestryLocale ( ) ) ; internal . setCmisLocale ( domain . getDefaultTapestryLocale ( ) . toString ( ) ) ; internal . setDomain ( domain ) ; accountRepository . create ( internal ) ; logger . debug ( "End setUp" ) ; }
private void printDocs ( User user ) { logger . debug ( "start" ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . debug ( "doc : " + ( ( DocumentEntry ) doc ) . getDocument ( ) . getUuid ( ) ) ; } } logger . debug ( "end" ) ; }
private void printDocs ( User user ) { logger . debug ( "begin : " + user . getLogin ( ) ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . info ( doc . toString ( ) ) ; } } logger . debug ( "end" ) ; }
private void printDocs ( User user ) { logger . debug ( "begin : " + user . getLogin ( ) ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . debug ( "doc : " + ( ( DocumentEntry ) doc ) . getDocument ( ) . getUuid ( ) ) ; } } logger . debug ( "end : " + user . getLogin ( ) ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; domain = domainRepository . findById ( LinShareTestConstants . TOP_DOMAIN ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; domain = domainRepository . findById ( LinShareTestConstants . TOP_DOMAIN ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ AfterEach public void tearDown ( ) throws Exception { LOG . info ( "Error count {}" , errors . get ( ) ) ; }
@ Test public void testFind ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; addStubingUuid ( ) ; SharedSpacePermission toFindPermission = service . findByUuid ( authUser , authUser , "31cb4d80-c939-40f1-a79e-4d77392e0e0b" ) ; Assertions . assertNotNull ( toFindPermission , "Permission has not been found." ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testFind ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; addStubingUuid ( ) ; SharedSpacePermission toFindPermission = service . findByUuid ( authUser , authUser , "31cb4d80-c939-40f1-a79e-4d77392e0e0b" ) ; Assertions . assertNotNull ( toFindPermission , "Permission has not been found." ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void findAllExistingDefaultRoles ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; List < SharedSpaceRole > toFindRoles = service . findAll ( authUser , authUser ) ; Assertions . assertNotNull ( toFindRoles , "Roles has not been not found" ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void findAllExistingDefaultRoles ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; List < SharedSpaceRole > toFindRoles = service . findAll ( authUser , authUser ) ; Assertions . assertNotNull ( toFindRoles , "Roles has not been not found" ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; root = userRepository . findByMail ( LinShareTestConstants . ROOT_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; root = userRepository . findByMail ( LinShareTestConstants . ROOT_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
private ActiveSyncRequest getActiveSyncRequest ( HttpServletRequest request ) { String qs = request . getQueryString ( ) ; if ( qs . contains ( "Cmd=" ) ) { return new SimpleQueryString ( request ) ; } else { InputStream is = null ; try { is = request . getInputStream ( ) ; } catch ( IOException e ) { log . error ( "Error occurred while fetching " + qs , e ) ; } return new Base64QueryString ( request , is ) ; } }
private void sendErrorResponse ( Responder responder , ItemOperationsProtocol protocol , ItemOperationsStatus status , Exception exception ) { logger . error ( exception . getMessage ( ) , exception ) ; responder . sendWBXMLResponse ( NAMESPACE , protocol . encodeErrorResponse ( status ) ) ; }
private void logError ( SyncStatus errorStatus , Exception exception ) { if ( errorStatus == SyncStatus . SERVER_ERROR ) { logger . error ( exception . getMessage ( ) ) ; } else { logger . warn ( exception . getMessage ( ) , exception ) ; } }
private void logError ( SyncStatus errorStatus , Exception exception ) { if ( errorStatus == SyncStatus . SERVER_ERROR ) { logger . error ( exception . getMessage ( ) , exception ) ; } else { logger . error ( exception . getMessage ( ) , exception ) ; } }
@ Override public void cancel ( User user , Device device ) { try { logger . info ( "canceling {} {}" , device , user ) ; IContinuation continuation = continuationTransactionMap . getContinuationForDevice ( user , device ) ; continuationTransactionMap . delete ( user , device ) ; continuation . resume ( ) ; } catch ( ElementNotFoundException e ) { logger . info ( "cancel device {} for user {} not found" , device , user ) ; } }
@ Override public void cancel ( User user , Device device ) { try { logger . info ( "cancel {} {}" , device , user ) ; IContinuation continuation = continuationTransactionMap . getContinuationForDevice ( user , device ) ; continuationTransactionMap . delete ( user , device ) ; continuation . resume ( ) ; } catch ( ElementNotFoundException e ) { logger . info ( "could not find continuation transaction for user {} for device {}" , user , device ) ; } }
private void logConfiguration ( ) { if ( ! isValidConfiguration ( ) ) { logger . error ( "{} configuration seems not valid, ldap connection will not be activated" , LDAP_CONF_FILE ) ; logger . info ( "LDAP configuration:n{}" , LDAP_CONF_FILE ) ; } }
private void logConfiguration ( ) { logger . info ( "LDAP configuration done, url={} basedn={} filter={} (valid conf={})" , url , baseDn , filter , isValidConfiguration ( ) ) ; if ( ! isValidConfiguration ( ) ) { logger . error ( "Failed to parse LDAP configuration: {}" , String . format ( "Invalid conf: %s" , baseDn ) ) ; } }
@ Test public void updateShouldProduceMeaningfulLogsWhenEmptyCQL ( ) { Version fromVersion = Version . of ( 1 ) ; Version toVersion = Version . of ( 2 ) ; String schema = "" ; expect ( schemaProducer . schema ( fromVersion , toVersion ) ) . andReturn ( schema ) ; logger . info ( "No CQL migration found from version {} to {}" , fromVersion . get ( ) , toVersion . get ( ) ) ; expectLastCall ( ) ; mocks . replay ( ) ; testee . migrate ( fromVersion , toVersion ) ; mocks . verify ( ) ; }
private TextBody appendRepliedTextMailToHtml ( TextBody htmlPart , String repliedEmail ) throws NotQuotableEmailException { try { Reader textAsHtmlReader = textToHtmlReader ( htmlPart . getReader ( ) ) ; return appendRepliedMailToHtml ( textAsHtmlReader , Charset . forName ( htmlPart . getMimeCharset ( ) ) , repliedEmail ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new NotQuotableEmailException ( "Html part isn't quotable" , e ) ; } }
@ Override public SMTPProtocol getSmtpClient ( UserDataRequest udr ) throws SmtpLocatorException { try { String smtpHost = locatorService . getServiceLocation ( "mail/smtp_out" , udr . getUser ( ) . getLoginAtDomain ( ) ) ; SMTPProtocol proto = new SMTPProtocol ( smtpHost ) ; logger . debug ( "Smtp server received: " + proto ) ; return proto ; } catch ( OpushLocatorException e ) { throw new SmtpLocatorException ( "Smtp server cannot be discovered" , e ) ; } }
private void setSmtpRcpts ( SMTPProtocol smtp , org . columba . ristretto . message . Address [ ] rcpts ) { for ( org . columba . ristretto . message . Address rcpt : rcpts ) { try { smtp . rcpt ( rcpt ) ; } catch ( SMTPException e ) { logger . warn ( "unknown rcpt: {}" , rcpt ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } } }
private void setSmtpRcpts ( SMTPProtocol smtp , org . columba . ristretto . message . Address [ ] rcpts ) { for ( org . columba . ristretto . message . Address rcpt : rcpts ) { try { smtp . rcpt ( rcpt ) ; } catch ( SMTPException e ) { logger . error ( "Bad sender address syntax {from:" + rcpt . getMailAddress ( ) + "}" , e ) ; } catch ( IOException e ) { logger . error ( "Error when setting smtp rcpt: {}" , e . getLocalizedMessage ( ) , e ) ; } } }
private void quit ( SMTPProtocol smtp ) throws SMTPException { try { if ( smtp != null ) { smtp . quit ( ) ; } } catch ( IOException e ) { LOGGER . error ( "Error on quit: " + e . getMessage ( ) ) ; } }
@ Override public void lifeCycleStopped ( LifeCycle event ) { LOGGER . info ( Messages . getString ( "jetty.stopped.notification" ) ) ; }
protected void startApplicationContext ( ) { LOGGER . info ( "starting spring application context..." ) ; config . startApplicationContext ( ) ; LOGGER . info ( "spring application context started" ) ; }
protected void startApplicationContext ( ) { LOGGER . info ( "starting spring application context..." ) ; config . startApplicationContext ( ) ; LOGGER . info ( "spring application context started" ) ; }
protected String getResource ( String resource ) { _log . info ( "getResource" ) ; if ( getResourcesMap ( ) . containsKey ( resource ) ) { return getResourcesMap ( ) . get ( resource ) ; } else { throw new NextProtException ( "Resource " + resource + " not found on a total of " + getResourcesMap ( ) . size ( ) + " resources" ) ; } }
public static void main ( String [ ] args ) { try { new PeffServiceValidatorTask ( args ) . run ( ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; log . error ( e . getMessage ( ) ) ; System . exit ( 1 ) ; } }
@ ResponseStatus ( HttpStatus . FORBIDDEN ) @ ExceptionHandler ( NotAuthorizedException . class ) @ ResponseBody public RestErrorResponse handle ( NotAuthorizedException ex ) { LOGGER . warn ( "NotAuthorizedException occurred: " + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . FORBIDDEN ) @ ExceptionHandler ( ConcurrentRequestsException . class ) @ ResponseBody public RestErrorResponse handle ( ConcurrentRequestsException ex ) { LOGGER . warn ( "Exception in ConcurrentRequestsAction: " + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . NOT_FOUND ) @ ExceptionHandler ( DataAccessException . class ) @ ResponseBody public RestErrorResponse handle ( DataAccessException ex ) { LOGGER . warn ( "Data access exception " + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . UNAUTHORIZED ) @ ExceptionHandler ( AccessDeniedException . class ) @ ResponseBody public RestErrorResponse handle ( AccessDeniedException ex ) { LOGGER . warn ( "Access denied" , ex ) ; return getResponseError ( ex ) ; }
@ Override public void clearRepository ( ) { File repo = new File ( REPOSITORY_PATH ) ; if ( repo . exists ( ) ) { File [ ] files = repo . listFiles ( ) ; if ( files != null ) { for ( File file : files ) { logger . info ( "Deleting {}" , file . getName ( ) ) ; file . delete ( ) ; } } } }
public void run ( ) { LOG . trace ( "Executing shutdown hook..." ) ; shutdown ( ) ; }
public void warn ( final Object ... args ) { if ( logger_ . isWarnEnabled ( ) ) { logger_ . warn ( process ( args ) ) ; } }
@ Override public void error ( final Object message ) { log . error ( m ( message ) ) ; }
@ Override public final String getSrcAttribute ( ) { final String src = getSrcAttributeNormalized ( ) ; if ( ATTRIBUTE_NOT_DEFINED == src ) { return src ; } final HtmlPage page = getHtmlPageOrNull ( ) ; if ( page != null ) { try { return page . getFullyQualifiedUrl ( src ) . toExternalForm ( ) ; } catch ( final MalformedURLException e ) { LOG . warn ( "Unexpected error creating full url from src tag" , e ) ; } } return src ; }
@ Override public void onAllChildrenAddedToPage ( final boolean postponed ) { if ( getOwnerDocument ( ) instanceof XmlPage ) { return ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "onAllChildrenAddedToPage(): classId=" + getClassIdAttribute ( ) + " was added to the XML document" ) ; } final String clsId = getClassIdAttribute ( ) ; if ( ATTRIBUTE_NOT_DEFINED != clsId && getPage ( ) . getWebClient ( ) . isJavaScriptEngineEnabled ( ) ) { ( ( HTMLObjectElement ) getScriptableObject ( ) ) . setClassid ( clsId ) ; } }
@ Override public void warning ( final String message , final URL url , final String html , final int line , final int column , final String key ) { LOG . warn ( format ( message , url , html , line , column ) ) ; }
@ Override public void closePath ( ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "[" + id_ + "] closePath()" ) ; } if ( subPaths_ . isEmpty ( ) ) { return ; } subPaths_ . get ( subPaths_ . size ( ) - 1 ) . closePath ( ) ; }
private void open ( final OpenMode openMode , final String urlTemplateName , final String [ ] parameterValues ) { String startingUrl = pageUrls . getNamedUrl ( urlTemplateName , parameterValues ) ; LOGGER . debug ( "Opening page at url {}" , startingUrl ) ; openPageAtUrl ( startingUrl ) ; checkUrlPatterns ( openMode ) ; initializePage ( ) ; LOGGER . debug ( "Page opened" ) ; }
private void open ( final OpenMode openMode , final String urlTemplateName , final String [ ] parameterValues ) { String startingUrl = pageUrls . getNamedUrl ( urlTemplateName , parameterValues ) ; LOGGER . debug ( "Opening page at url {}" , startingUrl ) ; openPageAtUrl ( startingUrl ) ; checkUrlPatterns ( openMode ) ; initializePage ( ) ; LOGGER . debug ( "Page opened" ) ; }
public void stepStarted ( ExecutedStepDescription description ) { if ( loggingLevelIsAtLeast ( getLoggingLevel ( ) . VERBOSE ) ) { getLogger ( ) . info ( "STARTED STEP: " + description . getStepName ( ) ) ; } }
public void stepPending ( String message ) { if ( loggingLevelIsAtLeast ( getLoggingLevel ( ) . VERBOSE ) ) { getLogger ( ) . info ( message ) ; } }
private Object runSkippedMethod ( Object obj , Method method , Object [ ] args , MethodProxy proxy ) { Object result = null ; StepEventBus . getEventBus ( ) . temporarilySuspendWebdriverCalls ( ) ; result = runIfNestedMethodsShouldBeRun ( obj , method , args , proxy ) ; StepEventBus . getEventBus ( ) . reenableWebdriverCalls ( ) ; logger . debug ( "Skipped method {} due to {}" , method . getName ( ) , result ) ; return result ; }
public void testStarted ( String description ) { int currentTestCount = testCount . getNextTest ( ) ; if ( loggingLevelIsAtLeast ( LoggingLevel . NORMAL ) ) { getLogger ( ) . info ( testStartedHeadings ( ) + "nTEST STARTED: " + currentTestCount + "nTESTED: " + testCount ) ; } }
@ Override public void fireTestIgnored ( Description description ) { log . debug ( "Test ignored: " + description ) ; lastIgnored = description ; if ( ! testStartAlreadyFired ) { super . fireTestStarted ( description ) ; } testStartAlreadyFired = false ; retryAwareRunNotifier . fireTestIgnored ( description ) ; }
@ Step public void enter_name_and_age ( String name , String age ) { logger . debug ( "Entering name/values name/duplicate: {} = {}" , name , age ) ; }
protected Schema < ? > getSchemaAdditionalProperties ( Schema schema ) { Schema < ? > inner = getAdditionalProperties ( schema ) ; if ( inner == null ) { inner = new StringSchema ( ) . description ( "TODO default missing map inner type to string" ) ; schema . setAdditionalProperties ( inner ) ; LOG . error ( "Undefined map inner type for `{}`. Default to String." , schema . getName ( ) ) ; } return inner ; }
public void postProcessFile ( File file , String fileType ) { logger . info ( "Processing file: " + file . getName ( ) + "..." ) ; }
@ Override public String toOperationId ( String operationId ) { if ( isReservedWord ( operationId ) ) { String newOperationId = underscore ( "call_" + operationId ) ; LOGGER . warn ( operationId + " (reserved word) cannot be used as method name. Renamed to " + newOperationId ) ; return newOperationId ; } return underscore ( operationId ) ; }
@ Override public void processOpts ( ) { super . processOpts ( ) ; if ( additionalProperties . containsKey ( MICROCONTROLLER ) ) { controller = additionalProperties . get ( MICROCONTROLLER ) . toString ( ) ; } addControllerToAdditionalProperties ( ) ; log . info ( "MICROCONTROLLER: {}" , controller ) ; }
@ Override public String toModelName ( String name ) { if ( ! StringUtils . isEmpty ( modelNamePrefix ) ) { name = modelNamePrefix + "_" + name ; } if ( ! StringUtils . isEmpty ( modelNameSuffix ) ) { name = name + "_" + modelNameSuffix ; } name = sanitizeName ( name ) ; if ( isReservedWord ( name ) ) { LOGGER . warn ( name + " (reserved word) cannot be used as model name. Renamed to " + camelize ( "model_" + name ) ) ; name = "model_" + name ; } return camelize ( name ) ; }
@ Override public void processOpts ( ) { super . processOpts ( ) ; if ( additionalProperties . containsKey ( OUTPUT_NAME ) ) { outputFileName = additionalProperties . get ( OUTPUT_NAME ) . toString ( ) ; LOGGER . info ( "Output file: {}" , outputFileName ) ; } }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "HTTP Method: " + request . getMethod ( ) ) ; log . info ( "Method Name: " + request . getDeclaringMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "Method: " + request . getMethod ( ) ) ; log . info ( "Headers: " + request . getHeaders ( ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request body: " + new String ( body , "UTF-8" ) ) ; }
@ Test ( ) @ MethodOwner ( owner = "qpsdemo" ) public void helloWorld ( ) { LOGGER . info ( VersionReader . getWelcomeMessage ( ) ) ; }
private File getTlsConfigDirectoryByPath ( String path ) { File directory = new File ( path ) ; if ( directory != null && directory . exists ( ) ) { LOGGER . info ( "Tls config directory found: " + directory . getAbsolutePath ( ) ) ; return directory ; } else { throw new RuntimeException ( "Directory doesn't exist: " + directory . getAbsolutePath ( ) ) ; } }
@ Override public void onConfigurationFailure ( ITestResult result ) { LOGGER . debug ( "AbstractTestListener->onConfigurationFailure" ) ; super . onConfigurationFailure ( result ) ; }
@ Override public void onTestFailure ( ITestResult result ) { LOGGER . debug ( "AbstractTestListener->onTestFailure" ) ; failItem ( result , Messager . TEST_FAILED ) ; afterTest ( result ) ; super . onTestFailure ( result ) ; }
@ Override public void onConfigurationFailure ( ITestResult result ) { LOGGER . debug ( "AbstractTestListener->onConfigurationFailure" ) ; super . onConfigurationFailure ( result ) ; }
@ Test @ TestRailCases ( testCasesId = TEST_ID ) public void testTestRailList ( ) { ITestResult result = Reporter . getCurrentTestResult ( ) ; Set < String > testRailUdids = getTestRailCasesUuid ( result ) ; Assert . assertTrue ( testRailUdids . contains ( EXPECTED_TEST_ID ) , "TestRail should contain id=" + EXPECTED_TEST_ID ) ; Assert . assertEquals ( testRailUdids . size ( ) , 3 ) ; LOGGER . info ( "TestRail list: " + testRailUdids . toString ( ) ) ; }
public static String setTestName ( String name ) { testName . set ( name ) ; log . info ( "Setting test name " + name ) ; return testName . get ( ) ; }
public static synchronized void start ( IPerformanceOperation operation , String key ) { String operationKey = operation . getKey ( ) + key ; Map < String , Long > testTimer = getTimer ( ) ; if ( testTimer . containsKey ( operationKey ) ) { log . warn ( "Operation " + operationKey + " already started." ) ; } else { testTimer . put ( operationKey , Calendar . getInstance ( ) . getTimeInMillis ( ) ) ; } }
public static synchronized void removeTempDir ( ) { if ( tempDirectory != null ) { try { FileUtils . deleteDirectory ( tempDirectory ) ; } catch ( IOException e ) { LOG . warn ( "Failed to delete temporary directory: {}" , tempDirectory ) ; } } }
private static String getUrl ( WebDriver driver , String name ) { String seleniumHost = Configuration . getSeleniumUrl ( ) . replace ( "wd/hub" , "download/" ) ; WebDriver drv = ( driver instanceof EventFiringWebDriver ) ? ( ( EventFiringWebDriver ) driver ) . getWrappedDriver ( ) : driver ; String sessionId = ( ( RemoteWebDriver ) drv ) . getSessionId ( ) . toString ( ) ; String url = seleniumHost + sessionId + "/" + name ; logger . debug ( "Opened url {} for session {} " , url , seleniumHost ) ; return url ; }
public static void setBuild ( String build ) { R . CONFIG . put ( Parameter . APP_VERSION . getKey ( ) , build ) ; if ( ! build . isEmpty ( ) ) { log . info ( "Setting build {} as: {}" , build , build ) ; CurrentTestRun . setBuild ( build ) ; } }
public static boolean isDaylightTime ( String tz ) { try { return DateTimeZone . forID ( tz ) . toTimeZone ( ) . observesDaylightTime ( ) ; } catch ( Exception e ) { LOGGER . error ( e . getMessage ( ) , e ) ; return false ; } }
@ SuppressWarnings ( "unchecked" ) public < T > T unmarshall ( String string , Class < T > resultClazz ) { try { return ( T ) getUnmarshaller ( resultClazz ) . unmarshal ( new ByteArrayInputStream ( string . getBytes ( ) ) ) ; } catch ( JAXBException e ) { LOGGER . error ( e . getMessage ( ) , e ) ; throw new RuntimeException ( e ) ; } }
private static void collectURL ( ResourceURLFilter f , Set < URL > s , URL u ) { if ( f == null || f . accept ( u ) ) { log . debug ( "Accepting {}: {}" , f . getClass ( ) . getName ( ) , u ) ; s . add ( u ) ; } }
public static String stringResponse ( Response response ) { String strResponse = null ; try { strResponse = response . asString ( ) ; } catch ( Throwable thr ) { LOG . warn ( "Response as string failed, Error: " + thr . getMessage ( ) ) ; } return strResponse ; }
public WebDriver getDriver ( ) { if ( driver == null ) { long currentThreadId = Thread . currentThread ( ) . getId ( ) ; LOG . error ( "Error getting driver for thread" , new Throwable ( "Error" ) ) ; throw new RuntimeException ( "Driver isn't initialized." ) ; } return driver ; }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . info ( "Triggering firing of a webdriver" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( "Webdriver exception has been fired. One more attempt to execute action." , e ) ; LOGGER . info ( supplier . toString ( ) ) ; return supplier . get ( ) ; } }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . debug ( "Command will be performed with the exception ignoring" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( e . getMessage ( ) ) ; LOGGER . info ( supplier . toString ( ) ) ; return supplier . get ( ) ; } }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . debug ( "Command will be performed with the exception ignoring" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( "Webdriver exception has been fired. One more attempt to execute action." , e ) ; LOGGER . info ( "Cause: " , e ) ; return supplier . get ( ) ; } }
public static void switchBackAfterPopup ( WebDriver driver ) { try { Set < String > beforeHandles = windows . get ( ( driver ) . hashCode ( ) ) ; String newWindowHandle = beforeHandles . iterator ( ) . next ( ) ; driver . switchTo ( ) . window ( newWindowHandle ) ; } catch ( Exception e ) { LOGGER . warn ( "Switching back after an error was thrown from JavaScript execution" , e ) ; } }
public WebDriver getDriver ( ) { if ( driver == null ) { throw new RuntimeException ( "Driver isn't initialized. Review stacktrace to analyze why driver is not populated correctly via reflection!" ) ; } LOGGER . debug ( "Driver isn't loaded. [Product=({})]" , driver ) ; return driver ; }
public void disconnectRemote ( ) { if ( ! isAdbEnabled ) return ; if ( isNull ( ) ) return ; log . info ( "disconnecting to {}." , getRemoteURL ( ) ) ; String [ ] cmd = CmdLine . insertCommandsAfter ( executor . getDefaultCmd ( ) , "disconnect" , getRemoteURL ( ) ) ; executor . execute ( cmd ) ; isAdbEnabled = false ; }
public String getApkPackageName ( String apkFile ) { String packageName = "" ; String [ ] cmd = CmdLine . insertCommandsAfter ( "aapt dump badging" . split ( " " ) , apkFile ) ; List < String > output = executor . execute ( cmd ) ; for ( String line : output ) { if ( line . contains ( "versionCode" ) && line . contains ( "versionName" ) ) { String [ ] outputs = line . split ( "'" ) ; packageName = outputs [ 1 ] ; } } LOGGER . info ( "Package name is: " + packageName ) ; return packageName ; }
@ Override protected void onDestroy ( ) { if ( repository instanceof RepositoryImpl ) { logger . debug ( "Shutting down repository {}" , repository . getSlug ( ) ) ; ( ( RepositoryImpl ) repository ) . shutdown ( ) ; } super . onDestroy ( ) ; }
@ Override public void run ( ) { try { if ( newBlockType == NewBlockType . BEST_CHAIN ) registration . listener . notifyNewBestBlock ( newStoredBlock ) ; } catch ( VerificationException e ) { log . error ( "Error notifying new best block: " + e . getMessage ( ) , e ) ; } }
public static Context getOrCreate ( NetworkParameters params ) { Context context ; try { context = get ( ) ; } catch ( IllegalStateException e ) { LOGGER . warn ( "Context does not match implicit network params: " + context . getParams ( ) + " vs " + params ) ; context = new Context ( params ) ; return context ; } if ( context . getParams ( ) != params ) throw new IllegalStateException ( "Context does not match implicit network params: " + context . getParams ( ) + " vs " + params ) ; return context ; }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . trace ( "Signature valid" ) ; } else { log . warn ( "Received alert with invalid signature from peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . info ( "Received alert from peer {}: {}" , this , m . getStatusBar ( ) ) ; } else { log . error ( "Signature validation failed for peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . info ( "Received alert from peer {}: {}" , this , m . getStatusBar ( ) ) ; } else { log . warn ( "Received alert with invalid signature from peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
private void exceptionCaught ( Exception e ) { PeerAddress addr = getAddress ( ) ; String s = addr == null ? "?" : addr . toString ( ) ; if ( e instanceof ConnectException || e instanceof IOException ) { log . error ( s + " - " + e . getMessage ( ) ) ; } else { log . warn ( s + " - " , e ) ; Thread . UncaughtExceptionHandler handler = Threading . uncaughtExceptionHandler ; if ( handler != null ) handler . uncaughtException ( Thread . currentThread ( ) , e ) ; } close ( ) ; }
private void exceptionCaught ( Exception e ) { PeerAddress addr = getAddress ( ) ; String s = addr == null ? "?" : addr . toString ( ) ; if ( e instanceof ConnectException || e instanceof IOException ) { log . info ( s + " - " + e . getMessage ( ) ) ; } else { log . error ( s , e ) ; Thread . UncaughtExceptionHandler handler = Threading . uncaughtExceptionHandler ; if ( handler != null ) handler . uncaughtException ( Thread . currentThread ( ) , e ) ; } close ( ) ; }
@ Override protected void timeoutOccurred ( ) { log . info ( "{}: Timed out" , getAddress ( ) ) ; closeConnection ( ) ; }
@ Override public void settle ( ) throws IllegalStateException { lock . lock ( ) ; try { checkState ( connectionOpen ) ; step = InitStep . WAITING_FOR_CHANNEL_CLOSE ; log . info ( "channel {} closed" , connection ) ; conn . sendToServer ( Protos . TwoWayChannelMessage . newBuilder ( ) . setType ( Protos . TwoWayChannelMessage . MessageType . CLOSE ) . build ( ) ) ; } finally { lock . unlock ( ) ; } }
@ Override public void onSuccess ( Transaction transaction ) { log . info ( "Successfully broadcast multisig contract {}. Channel now open." , transaction . getTxId ( ) ) ; try { wallet . receivePending ( contract , null , true ) ; } catch ( VerificationException e ) { throw new RuntimeException ( e ) ; } stateMachine . transition ( State . READY ) ; future . set ( PaymentChannelServerState . this ) ; }
public void addAndActivateHDChain ( DeterministicKeyChain chain ) { for ( ListenerRegistration < KeyChainEventListener > registration : basic . getListeners ( ) ) chain . addEventListener ( registration . listener , registration . executor ) ; if ( lookaheadSize >= 0 ) chain . setLookaheadSize ( lookaheadSize ) ; if ( lookaheadThreshold >= 0 ) chain . setLookaheadThreshold ( lookaheadThreshold ) ; chains . add ( chain ) ; logger . info ( "Registering HD chain, and re-enable lookaheadThreshold:" + lookaheadThreshold ) ; }
@ Override public void onFailure ( Throwable throwable ) { LOG . error ( "Failed to read SFFs from data store runAddOvsdbAugmentations." ) ; }
@ Override public void onCoinsReceived ( Wallet wallet , Transaction tx , Coin prevBalance , Coin newBalance ) { log . info ( "onCoinsReceived 2" ) ; throw new RuntimeException ( "barf" ) ; }
protected < T , E extends Throwable > T callWithRuntimeAndChecking ( final PluginCallback < T , E > cb ) throws E { try { checkPluginIsRunning ( ) ; final Ruby runtime = getRuntime ( ) ; return cb . doCall ( runtime ) ; } catch ( final RuntimeException e ) { log . error ( "Plugin execution failed" , e ) ; throw e ; } }
public void check ( final ServletContext servletContext ) { if ( shouldSkipUpdateCheck ( ) ) { log . info ( "Skip update check as no update check is needed" ) ; return ; } final Thread t = new Thread ( ) { @ Override public void run ( ) { try { doCheck ( servletContext ) ; } catch ( final IOException e ) { log . debug ( "Unable to perform update check" , e ) ; } } } ; t . setDaemon ( true ) ; t . start ( ) ; }
public void check ( final ServletContext servletContext ) { log . info ( "For Kill Bill Commercial Support, visit http://thebillingproject.com or send an email to support@thebillingproject.com" ) ; if ( shouldSkipUpdateCheck ( ) ) { return ; } final Thread t = new Thread ( ) { @ Override public void run ( ) { try { doCheck ( servletContext ) ; } catch ( final IOException e ) { log . error ( "Exception while checking for Kill Bill check." , e ) ; } } } ; t . setDaemon ( true ) ; t . start ( ) ; }
@ LifecycleHandlerType ( LifecycleLevel . LOAD_CATALOG ) public synchronized void loadCatalog ( ) throws ServiceException { if ( ! isInitialized ) { try { if ( config . getCatalogURI ( ) != null && ! config . getCatalogURI ( ) . isEmpty ( ) ) { catalogCache . loadDefaultCatalog ( config . getCatalogURI ( ) ) ; } isInitialized = true ; } catch ( final Exception e ) { LOG . error ( "Failed to load catalog from catalog cache" , e ) ; throw new ServiceException ( e ) ; } } }
@ AllowConcurrentEvents @ Subscribe public void handlePaymentInfoEvent ( final InvoicePaymentInfoInternalEvent event ) { if ( busDispatcherOptimizer . shouldDispatch ( event ) ) { log . debug ( "Received InvoicePaymentInfo event {}" , event ) ; insertBusEventIntoNotificationQueue ( event . getAccountId ( ) , event ) ; } }
public void startTestFramework ( final TestApiListener testListener , final ClockMock clock , final BusService busService , final SubscriptionBaseService subscriptionBaseService ) throws Exception { log . debug ( "STARTING TEST FRAMEWORK" ) ; resetTestListener ( testListener ) ; resetClockToStartOfTest ( clock ) ; startBusAndRegisterListener ( busService , testListener ) ; restartSubscriptionService ( subscriptionBaseService ) ; log . debug ( "STARTED TEST FRAMEWORK" ) ; }
public void startTestFramework ( final TestApiListener testListener , final ClockMock clock , final BusService busService , final SubscriptionBaseService subscriptionBaseService ) throws Exception { log . debug ( "STARTING TEST FRAMEWORK" ) ; resetTestListener ( testListener ) ; resetClockToStartOfTest ( clock ) ; startBusAndRegisterListener ( busService , testListener ) ; restartSubscriptionService ( subscriptionBaseService ) ; log . debug ( "STARTED TEST FRAMEWORK" ) ; }
public void printEvents ( final List < SubscriptionBaseEvent > events ) { for ( final SubscriptionBaseEvent cur : events ) { log . info ( "cur: " + cur ) ; } }
@ Override public void invalidateCache ( final TenantKey key , final Object cookie , final InternalTenantContext tenantContext ) { logger . debug ( "Invalidating cache for tenant {}" , tenantContext . getName ( ) ) ; cacheConfig . clearPerTenantConfig ( tenantContext ) ; }
@ Override public Object execute ( ) throws Throwable { logger . debug ( "Entering API call {}, arguments: {}" , invocation . getMethod ( ) , invocation . getArguments ( ) ) ; final Object proceed = invocation . proceed ( ) ; logger . debug ( "Exiting API call {}, returning: {}" , invocation . getMethod ( ) , proceed ) ; return proceed ; }
@ Override public Object execute ( ) throws Throwable { logger . debug ( "Entering API call {}, arguments: {}" , invocation . getMethod ( ) , invocation . getArguments ( ) ) ; final Object proceed = invocation . proceed ( ) ; logger . debug ( "Exiting API call {}, returning: {}" , invocation . getMethod ( ) , proceed ) ; return proceed ; }
@ LifecycleHandlerType ( LifecycleLevel . START_SERVICE ) public void start ( ) { try { createBootNodeInfo ( false ) ; } catch ( JsonProcessingException e ) { logger . error ( "Failed to create bootNodeInfo" , e ) ; } }
private boolean isAuthenticated ( final Response oktaRawResponse ) { try { final Map oktaResponse = mapper . readValue ( oktaRawResponse . getResponseBodyAsStream ( ) , Map . class ) ; if ( "SUCCESS" . equals ( oktaResponse . get ( "status" ) ) ) { return true ; } else { log . warn ( "Unable to read response from Okta" ) ; return false ; } } catch ( final IOException e ) { log . warn ( "Unable to read response from Okta" ) ; throw new AuthenticationException ( e ) ; } }
private boolean isAuthenticated ( final Response oktaRawResponse ) { try { final Map oktaResponse = mapper . readValue ( oktaRawResponse . getResponseBodyAsStream ( ) , Map . class ) ; if ( "SUCCESS" . equals ( oktaResponse . get ( "status" ) ) ) { return true ; } else { log . warn ( "Okta authentication failed: " + oktaResponse ) ; return false ; } } catch ( final IOException e ) { log . error ( "Not a CMS authentication failed" , e ) ; throw new AuthenticationException ( e ) ; } }
@ Subscribe public void handlePaymentEvents ( final PaymentInfoInternalEvent event ) { log . info ( String . format ( "Got PaymentInfo event %s" , event . toString ( ) ) ) ; assertEqualsNicely ( NextEvent . PAYMENT ) ; notifyIfStackEmpty ( ) ; }
@ Override protected void before ( ) throws Throwable { System . setProperty ( "cuba.unitTestMode" , "true" ) ; initAppComponents ( ) ; initAppProperties ( ) ; for ( Map . Entry < String , String > entry : appProperties . entrySet ( ) ) { AppContext . setProperty ( entry . getKey ( ) , entry . getValue ( ) ) ; } initDataSources ( ) ; initPersistenceConfig ( ) ; initAppContext ( ) ; logger . info ( "Database metaData metaData before" ) ; }
@ Override public void debug ( String msg , Throwable throwable ) { LOGGER . debug ( msg , throwable ) ; }
@ Override public void trace ( String msg , Throwable throwable ) { logger . trace ( msg , throwable ) ; }
@ Override public void unlock ( String name , String id ) { LockInfo lockInfo = locks . remove ( new LockKey ( name , id ) ) ; if ( lockInfo != null ) { LOG . debug ( "sending unlock request to cluster with id [{}] in [{}]" , id , name ) ; clusterManager . send ( new LockInfo ( null , name , id ) ) ; } }
@ Override public boolean primitiveParameters ( boolean b , int i , long l , double d ) { logger . info ( "Method " + Thread . currentThread ( ) . getStackTrace ( ) [ 1 ] . getMethodName ( ) + " not implemented" ) ; return b ; }
@ Override public String start ( ) { try { clusterManager . start ( ) ; return "Done" ; } catch ( Throwable e ) { log . error ( "Unable to start the cluster" , e ) ; return ExceptionUtils . getStackTrace ( e ) ; } }
protected void logError ( Entity entity , Exception e ) { LOG . error ( "Error while loading " + entity + ": " + e , e ) ; }
@ Override public void remove ( UserSession session ) { UserSessionInfo usi = removeSessionInfo ( session . getId ( ) ) ; if ( usi != null ) { if ( ! session . isSystem ( ) ) { log . debug ( "Removing: {}" , usi ) ; usi . lastUsedTs = 0 ; clusterManager . send ( usi ) ; } } }
private void loadLayoutSettings ( DesktopThemeImpl theme , Element element ) { try { String margin = element . attributeValue ( "margin-size" ) ; if ( margin != null ) { theme . setMarginSize ( Integer . valueOf ( margin ) ) ; } String spacing = element . attributeValue ( "spacing-size" ) ; if ( spacing != null ) { theme . setSpacingSize ( Integer . valueOf ( spacing ) ) ; } } catch ( NumberFormatException e ) { log . error ( "Error on setting color value: " + e . getMessage ( ) , e ) ; } }
protected void saveFile ( ) { FileUploadingAPI fileUploading = AppBeans . get ( FileUploadingAPI . NAME ) ; try { fileUploading . putFileIntoStorage ( uploadField . getFileId ( ) , fileDs . getItem ( ) ) ; } catch ( FileStorageException e ) { log . error ( "Error while saving file" , e ) ; showNotification ( getMessage ( "fileEditor.unableToSaveFile" ) , NotificationType . ERROR ) ; } }
protected void fireItemChanged ( E prevItem ) { if ( ! listenersEnabled ) { return ; } ItemChangeEvent < E > itemChangeEvent = new ItemChangeEvent < > ( this , prevItem , getItemOrNull ( ) ) ; log . trace ( "collectionChanged: {}" , itemChangeEvent ) ; events . publish ( ItemChangeEvent . class , itemChangeEvent ) ; }
protected void checkInitialized ( ) { if ( ! initialized ) { synchronized ( this ) { if ( ! initialized ) { log . info ( "Initializing views" ) ; init ( ) ; initialized = true ; } } } }
@ Override public void beforeEach ( ExtensionContext extensionContext ) throws Exception { try { before ( ) ; } catch ( Throwable throwable ) { log . error ( "TestContainer extension initialization failed." , throwable ) ; } }
@ Override public void closeTab ( Component target ) { CubaUI ui = ( CubaUI ) tabSheet . getUI ( ) ; if ( ! ui . isAccessibleForUser ( tabSheet ) ) { LoggerFactory . getLogger ( CubaTabSheet . class ) . debug ( "Ignore close tab attempt because TabSheet is inaccessible for user" ) ; return ; } tabSheet . closeTab ( target ) ; }
@ Override public void closeOtherTabs ( Component target ) { CubaUI ui = ( CubaUI ) tabSheet . getUI ( ) ; if ( ! ui . isAccessibleForUser ( tabSheet ) ) { LoggerFactory . getLogger ( CubaMainTabSheet . class ) . debug ( "Ignore close tab attempt because TabSheet is inaccessible for user" ) ; return ; } tabSheet . closeOtherTabs ( target ) ; }
@ Override public String getStyle ( com . vaadin . v7 . ui . Table source , Object itemId , Object propertyId ) { if ( exceptionHandled ) { return null ; } try { return generateCellStyle ( itemId , propertyId ) ; } catch ( Exception e ) { log . error ( "Error generating cell style for item {}: {}" , itemId , e . getMessage ( ) , e ) ; this . exceptionHandled = true ; return null ; } }
@ Override public String getLocalNodeName ( ) { String hostName ; try { hostName = System . getProperty ( RMI_SERVER_HOSTNAME_SYSTEM_PROPERTY , InetAddress . getLocalHost ( ) . getHostName ( ) ) ; } catch ( UnknownHostException e ) { logger . warn ( e . getMessage ( ) , e ) ; hostName = "<unknown-host>" ; } String jmxPort = System . getProperty ( JMX_PORT_SYSTEM_PROPERTY , "<unknown-port>" ) ; return String . format ( "<local> (%s:%s)" , hostName , jmxPort ) ; }
protected void initializeAnonymousSession ( ) { try { this . session = getAnonymousSessionFromService ( ) ; log . debug ( "Anonymous session loaded with id {}" , session . getId ( ) ) ; } catch ( LoginException e ) { log . error ( "Unable to obtain anonymous session from middleware" , e ) ; throw new RuntimeException ( "Unable to obtain anonymous session from middleware" , e ) ; } }
protected void initializeAnonymousSession ( ) { log . debug ( "Loading anonymous session" ) ; try { this . session = getAnonymousSessionFromService ( ) ; } catch ( LoginException e ) { log . error ( "Unable to obtain anonymous session from middleware" , e ) ; throw new RuntimeException ( "Unable to obtain anonymous session from middleware" , e ) ; } }
public void replaceState ( String navigationState , UI ui ) { checkNotNullArgument ( navigationState , "Navigation state cannot be null" ) ; if ( headless ( ) ) { log . debug ( "Unable to replace navigation state in headless mode" ) ; return ; } String state = ! navigationState . isEmpty ( ) ? "#" + navigationState : "" ; Page page = ui . getPage ( ) ; if ( ! state . isEmpty ( ) ) { page . replaceState ( state ) ; } else { page . replaceState ( getEmptyFragmentUri ( page ) ) ; } }
public Object getVariable ( String key ) { Object o = variables . get ( key ) ; if ( o == null ) { logger . warn ( "No variable found with key " + key ) ; } return o ; }
public static final void warn ( Object message ) { logger . warn ( addURLSuffix ( "WARNING " + message ) ) ; }
private ShortcutInfoDTO unSerializeShortcutInfo ( File jsonFile ) { try { return this . objectMapper . readValue ( jsonFile , ShortcutInfoDTO . class ) ; } catch ( IOException e ) { LOGGER . debug ( "JSON file not found" , e ) ; return new ShortcutInfoDTO . Builder ( ) . build ( ) ; } }
public int update ( String statement , Object ... params ) { Connection conn = connInTrans . get ( ) ; try { if ( conn == null ) { return queryRunner . update ( statement , params ) ; } else { return queryRunner . update ( conn , statement , params ) ; } } catch ( Exception ex ) { logger . error ( "Update failed. statement={}, params={}" , statement , params , ex ) ; throw ExceptionUtils . wrapIfChecked ( ex ) ; } }
public PullProcessVO pullDataset ( Long datasetId ) { String fullUrl = url + "/datasets/{id}/_pull" ; log . info ( "Request url : " + fullUrl ) ; return restTemplate . postForEntity ( fullUrl , null , PullProcessVO . class , datasetId ) . getBody ( ) ; }
public PullProcessVO pullDataSource ( Long datasourceId ) { String fullUrl = url + "/datasources/{id}/_pull" ; log . info ( "Will send a pull request to [{}]" , datasourceId ) ; return restTemplate . postForEntity ( fullUrl , null , PullProcessVO . class , datasourceId ) . getBody ( ) ; }
public static JsonNode stringToJson ( String jsonStr ) { try { return objectMapper . readTree ( jsonStr ) ; } catch ( JsonProcessingException e ) { logger . error ( "Error occurs when converting string to JSON string: " , e ) ; throw ExceptionUtils . wrapIfChecked ( e ) ; } }
private void sendMseEvent ( LoadSchemaResult loadSchemaResult ) { try { MetadataStatisticsEvent mse = new MetadataStatisticsEvent ( MetadataStatisticsEvent . EventType . FIELD , loadSchemaResult . getGid ( ) , loadSchemaResult . getSnapshotId ( ) ) ; httpClientUtil . doPost ( props . getString ( MSE_URL ) , JSONUtils . toJsonString ( mse ) ) ; } catch ( Exception e ) { logger . error ( "Error sending event" , e ) ; } }
private void uploadJar ( Long operatorId , File file ) { try { logger . debug ( "upload operator jar, operatorId = {}" , operatorId ) ; clientUtil . uploadOperatorJar ( operatorId , file ) ; } catch ( Exception e ) { logger . error ( "upload operator jar failed, operatorId = {}" , operatorId , e ) ; } }
private void uploadJar ( Long operatorId , File file ) { try { clientUtil . uploadOperatorJar ( operatorId , file ) ; logger . info ( "upload operator jar success, operatorId = {}" , operatorId ) ; } catch ( Exception e ) { logger . error ( "upload operator jar failed, operatorId = {}" , operatorId , e ) ; } }
private boolean isAvailable ( ) { String healthCheck = getBaseUrl ( ) + "/health" ; Call call = okHttpClient . newCall ( new Request . Builder ( ) . url ( healthCheck ) . get ( ) . build ( ) ) ; try ( Response response = call . execute ( ) ) { return response . code ( ) == 200 ; } catch ( IOException e ) { LOG . error ( e . getMessage ( ) , e ) ; return false ; } }
public boolean submit ( TaskAttempt taskAttempt ) { logger . info ( "begin to scheduler {}" , taskAttempt . getId ( ) ) ; podLifeCycleManager . start ( taskAttempt ) ; return true ; }
public boolean register ( Long taskAttemptId , WorkerEventHandler handler ) { logger . debug ( "register process event handler,taskAttemptId = {}" , taskAttemptId ) ; registerHandlers . put ( taskAttemptId , handler ) ; return true ; }
@ Override public void onClose ( WatcherException e ) { log . warn ( "Pod watcher OnClose" , e ) ; }
public void start ( ) { timer . scheduleAtFixedRate ( new PollingProcessStatus ( ) , 10 , POLLING_PERIOD , TimeUnit . MILLISECONDS ) ; localProcessBackend . watch ( new LocalProcessWatcher ( ) ) ; LOGGER . info ( "Local process watched" ) ; }
@ Override public boolean unRegister ( Long taskAttemptId ) { logger . debug ( "unRegister worker event handler,taskAttemptId = {}" , taskAttemptId ) ; registerHandlers . remove ( taskAttemptId ) ; return true ; }
@ Override public Integer getCapacity ( TaskAttemptQueue taskAttemptQueue ) { ResourceQueue limitResource = taskAttemptQueue . getResourceQueue ( ) ; ResourceQueue usedResource = getUsedResource ( taskAttemptQueue . getName ( ) ) ; LOG . info ( "Queue " + limitResource . getName ( ) + ", getting used resource number " + usedResource . getWorkerNumbers ( ) ) ; return limitResource . getWorkerNumbers ( ) - usedResource . getWorkerNumbers ( ) ; }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { logger . debug ( "Trying to abort current operator." ) ; try { operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
@ Override protected CascadeFillIn < InstanceFactory , ? > getFillIn ( AbstractMethod method ) { InstanceFactory instanceFactory = ThisMethodInvocationFactory . getInstance ( method ) ; if ( instanceFactory != null ) { return InstanceFactoryFillIn . getInstance ( instanceFactory ) ; } else { logger . warn ( e . toString ( ) ) ; return null ; } }
public static void invokeAndCatchProgramClosedException ( Runnable runnable ) { try { runnable . run ( ) ; } catch ( RuntimeException re ) { if ( isProgramClosedException ( re ) ) { LOG . error ( "Program closed exception" , re ) ; } else { throw re ; } } }
@ Override public void writeRuntimeConfig ( LaunchServerRuntimeConfig config ) throws IOException { try ( Writer writer = IOHelper . newWriter ( runtimeConfigFile ) ) { if ( Launcher . gsonManager . configGson != null ) { Launcher . gsonManager . configGson . toJson ( config , writer ) ; } else { LogHelper . error ( "Error writing LaunchServer runtime config file. Gson is null" ) ; } } }
public void prepare ( boolean force ) { try { IOHelper . createParentDirs ( config ) ; genWords ( force ) ; genConfig ( force ) ; } catch ( IOException e ) { XLog . getLog ( getClass ( ) ) . info ( "Error: xlog with/reset>" , e ) ; } }
@ Override public void invoke ( String ... args ) { long size = map . size ( ) ; garbageCollection ( ) ; LogHelper . info ( "GarbageCollector running for %d" , size ) ; }
@ Override public void run ( ) { Log . info ( "Binding LaunchServer as " + server . address + ":" + address . port ) ; nettyServer = new LauncherNettyServer ( server ) ; for ( LaunchServerConfig . NettyBindAddress address : server . config . netty . binds ) { nettyServer . bind ( new InetSocketAddress ( address . address , address . port ) ) ; } }
public static void addJVMClassPath ( Path path ) throws IOException { LogHelper . debug ( "Launcher Agent addJVMClassPath" ) ; inst . appendToSystemClassLoaderSearch ( new JarFile ( path . toFile ( ) ) ) ; }
@ Override public void setConfig ( NewLauncherSettings config ) { settings = config ; if ( settings . consoleUnlockKey != null && ! ConsoleManager . isConsoleUnlock ) { if ( ConsoleManager . checkUnlockKey ( settings . consoleUnlockKey ) ) { logger . info ( "New console unlock detected" ) ; ConsoleManager . unlock ( ) ; } } }
@ Override void onDisconnect ( ) { logger . debug ( "onDisconnect" ) ; if ( onCloseCallback != null ) onCloseCallback . onClose ( 0 , "unsupported param" , ! isClosed ) ; }
public static void addJVMClassPath ( String path ) throws IOException { LogHelper . debug ( "Launcher Agent addJVMClassPath" ) ; inst . appendToSystemClassLoaderSearch ( new JarFile ( path ) ) ; }
public void notifyItemStatusChanged ( UserOrderItem userOrderItem ) { if ( orderItemStatusChangeListeners != null && userOrderItem != null ) { for ( OrderItemStatusChangeListener listener : orderItemStatusChangeListeners ) { try { listener . onStatusChanged ( userOrderItem ) ; } catch ( Exception ex ) { LOG . error ( ex . toString ( ) , ex ) ; } } } }
@ Override public Page < Article > search ( String queryString , int pageNum , int pageSize ) { try { ArticleSearcher searcher = ArticleSearcherFactory . getSearcher ( ) ; Page < Article > page = searcher . search ( queryString , pageNum , pageSize ) ; if ( page != null ) { return page ; } } catch ( Exception ex ) { Log . error ( ex . getMessage ( ) , ex ) ; } return new Page < > ( new ArrayList < > ( ) , pageNum , pageSize , 0 , 0 ) ; }
@ Override public boolean handleEvent ( final Event abstractEvent ) { if ( ! enabled ) return true ; if ( abstractEvent instanceof AttributeTypeChangedEvent ) return handleAttributeTypeChangeEvent ( ( AttributeTypeChangedEvent ) abstractEvent ) ; if ( abstractEvent instanceof AuditEventTrigger ) return handleAuditEventTrigger ( ( AuditEventTrigger ) abstractEvent ) ; log . error ( "invalid event type: " + abstractEvent . getClass ( ) . getName ( ) ) ; return false ; }
private Map < Long , Map < String , Map < String , AttributeExt > > > getAllAttributes ( Predicate < Long > entityTester ) { Stopwatch w = Stopwatch . createStarted ( ) ; Stream < StoredAttribute > all = attributeDAO . getAll ( ) . stream ( ) . filter ( sa -> entityTester . test ( sa . getEntityId ( ) ) ) ; log . debug ( "getAllAttributes {}" , w . toString ( ) ) ; return mapAttributesByEntities ( all ) ; }
public synchronized void undeployJob ( String id ) { try { scheduler . deleteJob ( new JobKey ( id , BulkProcessingSupport . JOB_GROUP ) ) ; LOGGER . info ( "Successfully undeployed a rule with id {}" , id ) ; } catch ( SchedulerException e ) { throw new InternalException ( "Can't undeploy a rule with id " + id , e ) ; } }
@ Override public void invoke ( Entity entity ) { try { idsMan . removeEntity ( new EntityParam ( entity . getId ( ) ) ) ; log . info ( "Removed entity " + entity . getId ( ) + " from db." ) ; } catch ( Exception e ) { log . error ( "Removing entity failed" , e ) ; } }
@ Override public void invoke ( Entity entity ) { log . info ( "Removing entity " + entity ) ; try { idsMan . removeEntity ( new EntityParam ( entity . getId ( ) ) ) ; } catch ( Exception e ) { log . error ( "Caught exception in removeEntity" , e ) ; } }
private LoadingCache < String , Map < String , Integer > > initCache ( CapacityLimitDB limitDB ) { return CacheBuilder . newBuilder ( ) . expireAfterAccess ( 120 , TimeUnit . SECONDS ) . build ( new CacheLoader < String , Map < String , Integer > > ( ) { public Map < String , Integer > load ( String name ) { log . info ( "Get fresh values of capacity limits" ) ; return limitDB . getAll ( ) . stream ( ) . collect ( Collectors . toMap ( CapacityLimit :: getName , CapacityLimit :: getValue ) ) ; } } ) ; }
@ Override public void sendVerificationQuietNoTx ( EntityParam entity , Attribute attribute , boolean force ) { try { sendVerification ( entity , attribute , force ) ; } catch ( Exception e ) { log . warn ( "Can not send a confirmation for the verificable identity being added " + "on the key" , e ) ; } }
private boolean checkSendingLimit ( String mobileToConfirm ) { confirmationReqCache . evictExpiredElements ( ) ; Results results = confirmationReqCache . createQuery ( ) . includeValues ( ) . addCriteria ( Query . VALUE . ilike ( mobileToConfirm ) ) . execute ( ) ; if ( results . size ( ) >= requestLimit ) { log . warn ( "Limit of sent confirmation requests to email " + mobileToConfirm + " was reached. (Limit=" + requestLimit + "/24H)" ) ; return false ; } return true ; }
@ Override public void deployInternalEndpointFilter ( String contextPath , FilterHolder filter ) throws EngineException { log . info ( "Enabling shared handler for path " + contextPath ) ; sharedHandler . addFilter ( filter , contextPath + "/*" , EnumSet . of ( DispatcherType . REQUEST ) ) ; }
public void clearScheduledRemovalStatus ( long entityId ) throws IllegalIdentityValueException , IllegalTypeException { EntityInformation info = entityDAO . getByKey ( entityId ) ; if ( info . getState ( ) != EntityState . onlyLoginPermitted ) return ; log . info ( "Removing scheduled removal of an account [as the user is being logged] for entity " + entityId ) ; info . setState ( EntityState . valid ) ; info . setRemovalByUserTime ( null ) ; entityDAO . updateByKey ( entityId , info ) ; }
@ Override public Future < NotificationStatus > sendNotification ( String recipientAddress , Message message ) { NotificationStatus retStatus = new NotificationStatus ( ) ; return execService . getService ( ) . submit ( ( ) -> { try { sendSMS ( recipientAddress , message ) ; } catch ( Exception e ) { log . error ( "Could not send SMS message to localhost" , e ) ; retStatus . setProblem ( e ) ; } } , retStatus ) ; }
private String getClientIP ( HttpServletRequest httpRequest ) throws IOException { try { return ipDiscovery . getClientIP ( httpRequest ) ; } catch ( Exception e ) { log . error ( "Illegal client IP" , e ) ; throw new IOException ( "Illegal client IP" ) ; } }
private void addRedirectHandler ( UnityServerConfiguration cfg ) throws ConfigurationException { if ( cfg . isSet ( UnityServerConfiguration . DEFAULT_WEB_PATH ) ) { try { deployHandler ( new RedirectHandler ( cfg . getValue ( UnityServerConfiguration . DEFAULT_WEB_PATH ) ) , "sys:redirect" ) ; } catch ( EngineException e ) { log . error ( "Unable to deploy " + UnityServerConfiguration . DEFAULT_WEB_PATH , e ) ; } } }
@ Override public Optional < ByteArray > getUserHandleForUsername ( final String username ) { log . debug ( "getUserHandleForUsername({})" , username ) ; return entityHelper . getUserHandleForUsername ( username ) . map ( uh -> new ByteArray ( FidoUserHandle . fromString ( uh ) . getBytes ( ) ) ) ; }
private boolean isPolicyAgreementWaiting ( OAuthAuthzContext oauthCtx ) { try { return ! policyAgreementsMan . filterAgreementToPresent ( new EntityParam ( InvocationContext . getCurrent ( ) . getLoginSession ( ) . getEntityId ( ) ) , CommonIdPProperties . getPolicyAgreementsConfig ( msg , oauthCtx . getConfig ( ) ) . agreements ) . isEmpty ( ) ; } catch ( EngineException e ) { log . error ( "Unable to determine policy agreements to accept" ) ; } return false ; }
@ Path ( "/group/{groupPath}/meta" ) @ GET public String getGroupMeta ( @ PathParam ( "groupPath" ) String group ) throws EngineException , JsonProcessingException { log . debug ( "getGroupMeta query for " + group ) ; if ( ! group . startsWith ( "/" ) ) group = "/" + group ; GroupContents contents = groupsMan . getContents ( group , GroupContents . METADATA ) ; return mapper . writeValueAsString ( contents . getGroup ( ) ) ; }
@ Path ( "/group" ) @ PUT public void updateGroup ( String groupJson ) throws EngineException , JsonProcessingException { log . info ( "add group {}" , groupJson ) ; Group parsedGroup = JsonUtil . parse ( groupJson , Group . class ) ; groupsMan . updateGroup ( parsedGroup . getName ( ) , parsedGroup ) ; }
public Response toResponse ( JsonParseException ex ) { log . warn ( "JSON error during RESTful API invocation" , ex ) ; return Response . status ( Status . BAD_REQUEST ) . entity ( new JsonError ( ex ) . toString ( ) ) . type ( MediaType . APPLICATION_JSON ) . build ( ) ; }
public Response toResponse ( NullPointerException ex ) { log . error ( "A NullPointerException occurred in REST request" , ex ) ; return Response . status ( Status . INTERNAL_SERVER_ERROR ) . type ( MediaType . APPLICATION_JSON ) . build ( ) ; }
private String getClientsPersistentIdValidating ( EntityParam entityId , String expected ) { String persistentId = getClientsPersistentId ( entityId ) ; if ( ! persistentId . equals ( expected ) ) { logger . error ( "Persistent id validation failed for entity: " + entityId . getUuid ( ) + ". Expected: " + expected ) ; throw new ClientErrorException ( Status . FORBIDDEN ) ; } return persistentId ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { log . trace ( "Request:n" + request . getMethod ( ) + " " + request . getRequestURL ( ) + "n" + request . getQueryString ( ) ) ; StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request params:n" + request . getParameterMap ( ) ) ; log . trace ( "Blocked request contents:n" + sb ) ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request info:n" + request . getMethod ( ) ) ; log . trace ( "Received request message:n" + line ) ; log . trace ( "Blocked request contents:n" + sb ) ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request info:n" + request . getMethod ( ) ) ; log . trace ( "Blocked request params:n" + request . getParameterMap ( ) ) ; log . trace ( sb . toString ( ) ) ; }
private synchronized boolean isRefreshNeeded ( ) { long sinceLastRefresh = lastRefresh == null ? Long . MAX_VALUE : lastRefresh . until ( Instant . now ( ) , ChronoUnit . MILLIS ) ; if ( sinceLastRefresh >= refreshInterval ) { lastRefresh = Instant . now ( ) ; LOGGER . debug ( "Ignoring refresh event sinceLastRefresh = {}" , sinceLastRefresh ) ; return true ; } else { return false ; } }
private void notifyConsumer ( MetadataConsumer consumer , EntitiesDescriptorDocument metadata ) { try { consumer . consumer . accept ( metadata , consumer . id ) ; log . info ( "Metadata consumer accepted for metadata document {}" , metadata ) ; } catch ( Exception e ) { log . error ( "Metadata consumer failed to accept new metadata" , e ) ; } }
private void notifyConsumer ( MetadataConsumer consumer , EntitiesDescriptorDocument metadata ) { try { log . debug ( "Pushing metadata {} to consumer {}" , source . url , consumer . id ) ; consumer . consumer . accept ( metadata , consumer . id ) ; } catch ( Exception e ) { log . warn ( "Error when trying to push metadata, consumer class: {}" , source . url , e ) ; } }
@ Override public ZonedDateTime convertFromString ( String stringRepresentation ) { for ( String format : ACCEPTABLE_FORMATS ) { try { return ZonedDateTime . parse ( stringRepresentation , DateTimeFormatter . ofPattern ( format ) ) ; } catch ( Exception e ) { log . trace ( "Can not parse zoned datetime " + stringRepresentation + " using format: " + format , e ) ; } } throw new InternalException ( "Can not parse zoned datetime " + stringRepresentation + " using standard datetime formats" ) ; }
private T deserializeFromJson ( JsonParser input ) throws IOException { ObjectNode read = input . readValueAsTree ( ) ; try { return fromJsonSingle ( read ) ; } catch ( Exception e ) { log . error ( "Error deserializing object [" + read + "]" , e ) ; throw e ; } }
private void setupTransactionSession ( ProceedingJoinPoint pjp ) throws Exception { log . trace ( "Setting up transaction session for {}" , pjp . toShortString ( ) ) ; TransactionsState < HzTransactionState > transactionsStack = HzTransactionTL . getState ( ) ; if ( transactionsStack . isEmpty ( ) ) { createNewTransaction ( pjp ) ; } else { transactionsStack . push ( new HzTransactionState ( transactionsStack . getCurrent ( ) ) ) ; } }
@ Override protected StoredIdentity fromJsonSingle ( ObjectNode src ) { try { return new StoredIdentity ( new Identity ( src ) ) ; } catch ( IllegalArgumentException e ) { if ( log . isDebugEnabled ( ) ) log . debug ( "Skipping identity without comaprable value: likely transient." , e ) ; else log . warn ( "Identity without comaprable value: " + src ) ; return null ; } }
@ Override protected Token fromJsonSingle ( ObjectNode src ) { try { return Constants . MAPPER . treeToValue ( src , Token . class ) ; } catch ( JsonProcessingException e ) { log . error ( "Unable to deserialize token" , e ) ; } return null ; }
private static boolean updateThemeProperty ( Properties raw , String property , String endpointName ) { String fullName = "unity.endpoint.web." + property ; if ( raw . get ( fullName ) != null && raw . get ( fullName ) . equals ( "sidebarThemeValo" ) ) { raw . put ( fullName , "unityThemeValo" ) ; return true ; } log . info ( "Could not set property {} as not suitable as value was: {}" , property , endpointName ) ; return false ; }
private void updateDatabase ( ) { try { initDB . updateContents ( ) ; } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new InternalException ( "Update of the database contents failed" , e ) ; } }
private AttributeExt getAttribute ( String attributeName , String group ) { Collection < AttributeExt > attributes ; try { attributes = attributesMan . getAttributes ( new EntityParam ( entityId ) , group , attributeName ) ; } catch ( EngineException e ) { log . error ( "Can not get attribute " + attributeName , e ) ; return null ; } if ( attributes . isEmpty ( ) ) return null ; return attributes . iterator ( ) . next ( ) ; }
private boolean isRegistrationEnabled ( ) { try { return registrationFormController . isRegistrationEnabled ( ) ; } catch ( EngineException e ) { log . error ( "Can not get registration form" , e ) ; return false ; } }
private void handleUnknownUser ( UnknownRemoteUserException e ) { log . debug ( "Authentication failed" , e ) ; if ( e . getFormForUser ( ) != null || e . getResult ( ) . isEnableAssociation ( ) ) { setAuthenticationAborted ( ) ; authNPanel . showUnknownUserDialog ( e ) ; } else { log . trace ( "Authentication successful, user unknown, " + "no registration form" ) ; handleError ( msg . getMessage ( "AuthenticationUI.unknownRemoteUser" ) , null ) ; } }
private void handleUnknownUser ( UnknownRemoteUserException e ) { log . debug ( "Authentication failed" , e ) ; if ( e . getFormForUser ( ) != null || e . getResult ( ) . isEnableAssociation ( ) ) { log . trace ( "Authentication successful, user unknown, " + "showing unknown user dialog" ) ; setAuthenticationAborted ( ) ; authNPanel . showUnknownUserDialog ( e ) ; } else { handleError ( msg . getMessage ( "AuthenticationUI.unknownRemoteUser" ) , null ) ; } }
private void resendCodeViaEmail ( ) throws TooManyAttempts { try { backend . sendCode ( settings . getEmailSecurityCodeMsgTemplate ( ) , false ) ; } catch ( TooManyAttempts e ) { throw e ; } catch ( Exception e ) { log . warn ( "Credential reset notification failed" , e ) ; NotificationPopup . showError ( msg . getMessage ( "error" ) , msg . getMessage ( "CredentialReset.resetNotPossible" ) ) ; onCancel ( ) ; } }
private PolicyDocumentWithRevision getDoc ( String docId ) { try { return policyDocMan . getPolicyDocument ( Long . valueOf ( docId ) ) ; } catch ( Exception e ) { log . warn ( "Can not get policy document " + docId ) ; return null ; } }
@ Override public void onAuthnError ( AuthenticationException e , String authenticatorError ) { enableSharedComponentsAndHideAuthnProgress ( ) ; String genericError = msg . getMessage ( e . getMessage ( ) ) ; String errorToShow = authenticatorError == null ? genericError : authenticatorError ; log . warn ( "External authentication failed, but not implemented for {}. See http://tools.lsc-project.org/issues/show/31" , errorToShow ) ; NotificationPopup . showError ( errorToShow , "" ) ; }
@ Override public void removeListener ( AuthnResultListener listener ) { final String sessionId = VaadinService . getCurrentRequest ( ) . getWrappedSession ( ) . getId ( ) ; synchronized ( authnListenerList ) { List < AuthnResultListener > list = authnListenerList . get ( sessionId ) ; if ( list != null ) { list . remove ( listener ) ; if ( list . isEmpty ( ) ) authnListenerList . remove ( sessionId ) ; } } getLogger ( ) . info ( "Removing listener {} from session {}" , listener . getClass ( ) . getName ( ) , sessionId ) ; }
void addAuthenticator ( AuthenticatorDefinition authenticator ) throws ControllerException { try { authnMan . createAuthenticator ( authenticator . id , authenticator . type , authenticator . configuration , authenticator . localCredentialName ) ; } catch ( Exception e ) { log . error ( "Can not add authenticator" , e ) ; throw new ControllerException ( msg . getMessage ( "AuthenticatorsController.addError" , authenticator . id ) , e ) ; } }
private String getPolicyDocName ( Long id ) { try { return policyDocMan . getPolicyDocument ( id ) . name ; } catch ( Exception e ) { log . warn ( "Can not get policy document " + id , e ) ; return String . valueOf ( id ) ; } }
public void deleteGroup ( String projectPath , String groupPath ) throws ControllerException { try { delGroupMan . removeGroup ( projectPath , groupPath ) ; } catch ( Exception e ) { log . warn ( "Can not delete group " + projectPath , e ) ; throw new ServerFaultException ( msg ) ; } }
public Optional < String > getProjectSingUpEnquiryFormLink ( String projectPath ) throws ControllerException { try { return requestMan . getProjectSignUpEnquiryFormLink ( projectPath ) ; } catch ( EngineException e ) { log . warn ( "Can not get project signup enquiry form link " + projectPath , e ) ; throw new ServerFaultException ( msg ) ; } }
private void commitQuietly ( ) { if ( connection != null ) { try { connection . commit ( ) ; } catch ( final SQLException e ) { logger . debug ( "Unable to commit transaction" , e ) ; } } connection = null ; }
public TableDefinition refresh ( final Connection connection , final TableId tableId ) throws SQLException { final TableDefinition dbTable = dialect . describeTable ( connection , tableId ) ; log . info ( "Refreshing {} table {}" , dbTable . id ( ) , tableId ) ; cache . put ( dbTable . id ( ) , dbTable ) ; return dbTable ; }
@ Override protected void executeInternal ( ) throws Throwable { logger . info ( "This is not implemented as the demo component is not implemented as the configuration is false. Better remove me from the log in Production" ) ; System . out . println ( "DemoComponent has been executed" ) ; logger . info ( "This is only for information purposes. Better remove me from the log in Production" ) ; }
@ Override protected void executeInternal ( ) throws Throwable { logger . debug ( "Test debug logging. Congratulation your JAR Module is working" ) ; System . out . println ( "DemoComponent has been executed" ) ; logger . debug ( "Test debug logging. Congratulation your JAR Module is working" ) ; }
public boolean deactivateCustomModel ( String fileName ) { try { FileModel customModel = getCustomModel ( fileName ) ; if ( customModel != null ) { cmisApi . authenticateUser ( dataUser . getAdminUser ( ) ) . usingResource ( customModel ) . updateProperty ( "cm:modelActive" , false ) ; return true ; } } catch ( Exception e ) { LOG . info ( e . getMessage ( ) ) ; } return false ; }
private void deleteNode ( UpdateRequestProcessor processor , SolrQueryRequest request , Node node ) throws IOException { LOGGER . debug ( "Node {} going to be deleted" , node . getId ( ) ) ; deleteErrorNode ( processor , request , node ) ; deleteNode ( processor , request , node . getId ( ) ) ; LOGGER . debug ( "Node {} deletion correctly sent" , node . getId ( ) ) ; }
private void deleteNode ( UpdateRequestProcessor processor , SolrQueryRequest request , Node node ) throws IOException { LOGGER . debug ( "Node {} is being deleted" , node . getId ( ) ) ; deleteErrorNode ( processor , request , node ) ; deleteNode ( processor , request , node . getId ( ) ) ; LOGGER . info ( "Node {} deleted." , node . getId ( ) ) ; }
private void findCores ( File dir , List < File > cores ) { File [ ] files = dir . listFiles ( ) ; if ( files != null ) { for ( File file : files ) { if ( file . isDirectory ( ) ) { findCores ( file , cores ) ; } else { if ( "core.properties" . equals ( file . getName ( ) ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Adding core: " + file ) ; } cores . add ( dir ) ; } } } } }
protected void indexAcls ( ) throws AuthenticationException , IOException , JSONException { while ( aclsToIndex . peek ( ) != null ) { Long aclId = aclsToIndex . poll ( ) ; if ( aclId != null ) { Acl acl = new Acl ( 0 , aclId ) ; List < AclReaders > readers = client . getAclReaders ( Collections . singletonList ( acl ) ) ; logger . debug ( "Indexing AclReaders" ) ; indexAcl ( readers , false ) ; } checkShutdown ( ) ; } }
@ Override protected void onFail ( Throwable failCausedBy ) { LOG . error ( "Failed to send response message to Google PubSub, topic: {}" , combinedTopic , failCausedBy ) ; }
private void purgeNodes ( ) throws IOException , JSONException { while ( nodesToPurge . peek ( ) != null ) { Long nodeId = nodesToPurge . poll ( ) ; if ( nodeId != null ) { this . infoSrv . deleteByNodeId ( nodeId ) ; LOGGER . info ( "[CORE {}] - PURGE ACTION - Purged nodeId {}" , coreName , nodeId ) ; } checkShutdown ( ) ; } }
public static void dismissSolrServers ( ) { try { destroyServers ( ) ; distribTearDown ( ) ; boolean keepTests = Boolean . parseBoolean ( System . getProperty ( "keep.tests" ) ) ; if ( ! keepTests ) FileUtils . deleteDirectory ( testDir ) ; } catch ( Exception e ) { logger . error ( "dismissing in failed to delete test directory: " + testDir , e ) ; } }
public void compareSolrResponses ( SolrResponse a , SolrResponse b ) { handle . put ( "QTime" , SKIPVAL ) ; String cmp = compare ( a . getResponse ( ) , b . getResponse ( ) , flags , handle ) ; if ( cmp != null ) { log . error ( "Could not compare Solr response" ) ; Assert . fail ( cmp ) ; } }
@ Override @ Behaviour ( kind = BehaviourKind . CLASS ) public void onCreateNode ( ChildAssociationRef childAssocRef ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( "onCreateNode: " + childAssocRef ) ; } validateAndReset ( childAssocRef . getChildRef ( ) ) ; }
@ Override public boolean handleAuditEntryError ( Long entryId , String errorMsg , Throwable error ) { logger . warn ( "Error fetching tagging update entry - " + errorMsg , error ) ; return true ; }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { if ( log != null ) { log . fatal ( arg0 , arg1 ) ; } }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { log . fatal ( arg0 , arg1 ) ; log2 . fatal ( arg0 , arg1 ) ; }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { log . fatal ( arg0 , arg1 ) ; log2 . fatal ( arg0 , arg1 ) ; }
public static final void debug ( Log logger , String messageKey , Object ... args ) { logger . debug ( I18NUtil . getMessage ( messageKey , args ) ) ; }
public static final void info ( Log logger , String messageKey , Object ... args ) { logger . info ( I18NUtil . getMessage ( messageKey , args ) ) ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( iae ) ; } return o ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( iae ) ; } return o ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( null ) ; } return o ; }
public void run ( ) { vmShuttingDown = true ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "vm shutdown timed out, will attempt to re-establish " + "it once the new session was established." ) ; } }
@ Override public void run ( ) { if ( allAwake ) return ; sleeping . put ( Thread . currentThread ( ) . getName ( ) , Thread . currentThread ( ) ) ; logger . debug ( "Going to sleep for going to sleep." ) ; try { Thread . sleep ( 30 * 1000 ) ; System . err . println ( "Warning - Thread finished sleeping without wake!" ) ; } catch ( InterruptedException e ) { logger . debug ( "Interrupted thread: " + Thread . currentThread ( ) . getName ( ) ) ; } }
@ Override public void run ( ) { if ( allAwake ) return ; logger . debug ( "Adding thread: " + Thread . currentThread ( ) . getName ( ) ) ; sleeping . put ( Thread . currentThread ( ) . getName ( ) , Thread . currentThread ( ) ) ; try { Thread . sleep ( 30 * 1000 ) ; System . err . println ( "Warning - Thread finished sleeping without wake!" ) ; } catch ( InterruptedException e ) { logger . error ( "Error in sleeping" , e ) ; } }
public void remove ( final String tenantId ) { liveLock . writeLock ( ) . lock ( ) ; try { DictionaryRegistry dictionaryRegistry = live . get ( tenantId ) ; if ( dictionaryRegistry != null ) { live . remove ( tenantId ) ; dictionaryRegistry . remove ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Dictionary removed for tenant " + tenantId ) ; } } } finally { liveLock . writeLock ( ) . unlock ( ) ; } }
public static void clearCurrentSecurityContext ( ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( "Clearing current security context." ) ; } ContextHolder . setContext ( null ) ; InMemoryTicketComponentImpl . clearCurrentSecurityContext ( ) ; NDC . remove ( ) ; TenantContextHolder . clearTenantDomain ( ) ; }
protected void redirectToLoginPage ( HttpServletRequest req , HttpServletResponse res ) throws IOException { if ( getLogger ( ) . isTraceEnabled ( ) ) { getLogger ( ) . trace ( "Redirecting to login page " + req . getContextPath ( ) ) ; } if ( hasLoginPage ( ) ) res . sendRedirect ( req . getContextPath ( ) + "/faces" + getLoginPage ( ) ) ; }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
public void contextInitialized ( ServletContextEvent sce ) { try { ServletContext servletContext = sce . getServletContext ( ) ; WebApplicationContextLoader . getApplicationContext ( servletContext , configLocations , classLocations ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Created Jetty context" ) ; } } catch ( Throwable t ) { logger . error ( "Failed to start Jetty server: " + t ) ; throw new AlfrescoRuntimeException ( "Failed to start Jetty server" , t ) ; } }
public void contextInitialized ( ServletContextEvent sce ) { try { ServletContext servletContext = sce . getServletContext ( ) ; WebApplicationContextLoader . getApplicationContext ( servletContext , configLocations , classLocations ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "contextInitialized " + sce ) ; } } catch ( Throwable t ) { logger . error ( "Failed to start Jetty server" , t ) ; throw new AlfrescoRuntimeException ( "Failed to start Jetty server" , t ) ; } }
public NodeRef getNodeRef ( NodeRef pathRootNodeRef , String path ) throws FileNotFoundException { List < NodeRef > nodeRefs = getNodeRefs ( pathRootNodeRef , path ) ; if ( nodeRefs . size ( ) == 0 ) { throw new FileNotFoundException ( path ) ; } else if ( nodeRefs . size ( ) > 1 ) { } NodeRef nodeRef = nodeRefs . get ( 0 ) ; logger . debug ( "getNodeRef(path={}, path={}) = {}" , path , path , nodeRefs ) ; return nodeRef ; }
public long seekFile ( SrvSession sess , TreeConnection tree , NetworkFile file , long pos , int typ ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "seek " + file . getName ( ) ) ; } if ( file . isDirectory ( ) ) { throw new AccessDeniedException ( ) ; } return file . seekFile ( pos , typ ) ; }
public void deleteEmptyFile ( NodeRef rootNode , String path ) { try { NodeRef target = getCifsHelper ( ) . getNodeRef ( rootNode , path ) ; if ( target != null ) { if ( nodeService . hasAspect ( target , ContentModel . ASPECT_NO_CONTENT ) ) { nodeService . deleteNode ( target ) ; } } } catch ( IOException ne ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "No content thrown by " + path , ne ) ; } } }
public int readFile ( byte [ ] buffer , int length , int position , long fileOffset ) throws IOException { openContent ( false , false ) ; ByteBuffer byteBuffer = ByteBuffer . wrap ( buffer , position , length ) ; int count = channel . read ( byteBuffer , fileOffset ) ; if ( count < 0 ) { count = 0 ; } if ( getFileState ( ) != null ) getFileState ( ) . updateAccessDateTime ( ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( "Read " + count + " bytes, " + getFileState ( ) . getUri ( ) + ", " + fileOffset ) ; return count ; }
@ Override public void addLock ( NodeRef nodeRef ) { if ( lockEnabled ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Adding lock at txid " + getTransactionId ( ) ) ; } getLockService ( ) . lock ( nodeRef , LockType . WRITE_LOCK , getTimeToExpire ( ) , Lifetime . EPHEMERAL , LOCK_KEEPER_KEY ) ; lockKeeperTransactionalCache . put ( nodeRef , new KeeperInfo ( AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ) ; } }
public void startMonitor ( ) { m_stateTable = m_filesysCtx . getStateCache ( ) ; m_thread = new Thread ( this ) ; m_thread . setName ( "NodeMonitor_" + m_filesysCtx . getDeviceName ( ) ) ; m_thread . setDaemon ( true ) ; m_thread . start ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Starting NodeMonitor" ) ; } }
@ Override public FileInfo getFileInformation ( SrvSession sess , TreeConnection tree , String path ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getFileInformation(" + path + ")" ) ; } FileFilterMode . setClient ( ClientHelper . getClient ( sess ) ) ; try { FileInfo info = diskInterface . getFileInformation ( sess , tree , path ) ; return info ; } finally { FileFilterMode . clearClient ( ) ; } }
public void closeFile ( ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( " close file " + getFileName ( ) ) ; logger . debug ( " Open count=" + getOpenCount ( ) + ", fstate open=" + getFileState ( ) . getOpenCount ( ) ) ; } super . closeFile ( ) ; }
public void closeFile ( ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Close OpenOffice file, " + getName ( ) + ", delayed close count=" + getDelayedCloseCount ( ) + ", writes=" + getWriteCount ( ) + ", modified=" + isModified ( ) ) ; } logger . debug ( "Close OpenOffice file" ) ; super . closeFile ( ) ; }
private ResultCallback deleteFileCallbackCommand ( ) { return new ResultCallback ( ) { @ Override public void execute ( Object result ) { if ( result instanceof NodeRef ) { logger . debug ( "got node ref of deleted node" ) ; originalNodeRef = ( NodeRef ) result ; } } @ Override public AlfrescoTransactionSupport . TxnReadState getTransactionRequired ( ) { return AlfrescoTransactionSupport . TxnReadState . TXN_NONE ; } } ; }
@ Override protected boolean evaluateImpl ( ActionCondition actionCondition , NodeRef actionedUponNodeRef ) { logger . warn ( "Action condition not met. Aborting action condition with node {}" , actionCondition ) ; return false ; }
protected void removeFromScheduler ( ScheduledPersistedActionImpl schedule ) { if ( schedule . getPersistedAtNodeRef ( ) == null ) return ; try { scheduler . deleteJob ( new JobKey ( schedule . getPersistedAtNodeRef ( ) . toString ( ) , SCHEDULER_GROUP ) ) ; } catch ( SchedulerException e ) { log . error ( "" , e ) ; } }
@ Override Void doWork ( ) { authenticationService . invalidateUserSession ( username ) ; log . info ( "User {} invalidated" , username ) ; return null ; }
public void guessMimetype ( String filename ) { if ( mimetypeService == null ) { logger . warn ( "MimetypeService not supplied, but required for content guessing" ) ; return ; } if ( isClosed ( ) ) { doGuessMimetype ( filename ) ; } else { guessingOnCloseListener . guessMimetype = true ; guessingOnCloseListener . filename = filename ; } }
public boolean delete ( String contentUrl ) throws ContentIOException { boolean deleted = true ; List < ContentStore > stores = getAllStores ( ) ; for ( ContentStore store : stores ) { if ( store . isWriteSupported ( ) ) { deleted &= store . delete ( contentUrl ) ; } } if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Deleted {}" , ( deleted ? "successful" : "not" ) + " to Closed" ) ; } return deleted ; }
private String acquireLock ( JobLockRefreshCallback lockCallback ) { String lockToken = jobLockService . getLock ( LOCK_QNAME , LOCK_TTL ) ; jobLockService . refreshLock ( lockToken , LOCK_QNAME , LOCK_TTL , lockCallback ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "lock acquired: " + LOCK_QNAME + ": " + lockToken ) ; } return lockToken ; }
private OverwritePolicy removeOverwritePolicy ( Map < String , Serializable > map , String key , OverwritePolicy defaultValue ) { Serializable value = map . remove ( key ) ; if ( value == null ) { return defaultValue ; } try { return OverwritePolicy . valueOf ( ( String ) value ) ; } catch ( IllegalArgumentException | ClassCastException e ) { logger . error ( String . format ( "Failed to parse overwrite policy value %s as a string" , value ) , e ) ; return null ; } }
@ Override public M2Model getM2Model ( final NodeRef modelNodeRef ) { ContentReader reader = contentService . getReader ( modelNodeRef , ContentModel . PROP_CONTENT ) ; if ( reader == null ) { return null ; } InputStream in = reader . getContentInputStream ( ) ; try { return M2Model . createModel ( in ) ; } finally { if ( in != null ) { try { in . close ( ) ; } catch ( IOException e ) { logger . debug ( "IOException while trying to close the model." , e ) ; } } } }
public Void execute ( ) throws Throwable { return TenantUtil . runAsSystemTenant ( new TenantRunAsWork < Void > ( ) { public Void doWork ( ) { dictionaryDAO . init ( ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "Workflow deployer afterCommit: Dictionary destroyed [" + AlfrescoTransactionSupport . getTransactionId ( ) + "]" ) ; } return null ; } } , tenantName ) ; }
@ Override public Void execute ( ) throws Throwable { try { if ( qnameDAO . getQName ( className ) != null ) { qnameDAO . deleteQName ( className ) ; } throw new ModelNotInUseException ( "Class " + className + " not in use" ) ; } catch ( DataIntegrityViolationException e ) { logger . debug ( e ) ; throw new ModelInUseException ( "Cannot delete model, class " + className + " is in use" ) ; } }
@ Override protected AuditApplicationEntity getAuditApplicationById ( Long id ) { Map < String , Object > params = new HashMap < String , Object > ( 11 ) ; params . put ( "id" , id ) ; AuditApplicationEntity entity = template . selectOne ( SELECT_APPLICATION_BY_ID , params ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Query for application by id = " + id + ", returning = " + entity ) ; } return entity ; }
@ Override public int deleteByKey ( Long key ) { deletePropertyRoot ( key ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Key: {} deleted. Count: {}" , key , count ) ; } return 1 ; }
@ Override public void cleanupUnusedValuesV2 ( ) { try { scriptExecutor . exec ( false , "alfresco/dbscripts/utility/${db.script.dialect}" , "CleanAlfPropTablesV2.sql" ) ; } catch ( RuntimeException e ) { logger . error ( "Failed to cleanup value" , e ) ; throw e ; } finally { clearCaches ( ) ; } }
public NodeRef getOrCreateDowloadContainer ( ) { NodeRef downloadsContainer = getContainer ( ) ; if ( downloadsContainer == null ) { if ( log . isInfoEnabled ( ) ) log . info ( "Or creating the default downloads container: " + downloadsContainer ) ; downloadsContainer = SystemNodeUtils . getOrCreateSystemChildContainer ( getContainerQName ( ) , nodeService , repositoryHelper ) . getFirst ( ) ; } return downloadsContainer ; }
@ Override protected void updateAssociations ( NodeService nodeService ) { List < AssociationRef > existingAssocs = nodeService . getTargetAssocs ( sourceNodeRef , assocQName ) ; for ( AssociationRef assoc : existingAssocs ) { if ( assoc . getTargetRef ( ) . equals ( targetNodeRef ) ) { if ( logger . isWarnEnabled ( ) ) { logger . warn ( "duplicate association to {}" , assoc ) ; } return ; } } nodeService . createAssociation ( sourceNodeRef , targetNodeRef , assocQName ) ; }
public void shutdown ( ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( "Shutting down scheduler thread pool" ) ; } scheduler . shutdown ( ) ; }
@ Override public List < FileInfo > listFolders ( NodeRef contextNodeRef ) { List < FileInfo > results = listSimple ( contextNodeRef , false , true ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "List files: n" + " context: " + contextNodeRef + "n" + " results: " + results ) ; } return results ; }
@ Override public List < FileInfo > listDeepFolders ( NodeRef contextNodeRef , SubFolderFilter filter ) { List < NodeRef > nodeRefs = listSimpleDeep ( contextNodeRef , false , true , filter ) ; List < FileInfo > results = toFileInfo ( nodeRefs ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "ListDeepFolders({}) returns {}" , contextNodeRef , results ) ; } return results ; }
@ Override public void delete ( NodeRef nodeRef ) { nodeService . deleteNode ( nodeRef ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Deleted node " + nodeRef ) ; } }
public void onRemoveAspect ( NodeRef nodeRef , QName aspectTypeQName ) { if ( ! storesToIgnore . contains ( nodeRef . getStoreRef ( ) . toString ( ) ) ) { if ( aspectTypeQName . equals ( ContentModel . ASPECT_INCOMPLETE ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Ignoring aspect addition: " + ContentModel . ASPECT_INCOMPLETE ) ; } } save ( nodeRef ) ; } }
private String getUrl ( String url , String propName ) { if ( url == null ) { LOGGER . warn ( "The url for the property [" + propName + "] is not configured." ) ; return "" ; } if ( url . endsWith ( "/" ) ) { url = url . substring ( 0 , url . length ( ) - 1 ) ; } return UrlUtil . replaceShareUrlPlaceholder ( url , sysAdminParams ) ; }
private boolean isOldRenditionInCorrectLocation ( ) { boolean result = isOldRenditionInCorrectLocationWithoutLog ( ) ; if ( logger . isDebugEnabled ( ) ) { StringBuilder msg = new StringBuilder ( ) ; msg . append ( "The old rendition was " ) ; if ( result == false ) { msg . append ( "not " ) ; } msg . append ( "in the correct location" ) ; logger . debug ( msg . toString ( ) ) ; } return result ; }
protected void checkSourceNodeExists ( NodeRef actionedUponNodeRef ) { if ( nodeService . exists ( actionedUponNodeRef ) == false ) { String msg = "Cannot execute action as node does not exist: " + actionedUponNodeRef ; logger . warn ( msg ) ; throw new RenditionServiceException ( msg ) ; } }
public Object execute ( ) throws Throwable { if ( logger . isDebugEnabled ( ) ) logger . debug ( "Persisting replication definition " + replicationDef ) ; replicationDefinitionPersister . saveReplicationDefinition ( replicationDef ) ; return null ; }
@ Override public Void doWork ( ) throws Exception { return retryingTransactionHelper . doInTransaction ( new RetryingTransactionCallback < Void > ( ) { public Void execute ( ) throws Exception { deleteFacet ( facetId ) ; logger . info ( "Deleted [{}] node, as the filter has been removed from the config file!" , facetId ) ; return null ; } } , false ) ; }
private void logReturnedUser ( String userId ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( userId + " returning " + AuthenticatedPrincipal . getCurrentUser ( ) ) ; } }
private void split ( Set < NodeRef > toSplit ) { for ( NodeRef nodeRef : toSplit ) { String userName = ( String ) nodeService . getProperty ( nodeRef , ContentModel . PROP_USERNAME ) ; String newUserName = userName + GUID . generate ( ) ; logger . debug ( "Splitting node: {}, new entity: {}" , nodeRef , newUserName ) ; nodeService . setProperty ( nodeRef , ContentModel . PROP_USERNAME , userName + GUID . generate ( ) ) ; } }
@ Override protected void onBootstrap ( ApplicationEvent event ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "ApplicationListener initialized" ) ; } }
public void processChunk ( Set < ContentData > data ) { checkCancel ( transfer . getTransferId ( ) ) ; for ( ContentData file : data ) { LOG . debug ( "{}: content request for transfer {}" , name , file ) ; counter ++ ; eventProcessor . sendContent ( file , fRange , counter ) ; } transmitter . sendContent ( transfer , data ) ; }
@ Override public RepoUsage getUsage ( ) { checkTxnState ( TxnReadState . TXN_READ_ONLY ) ; restrictionsReadLock . lock ( ) ; try { RepoUsage usage = getUsageImpl ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "{}: getUsage {}" , this , usage ) ; } return usage ; } finally { restrictionsReadLock . unlock ( ) ; } }
@ Override @ Extend ( extensionAPI = VersionServiceExtension . class , traitAPI = VersionServiceTrait . class ) public void revert ( NodeRef nodeRef , Version version ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } revert ( nodeRef , version , true ) ; }
@ Override @ Extend ( extensionAPI = VersionServiceExtension . class , traitAPI = VersionServiceTrait . class ) public void revert ( NodeRef nodeRef , Version version ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } revert ( nodeRef , version , true ) ; }
@ Override public StoreRef getVersionStoreReference ( ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } return new StoreRef ( StoreRef . PROTOCOL_WORKSPACE , VersionModel . STORE_ID ) ; }
@ Override public StoreRef getVersionStoreReference ( ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } return new StoreRef ( StoreRef . PROTOCOL_WORKSPACE , VersionModel . STORE_ID ) ; }
public List < WorkflowInstance > getActiveWorkflows ( String workflowDefinitionId ) { try { return getWorkflows ( new WorkflowInstanceQuery ( workflowDefinitionId , true ) ) ; } catch ( ActivitiException ae ) { String message = messageService . getMessage ( ERR_GET_ACTIVE_WORKFLOW_INSTS , workflowDefinitionId ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( message , ae ) ; } throw new WorkflowException ( message , ae ) ; } }
@ Override public Void execute ( ) throws Throwable { log . info ( "TestCrossDbOps setup1.docx" ) ; ClassPathResource fileResource = new ClassPathResource ( "filesys/ContentDiskDriverTest1.docx" ) ; assertNotNull ( "unable to find test resource filesys/ContentDiskDriverTest1.docx" , fileResource ) ; writeResourceToNetworkFile ( fileResource , testContext . firstFileHandle ) ; driver . closeFile ( testSession , testConnection , testContext . firstFileHandle ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "second refresh" ) ; lockKeeper . refreshAllLocks ( ) ; return null ; }
protected void createSite ( String siteId , boolean isPublic ) throws Exception { siteService . createSite ( "myPreset" , siteId , "myTitle" , "myDescription" , ( isPublic ? SiteVisibility . PUBLIC : SiteVisibility . PRIVATE ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Site created: " + siteId ) ; } }
public Void execute ( ) throws Throwable { log . debug ( "Versionable node: " + Versionable . getVersionString ( ) ) ; ScriptNode sn = new ScriptNode ( testNode , SERVICE_REGISTRY ) ; sn . addAspect ( "cm:versionable" ) ; return null ; }
@ Override public boolean isActive ( ) { isActiveCount ++ ; log . debug ( "active = " + isActive ) ; return isActive ; }
@ Override public void lockReleased ( ) { log . debug ( "Lock release notification: {}" , LOCK_QNAME ) ; released = true ; }
public Void execute ( ) throws Throwable { NODE_SERVICE . deleteNode ( folder1 ) ; logger . info ( "deleted folder1 " + folder1 ) ; return null ; }
public Void execute ( ) throws Throwable { AUTHENTICATION_COMPONENT . getCurrentUserName ( ) ; log . debug ( "About to delete site." ) ; SITE_SERVICE . deleteSite ( siteShortName ) ; log . debug ( "Site deleted." ) ; return null ; }
public Void execute ( ) throws Throwable { log . debug ( "About to delete site." ) ; AUTHENTICATION_COMPONENT . getCurrentUserName ( ) ; SITE_SERVICE . deleteSite ( siteShortName ) ; log . debug ( "Site deleted." ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "First transfer - create new node (no content yet)" ) ; TransferDefinition definition = new TransferDefinition ( ) ; Set < NodeRef > nodes = new HashSet < NodeRef > ( ) ; nodes . add ( testContext . contentNodeRef ) ; definition . setNodes ( nodes ) ; transferService . transfer ( targetName , definition ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "delete node BgpAndInstall" ) ; nodeService . deleteNode ( testData . A3NodeRef ) ; return null ; }
@ Test public void testDefaultSyspath ( ) throws Exception { NodeRef vf = createVirtualizedFolder ( testRootFolder . getNodeRef ( ) , "SystemVirtualizationMethodTest_testDefaultSyspath" , null ) ; assertFalse ( systemVirtualizationMethod . canVirtualize ( environment , vf ) ) ; try { systemVirtualizationMethod . virtualize ( environment , vf ) ; fail ( "Should not be able to virtualize non-virtualizable nodes." ) ; } catch ( VirtualizationException e ) { logger . info ( "vm can not be able to virtualize " + e ) ; } }
@ Test public void testNonVirtualizable ( ) throws Exception { NodeRef aNodeRef = createVirtualizedFolder ( testRootFolder . getNodeRef ( ) , "TestVirtualStoreImpl_createVirtualizedFolder" , null ) ; assertFalse ( smartStore . canVirtualize ( aNodeRef ) ) ; try { smartStore . virtualize ( aNodeRef ) ; fail ( "Should not be able to virtualize non-virtualizable nodes." ) ; } catch ( VirtualizationException e ) { logger . info ( "TestVirtualStoreImpl::testVirtualize: " + e ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema factory dump. " + toString ( ) ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( " " + dbo ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Iterating through Schema objects:" ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Iterating through Schema objects:" ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( " " + dbo ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Done creating through Schema objects" ) ; } }
protected OperatingSystem parseOperatingSystem ( Server from ) { try { return Iterables . find ( images . get ( ) , new FindImageForServer ( from ) ) . getOperatingSystem ( ) ; } catch ( NoSuchElementException e ) { logger . debug ( "could not find a matching image for server %s" , from ) ; } return null ; }
protected ExecResponse runCommand ( String command ) { ExecResponse returnVal ; logger . debug ( ">> running [%s] as %s@%s" , command . replace ( node . getCredentials ( ) . getOptionalPassword ( ) . isPresent ( ) ? node . getCredentials ( ) . getOptionalPassword ( ) . get ( ) : "XXXXX" , "XXXXX" ) , ssh . getUsername ( ) , ssh . getHostAddress ( ) ) ; returnVal = ssh . exec ( command ) ; return returnVal ; }
public T apply ( HttpResponse from ) { InputStream gson = from . getPayload ( ) . getInput ( ) ; try { return apply ( gson ) ; } catch ( Exception e ) { StringBuilder message = new StringBuilder ( ) ; message . append ( "Error parsing input" ) ; logger . error ( e , message . toString ( ) ) ; throw new HttpResponseException ( message . toString ( ) + "n" + from , null , from , e ) ; } finally { releasePayload ( from ) ; } }
public void imposeBackoffExponentialDelay ( long period , long maxPeriod , int pow , int failureCount , int max , String commandDescription ) { long delayMs = ( long ) ( period * Math . pow ( failureCount , pow ) ) ; delayMs = delayMs > maxPeriod ? maxPeriod : delayMs ; try { Thread . sleep ( delayMs ) ; } catch ( InterruptedException e ) { logger . warn ( "send command [" + commandDescription + "] sleep failed" ) ; Throwables . propagate ( e ) ; } }
@ Override public Set < String > get ( ) { String regionString = config . apply ( configKey ) ; if ( regionString == null ) { logger . warn ( "No value configured for key [{}]" , configKey ) ; return ImmutableSet . of ( ) ; } else { return ImmutableSet . copyOf ( Splitter . on ( ',' ) . split ( regionString ) ) ; } }
private Function < HttpResponse , ? > getTransformer ( String commandName , HttpCommand command ) { HttpRequest request = command . getCurrentRequest ( ) ; Function < HttpResponse , ? > transformer = transformerForRequest . apply ( request ) ; log . debug ( "{}: Executed {} for command {}" , transformerForRequest , commandName , command ) ; return transformer ; }
@ Override protected void logDebug ( String message ) { ourLog . debug ( message ) ; }
@ Override public void clear ( ) { if ( ssh != null && ssh . isConnected ( ) ) { try { ssh . disconnect ( ) ; } catch ( AssertionError e ) { } catch ( IOException e ) { LOG . warn ( "Unexpected error when disconnecting ssh client" , e ) ; } ssh = null ; } }
protected Image parseImage ( Server from ) { Image image = null ; try { image = Iterables . find ( images . get ( ) , new FindImageForServer ( from ) ) ; } catch ( NoSuchElementException e ) { logger . debug ( "could not find a matching image for server %s" , from ) ; } return image ; }
public boolean apply ( Volume volume ) { logger . trace ( "looking for state on volume %s" , volume . getId ( ) ) ; volume = client . getVolume ( volume . getId ( ) ) ; if ( volume == null ) return false ; logger . trace ( "%s: looking for volume state %s: currently: %s" , volume . getId ( ) , Volume . State . UNMOUNTED , volume . getState ( ) ) ; return volume . getState ( ) == Volume . State . UNMOUNTED ; }
public boolean apply ( Volume volume ) { logger . trace ( "looking for state on volume %s" , volume ) ; volume = client . getVolume ( volume . getId ( ) ) ; if ( volume == null ) return false ; logger . trace ( "%s: looking for volume state %s: currently: %s" , volume . getId ( ) , Volume . State . UNMOUNTED , volume . getState ( ) ) ; return volume . getState ( ) == Volume . State . UNMOUNTED ; }
@ Override public boolean apply ( final String networkDomainId ) { checkNotNull ( networkDomainId , "networkDomainId" ) ; logger . trace ( "looking for state on network domain %s" , networkDomainId ) ; final NetworkDomain networkDomain = networkApi . getNetworkDomain ( networkDomainId ) ; final boolean isDeleted = networkDomain == null && state == State . DELETED ; return isDeleted || ( networkDomain != null && networkDomain . state ( ) == state ) ; }
@ Override public boolean apply ( final String customerImageId ) { checkNotNull ( customerImageId , "customerImageId" ) ; logger . info ( "current customerImageId: " + customerImageId ) ; final CustomerImage customerImage = serverImageApi . getCustomerImage ( customerImageId ) ; final boolean isDeleted = customerImage == null && state == State . DELETED ; return isDeleted || ( customerImage != null && customerImage . state ( ) == state ) ; }
@ Override public List < Image > call ( ) throws Exception { logger . trace ( "<< fetching images.." ) ; Iterable < Image > filteredImages = Iterables . filter ( api . imageApi ( ) . getList ( new DepthOptions ( ) . depth ( 1 ) ) , new Predicate < Image > ( ) { @ Override public boolean apply ( Image image ) { return image . properties ( ) . imageType ( ) == Image . Type . HDD ; } } ) ; logger . trace ( ">> images fetched." ) ; return ImmutableList . copyOf ( filteredImages ) ; }
@ Override public List < Image > call ( ) throws Exception { logger . trace ( "<< fetching images.." ) ; Iterable < Image > filteredImages = Iterables . filter ( api . imageApi ( ) . getList ( new DepthOptions ( ) . depth ( 1 ) ) , new Predicate < Image > ( ) { @ Override public boolean apply ( Image image ) { return image . properties ( ) . imageType ( ) == Image . Type . HDD ; } } ) ; logger . trace ( ">> images fetched." ) ; return ImmutableList . copyOf ( filteredImages ) ; }
@ Override public void rebootNode ( String id ) { String virtualMachineId = id ; String job = client . getVirtualMachineApi ( ) . rebootVirtualMachine ( virtualMachineId ) ; if ( job != null ) { logger . debug ( ">> rebooting virtualMachine(%s) job(%s)" , virtualMachineId , job ) ; awaitCompletion ( job ) ; } }
@ Override public void resumeNode ( String id ) { String virtualMachineId = id ; String job = client . getVirtualMachineApi ( ) . startVirtualMachine ( id ) ; if ( job != null ) { logger . debug ( ">> starting virtualMachine(%s) job(%s)" , virtualMachineId , job ) ; awaitCompletion ( job ) ; } }
@ Override public Set < ? extends NodeMetadata > listNodesDetailsMatching ( Predicate < ? super NodeMetadata > filter ) { checkNotNull ( filter , "filter" ) ; logger . trace ( ">> listing node details matching(%s)" , filter ) ; Set < ? extends NodeMetadata > set = newLinkedHashSet ( listNodesStrategy . listDetailsOnNodesMatching ( filter ) ) ; logger . trace ( "<< list(%d)" , set . size ( ) ) ; return set ; }
@ Override public Set < ? extends NodeMetadata > listNodesDetailsMatching ( Predicate < ? super NodeMetadata > filter ) { checkNotNull ( filter , "filter" ) ; logger . trace ( ">> listing node details matching(%s)" , filter ) ; Set < ? extends NodeMetadata > set = newLinkedHashSet ( listNodesStrategy . listDetailsOnNodesMatching ( filter ) ) ; logger . trace ( "<< list(%d)" , set . size ( ) ) ; return set ; }
private void cleanupAutoGeneratedKeyPairs ( Set < Integer > generatedSshKeyIds ) { logger . debug ( ">> cleaning up auto-generated key pairs..." ) ; for ( Integer sshKeyId : generatedSshKeyIds ) { try { api . keyApi ( ) . delete ( sshKeyId ) ; } catch ( Exception ex ) { logger . warn ( ">> could not delete key pair %s: %s" , sshKeyId , ex . getMessage ( ) ) ; } } }
private void cleanupAutoGeneratedKeyPairs ( Set < Integer > generatedSshKeyIds ) { logger . debug ( ">> cleaning up auto-generated key pairs..." ) ; for ( Integer sshKeyId : generatedSshKeyIds ) { try { api . keyApi ( ) . delete ( sshKeyId ) ; } catch ( Exception ex ) { logger . warn ( ">> could not delete key pair %s: %s" , sshKeyId , ex . getMessage ( ) ) ; } } }
@ SuppressWarnings ( "serial" ) private void write ( ) { try { if ( ! file . exists ( ) ) { file . createNewFile ( ) ; } logger . info ( "Starting to write File; Access control!" ) ; FileWriter out = new FileWriter ( file ) ; gson . toJson ( clients , new TypeToken < Map < String , RegisteredClient > > ( ) { } . getType ( ) , out ) ; out . close ( ) ; } catch ( IOException e ) { logger . error ( "Could not write to output file" , e ) ; } }
@ SuppressWarnings ( "serial" ) private void write ( ) { try { if ( ! file . exists ( ) ) { logger . info ( "Creating saved clients list in " + file ) ; file . createNewFile ( ) ; } FileWriter out = new FileWriter ( file ) ; gson . toJson ( clients , new TypeToken < Map < String , RegisteredClient > > ( ) { } . getType ( ) , out ) ; out . close ( ) ; } catch ( IOException e ) { logger . error ( "Error while writing to input file" , e ) ; } }
@ Override public void signJwt ( SignedJWT jwt , JWSAlgorithm alg ) { JWSSigner signer = null ; for ( JWSSigner s : signers . values ( ) ) { if ( s . supportedJWSAlgorithms ( ) . contains ( alg ) ) { signer = s ; break ; } } if ( signer == null ) { logger . error ( "Missing JWT algorithm: " + alg ) ; } try { jwt . sign ( signer ) ; } catch ( JOSEException e ) { logger . error ( "Failed to sign JWT, error was: " , e ) ; } }
@ Override public void signJwt ( SignedJWT jwt , JWSAlgorithm alg ) { JWSSigner signer = null ; for ( JWSSigner s : signers . values ( ) ) { if ( s . supportedJWSAlgorithms ( ) . contains ( alg ) ) { signer = s ; break ; } } if ( signer == null ) { logger . error ( "No matching algirthm found for alg=" + alg ) ; } try { jwt . sign ( signer ) ; } catch ( JOSEException e ) { logger . error ( "Failed to sign JWT" , e ) ; } }
private OAuth2RefreshTokenEntity clearExpiredRefreshToken ( OAuth2RefreshTokenEntity token ) { if ( token == null ) { return null ; } else if ( token . isExpired ( ) ) { logger . debug ( "Clearing expired refresh token: " + token . getValue ( ) ) ; revokeRefreshToken ( token ) ; return null ; } else { return token ; } }
private void writeBlacklistedSites ( JsonWriter writer ) throws IOException { logger . info ( "Writing blacklisted sites" ) ; for ( BlacklistedSite blSite : blSiteRepository . getAll ( ) ) { writer . beginObject ( ) ; writer . name ( ID ) . value ( blSite . getId ( ) ) ; writer . name ( URI ) . value ( blSite . getUri ( ) ) ; writer . endObject ( ) ; } logger . info ( "Done writing blacklisted sites" ) ; }
private void writeBlacklistedSites ( JsonWriter writer ) throws IOException { for ( BlacklistedSite blSite : blSiteRepository . getAll ( ) ) { logger . debug ( "Wrote blacklisted site {}" , blSite . getId ( ) ) ; writer . beginObject ( ) ; writer . name ( ID ) . value ( blSite . getId ( ) ) ; writer . name ( URI ) . value ( blSite . getUri ( ) ) ; writer . endObject ( ) ; logger . debug ( "Wrote blacklisted site {}" , blSite . getId ( ) ) ; } }
@ Override protected int execute ( String [ ] args ) throws Exception { Configuration conf = getConf ( ) ; conf . set ( StageConstants . PROP_BATCH_ID , getBatchId ( ) ) ; conf . set ( StageConstants . PROP_FLOW_ID , getFlowId ( ) ) ; Job job = createJob ( conf ) ; LOG . debug ( "Executing job {}" , job ) ; return submit ( job ) ; }
@ Override public boolean run ( Job job ) throws IOException , InterruptedException , ClassNotFoundException { job . submit ( ) ; LOGGER . info ( "Job running" ) ; return job . waitForCompletion ( true ) ; }
@ Override public void write ( T model ) throws IOException { if ( requireGenerateHeader ) { requireGenerateHeader = false ; writeHeader ( ) ; } if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( "GenerateHeader: " + model ) ; } for ( FieldDriver < T , ? > field : fields ) { writer . putField ( fill ( model , field ) ) ; } try { writer . putEndOfRecord ( ) ; } catch ( UnmappableOutputException e ) { handleUnmappable ( model , e . getEntries ( ) ) ; } }
public static boolean isValid ( String name ) { if ( checkSyntax ( name ) == false ) { return false ; } try { Models . toName ( Models . getModelFactory ( ) , name ) ; return true ; } catch ( IllegalArgumentException e ) { LogUtils . warn ( "org.docear.plugin.services.features.setup.view.VerifyServicePagePanel.isValid(name): " + name + " is not a valid name." ) ; return false ; } }
public static boolean isValid ( String pattern ) { try { DecimalFormat format = new DecimalFormat ( ) ; format . applyPattern ( pattern ) ; return true ; } catch ( IllegalArgumentException e ) { logger . debug ( "Pattern [{}] is not a valid number" , pattern ) ; return false ; } }
private static void closeQuiet ( Object object ) { if ( object instanceof Closeable ) { try { ( ( Closeable ) object ) . close ( ) ; } catch ( IOException e ) { LOG . warn ( MessageFormat . format ( "Exception occurred while closing: {0}" , object ) , e ) ; } } }
public static < T > byte [ ] serialize ( Class < ? extends T > type , T object ) { ObjectMapper mapper = mapper ( ) ; try { byte [ ] bytes = mapper . writerWithDefaultPrettyPrinter ( ) . forType ( type ) . writeValueAsBytes ( object ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( "Serialize {} to {}" , type , StringUtils . join ( bytes , ", " ) ) ; } return bytes ; } catch ( JsonProcessingException e ) { throw new AssertionError ( e ) ; } }
public boolean isSymlink ( FileSystem fs , FileStatus file ) { try { return isSymlink0 ( fs , file ) ; } catch ( Exception e ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "Error occurred while checking symlink: " + e ) ; } return false ; } }
private static void handle ( CommandExecutionException e ) { logger . error ( "{}" , e . getMessage ( ) ) ; }
private Optional < FileStatus > stat ( Path path ) { try { return Optional . of ( dataSourceParameter . getHadoopFileSystem ( path ) . getFileStatus ( path ) ) ; } catch ( FileNotFoundException e ) { LOG . debug ( "No Hadoop path found in Hadoop path: {}" , path ) ; return Optional . empty ( ) ; } catch ( IOException e ) { throw new CommandConfigurationException ( MessageFormat . format ( "error occurred while resolving Hadoop path: {0}" , path ) , e ) ; } }
private void message ( Diagnostic . Kind kind , Element element , String pattern , Object ... arguments ) { assert kind != null ; assert element != null ; assert pattern != null ; assert arguments != null ; String message = arguments . length == 0 ? pattern : MessageFormat . format ( pattern , arguments ) ; if ( kind == Diagnostic . Kind . NOTE ) { log . info ( message ) ; } else { environment . getProcessingEnvironment ( ) . getMessager ( ) . printMessage ( kind , message , element ) ; } }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 13 , 14 , 15 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}" , 7 , 8 , 9 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 13 , 14 , 15 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 13 , 14 , 15 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}" , 13 , 14 , 15 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: {}" , false ) ; }
public void truncate ( ExporterDescription description ) throws IOException { logger . info ( "Truncating exporter: " + description ) ; TestModerator moderator = new TestModerator ( getTestTools ( ) , this ) ; moderator . truncate ( description ) ; }
private static void clean ( ) { try { FileSystem . closeAll ( ) ; } catch ( IOException e ) { LOGGER . error ( "Error during file clean" , e ) ; } }
@ Override protected void handle ( IOException exception ) throws IOException { exceptions . record ( exception ) ; WGLOG . error ( exception , "E05003" , script . getName ( ) , script . getSourceScript ( ) . getResourceName ( ) , script . getDrainScript ( ) . getResourceName ( ) ) ; }
@ Override public ResourceMirror create ( String sessionId , ParameterList arguments ) throws IOException { if ( sessionId == null ) { throw new IllegalArgumentException ( "sessionId must not be null" ) ; } if ( arguments == null ) { throw new IllegalArgumentException ( "arguments must not be null" ) ; } LOG . debug ( "Creating HadoopFsMirror for session {}" , sessionId ) ; return new HadoopFsMirror ( configuration , hfsProfile , arguments ) ; }
@ Override public ResourceMirror create ( String sessionId , ParameterList arguments ) throws IOException { if ( sessionId == null ) { throw new IllegalArgumentException ( "sessionId must not be null" ) ; } if ( arguments == null ) { throw new IllegalArgumentException ( "arguments must not be null" ) ; } LOG . debug ( "Creating JschHadoopFsMirror({}, {})" , sessionId , arguments ) ; return new JschHadoopFsMirror ( configuration , sshProfile , arguments ) ; }
public static FileList . Reader createReader ( InputStream input ) throws IOException { if ( input == null ) { throw new IllegalArgumentException ( "input must not be null" ) ; } WGLOG . info ( "Creating input stream" ) ; byte [ ] dropped = FileListUtil . dropPreamble ( input , PREAMBLE_MARGIN ) ; if ( dropped . length >= 1 ) { WGLOG . warn ( "W19002" , new String ( dropped , Charset . defaultCharset ( ) ) ) ; } return new Reader ( input ) ; }
public static FileList . Reader createReader ( InputStream input ) throws IOException { if ( input == null ) { throw new IllegalArgumentException ( "input must not be null" ) ; } LOG . debug ( "Creating a new file list reader" ) ; byte [ ] dropped = FileListUtil . dropPreamble ( input , PREAMBLE_MARGIN ) ; if ( dropped . length >= 1 ) { LOG . warn ( "There are still {} files dropped. Error: {}" , dropped . length , dropped ) ; } return new Reader ( input ) ; }
private static void extractCompressionCodec ( Configuration configuration , ResourceProfile profile ) { assert configuration != null ; assert profile != null ; String compressionCodecString = extract ( profile , KEY_COMPRESSION , false ) ; if ( compressionCodecString != null ) { WGLOG . warn ( "W00001" , profile . getName ( ) , KEY_COMPRESSION , compressionCodecString ) ; } }
private PreparedStatement prepareStatement ( ) throws SQLException { String sql = createSql ( ) ; logger . trace ( "Preparing: {}" , sql ) ; return connection . prepareStatement ( sql ) ; }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . info ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting file: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Successfully deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . info ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting file: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . warn ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private static void addArgument ( Map < String , String > results , String key , String value ) { assert results != null ; assert key != null ; assert value != null ; if ( results . containsKey ( key ) ) { LOGGER . warn ( "Argument {} was already set. Skipping argument execution." , key ) ; } else { results . put ( key , value ) ; } }
public static void main ( String ... args ) { CommandLineUtil . prepareLogContext ( ) ; CommandLineUtil . prepareRuntimeContext ( ) ; WGLOG . info ( "I01999" ) ; long start = System . currentTimeMillis ( ) ; int status = execute ( args ) ; long end = System . currentTimeMillis ( ) ; WGLOG . info ( "I01999" , status , end - start ) ; System . exit ( status ) ; }
public static void main ( String ... args ) { CommandLineUtil . prepareLogContext ( ) ; CommandLineUtil . prepareRuntimeContext ( ) ; WGLOG . info ( "I01000" ) ; long start = System . currentTimeMillis ( ) ; int status = execute ( args ) ; long end = System . currentTimeMillis ( ) ; WGLOG . info ( "I01000" , status , end - start ) ; System . exit ( status ) ; }
static int exec ( String ... args ) { if ( args . length == 0 ) { LOG . error ( MessageFormat . format ( "no arguments: {0}" , args ) ) ; return - 1 ; } boolean sawError = false ; Configuration conf = new Configuration ( ) ; for ( String arg : args ) { try { delete ( conf , new Path ( arg ) ) ; } catch ( IOException e ) { LOG . error ( MessageFormat . format ( "failed to delete file: {0}" , arg ) , e ) ; sawError = true ; } } return sawError ? 1 : 0 ; }
static int exec ( String ... args ) { if ( args . length == 0 ) { LOG . warn ( "there are no files to delete" ) ; return - 1 ; } boolean sawError = false ; Configuration conf = new Configuration ( ) ; for ( String arg : args ) { try { delete ( conf , new Path ( arg ) ) ; } catch ( IOException e ) { LOG . warn ( "Unable to delete path " + arg ) ; sawError = true ; } } return sawError ? 1 : 0 ; }
@ Override public void execute ( ExecutionMonitor monitor , ExecutionContext context , T script ) throws InterruptedException , IOException { LOG . debug ( "execute with script: {}" , script ) ; ExecutionScriptHandler < T > target = resolve ( context , script ) ; assert target != null ; target . execute ( monitor , context , script ) ; }
public static String getHostname ( ) { if ( Netshot . hostname == null ) { try { Process process = Runtime . getRuntime ( ) . exec ( "hostname" ) ; BufferedReader stdInput = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) ; Netshot . hostname = stdInput . readLine ( ) ; } catch ( IOException e ) { logger . warn ( "Unable to read the hostname from the database process." , e ) ; } if ( Netshot . hostname == null ) { Netshot . hostname = "unknown" ; } } return Netshot . hostname ; }
public static void init ( ) { if ( Netshot . getConfig ( "netshot.tftpserver.disabled" , "true" ) . equals ( "true" ) ) { logger . warn ( "The telemetry server is disabled by configuration." ) ; return ; } nsTftpServer = new TftpServer ( ) ; nsTftpServer . start ( ) ; }
@ Override public void info ( String message ) { log . info ( printConsole ( ChatColor . RESET + ChatColor . BOLD + message , colored ) ) ; }
@ Override public void disconnect ( ) { try { if ( channel != null ) { channel . disconnect ( ) ; } if ( session != null ) { session . disconnect ( ) ; } } catch ( Exception e ) { logger . warn ( "Connection to {} failed to {}: {}" , host , port , e . getMessage ( ) ) ; } }
@ Override public void createDirectory ( Path dir , FileAttribute < ? > ... attrs ) throws IOException { logger . warn ( "Request to create directory {} in {}." , dir , Arrays . toString ( attrs ) ) ; throw new SecurityException ( "Creation of directory " + dir + " is denied." ) ; }
@ Override public void stop ( ) { for ( Method method : o . getClass ( ) . getMethods ( ) ) { if ( method . getAnnotation ( LifecycleStop . class ) != null ) { log . info ( "Stopping method[%s] on object[%s]" , method , o ) ; try { method . invoke ( o ) ; } catch ( Exception e ) { log . error ( e , "Exception when stopping method[%s] on object[%s]" , method , o ) ; } } } }
@ Override public void stop ( ) { for ( Method method : o . getClass ( ) . getMethods ( ) ) { if ( method . getAnnotation ( LifecycleStop . class ) != null ) { log . info ( "Invoking stop method[%s] on object[%s]." , method , o ) ; try { method . invoke ( o ) ; } catch ( Exception e ) { log . error ( e , "Error calling stop method[%s]" , method ) ; } } } }
@ Override public void start ( ) throws Exception { log . trace ( "start()" ) ; startMethod . invoke ( o ) ; }
public void error ( Throwable t , String message , Object ... formatArgs ) { log . error ( StringUtils . safeFormat ( message , formatArgs ) , t ) ; }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter [%s]." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]" , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter %s." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]" , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter [%s]." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]." , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override public void handle ( Exception exception ) { if ( exceptionCount % 1000 == 0 ) { logger . error ( "Error in processing message " + exception . getMessage ( ) ) ; } exceptionCount += 1 ; }
@ Override public void close ( ChannelFuture resource ) { logger . trace ( "Async Closing Done {}" , resource ) ; resource . awaitUninterruptibly ( ) . getChannel ( ) . close ( ) ; }
private Integer getGeneralizedPatternID ( OWLAxiom axiom ) { try { selectGeneralizedPatternIdPs . setString ( 1 , render ( axiom ) ) ; try ( ResultSet rs = selectGeneralizedPatternIdPs . executeQuery ( ) ) { if ( rs . next ( ) ) { return rs . getInt ( 1 ) ; } } } catch ( SQLException e ) { LOGGER . error ( "Failed to get generalized pattern ID." , e ) ; } return null ; }
private synchronized void addOntologyImport ( URI physicalURI1 , OWLOntology ontology1 , URI physicalURI2 , OWLOntology ontology2 ) { Integer ontologyID1 = getOntologyID ( physicalURI1 , ontology1 ) ; Integer ontologyID2 = getOntologyID ( physicalURI2 , ontology2 ) ; try { insertOntologyImportPs . setInt ( 1 , ontologyID1 ) ; insertOntologyImportPs . setInt ( 2 , ontologyID2 ) ; insertOntologyImportPs . execute ( ) ; } catch ( SQLException e ) { logger . error ( "Error inserting ontology import" , e ) ; } }
@ Override public SortedSet < OWLIndividual > getIndividualsImpl ( OWLClassExpression ce ) { Set < OWLNamedIndividual > individuals ; try { individuals = reasoner . getInstances ( ce , false ) . getFlattened ( ) ; } catch ( UnsupportedOperationException e ) { if ( useFallbackReasoner ) { individuals = fallbackReasoner . getInstances ( ce , false ) . getFlattened ( ) ; } else { log . debug ( "Could not retrieve individuals" ) ; throw e ; } } return new TreeSet < > ( individuals ) ; }
@ SuppressWarnings ( "unused" ) private void makeNegativeExamplesFromRange ( String role , int sparqlResultSetLimit ) { logger . debug ( "making Negative Examples from Range of : " + role ) ; fromRange . addAll ( sparqltasks . getRangeInstances ( role , sparqlResultSetLimit ) ) ; fromRange . removeAll ( fullPositiveSet ) ; logger . debug ( "|-neg Example size from Range: " + fromRange . size ( ) ) ; }
@ SuppressWarnings ( "unused" ) private void makeNegativeExamplesFromRange ( String role , int sparqlResultSetLimit ) { logger . debug ( "making Negative Examples from Range of : " + role ) ; fromRange . addAll ( sparqltasks . getRangeInstances ( role , sparqlResultSetLimit ) ) ; fromRange . removeAll ( fullPositiveSet ) ; logger . debug ( "|-neg Example size from Range: " + this . fromRange . size ( ) ) ; }
private List < String > getResultSplitted ( String sparqlQuery ) { Query query = QueryFactory . create ( sparqlQuery ) ; List < Query > queries = QueryRewriter . split ( query ) ; List < String > resources = getResult ( queries . remove ( 0 ) . toString ( ) ) ; queries . stream ( ) . map ( q -> getResult ( q . toString ( ) ) ) . forEach ( resources :: retainAll ) ; LOGGER . debug ( "{} splitted {} results" , resources , sparqlQuery ) ; return resources ; }
@ Override public void init ( ) throws ComponentInitException { if ( edge == null ) { String msg = "Underlying EDGE class not instantiated" ; logger . debug ( msg ) ; throw new ComponentInitException ( msg ) ; } logger . debug ( "Initializing EDGE" ) ; fullyInitialized = false ; super . init ( ) ; }
@ Override public void init ( ) throws ComponentInitException { if ( edge == null ) { String msg = "Underlying EDGE class not instantiated" ; logger . error ( msg ) ; throw new ComponentInitException ( msg ) ; } fullyInitialized = false ; super . init ( ) ; logger . info ( "RemoteGroupInfoInitialized" ) ; }
private Set < Set < OWLAxiom > > computeExplanations ( OWLOntology ontology ) { logger . info ( "Computing explanations..." ) ; long startTime = System . currentTimeMillis ( ) ; boolean useGlassBox = true ; PelletExplanation expGen = new PelletExplanation ( ontology , useGlassBox ) ; Set < Set < OWLAxiom > > explanations = expGen . getInconsistencyExplanations ( maxNrOfExplanations ) ; logger . info ( "...done in " + ( System . currentTimeMillis ( ) - startTime ) + "ms." ) ; return explanations ; }
private Set < Set < OWLAxiom > > computeExplanations ( OWLOntology ontology ) { logger . info ( "Computing explanations..." ) ; long startTime = System . currentTimeMillis ( ) ; boolean useGlassBox = true ; PelletExplanation expGen = new PelletExplanation ( ontology , useGlassBox ) ; Set < Set < OWLAxiom > > explanations = expGen . getInconsistencyExplanations ( maxNrOfExplanations ) ; logger . info ( "Explanations took {}ms" , System . currentTimeMillis ( ) - startTime ) ; return explanations ; }
public int getSymLinkDepth ( ) { int value = 0 ; try { value = Integer . parseInt ( line . getOptionValue ( ARGUMENT . SYM_LINK_DEPTH , "0" ) ) ; if ( value < 0 ) { value = 0 ; } } catch ( NumberFormatException ex ) { logger . warn ( "Could not parse symlink depth: {}" , ex . getMessage ( ) ) ; } return value ; }
private boolean checkEnabled ( ) { try { return getSettings ( ) . getBoolean ( Settings . KEYS . ANALYZER_CENTRAL_ENABLED ) ; } catch ( InvalidSettingException ise ) { LOGGER . warn ( "Invalid setting. Disabling the setting." ) ; } return false ; }
@ Override public void prepareAnalyzer ( Engine engine ) throws InitializationException { try { loadHintRules ( ) ; } catch ( HintParseException ex ) { throw new InitializationException ( "Unable to parse the hint file" , ex ) ; } LOGGER . debug ( "Could not initialize the hint file" ) ; }
public static boolean isH2Connection ( Settings configuration ) { final String connStr ; try { connStr = configuration . getConnectionString ( Settings . KEYS . DB_CONNECTION_STRING , Settings . KEYS . DB_FILE_NAME ) ; } catch ( IOException ex ) { logger . error ( "Unable to get connection string from settings." , ex ) ; return false ; } return isH2Connection ( connStr ) ; }
private void given ( CharSequence s , int wanted , int got ) { logger . debug ( "about to call given {} wanted {} {}" , s , wanted , got ) ; red . append ( s ) ; given += got ; }
public synchronized void cleanup ( boolean deleteTemporary ) { if ( deleteTemporary && tempDirectory != null && tempDirectory . exists ( ) ) { LOGGER . debug ( "Deleting temporary directory: {}" , tempDirectory ) ; FileUtils . delete ( tempDirectory ) ; tempDirectory = null ; } }
public void toStop ( ) { toStop = true ; logrThread . interrupt ( ) ; try { logrThread . join ( ) ; } catch ( InterruptedException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ ExceptionHandler ( ServiceException . class ) public AjaxResult < Void > handleServiceException ( ServiceException e , HttpServletRequest request ) { log . error ( e . getMessage ( ) , e ) ; Integer code = e . getCode ( ) ; return StringUtils . isNotNull ( code ) ? AjaxResult . error ( code , e . getMessage ( ) ) : AjaxResult . error ( e . getMessage ( ) ) ; }
public void associateEnvironmentToJndi ( JNDIResourceModel resource , EnvironmentReferenceModel ref ) { if ( ref . getJndiReference ( ) == null ) { log . warn ( "could not associate environment reference with JNDI reference: " + ref . getReferenceType ( ) ) ; ref . setJndiReference ( resource ) ; } jndiResourceService . associateTypeJndiResource ( resource , ref . getReferenceType ( ) ) ; }
@ Override public void perform ( GraphRewrite event , EvaluationContext context , ArchiveModel archive ) { LOG . info ( "Deleting {}." , archive . getUnzippedDirectory ( ) ) ; FileUtils . deleteQuietly ( new File ( archive . getUnzippedDirectory ( ) ) ) ; }
@ Override public void perform ( GraphRewrite event , EvaluationContext context , JavaTypeReferenceModel payload ) { firstRuleMatchCount ++ ; log . info ( "First rule matched: " + payload . getFile ( ) . getFilePath ( ) ) ; }
private void installOldAddonVersion ( String currentUiVersion ) { RemoveRequest remove = manager . remove ( AddonId . from ( WINDUP_UI_ADDON_NAME , currentUiVersion ) ) ; remove . perform ( ) ; final AddonId olderAddonId = AddonId . from ( WINDUP_UI_ADDON_NAME , WINDUP_OLD_VERSION ) ; InstallRequest install = manager . install ( olderAddonId ) ; install . perform ( ) ; LOG . info ( "Removed old addon version {}" , currentUiVersion ) ; }
public void end ( ) { if ( this . startTime == 0 ) { return ; } this . totalNanos += ( System . nanoTime ( ) - startTime ) ; this . startTime = 0 ; this . numberOfExecutions ++ ; log . info ( String . format ( "Completed %.2f ms %.3f ms %.3f ms %.3f ms" , this . totalNanos , this . count , this . totalNanos , this . durationMs * 100f / this . numberOfExecutions ) ) ; }
private ArrayList getRoleValue ( String relationId , String roleName ) { Logger logger = getLogger ( ) ; try { Object [ ] params = { relationId , roleName } ; String [ ] signature = { "java.lang.String" , "java.lang.String" } ; return ( ( ArrayList ) ( m_server . invoke ( m_relationObjectName , "getRole" , params , signature ) ) ) ; } catch ( Exception ex ) { logger . error ( ex . getMessage ( ) , ex ) ; return null ; } }
@ Override protected void logWarning ( String description , String message ) { log . debug ( description ) ; log . debug ( message ) ; }
@ Override protected void logWarning ( String description , String message ) { log . debug ( description ) ; log . debug ( message ) ; }
@ GET @ Timed @ Produces ( APPLICATION_JSON_WITH_CHARSET ) public String list ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph , @ QueryParam ( "limit" ) @ DefaultValue ( "100" ) long limit ) { LOG . debug ( "Graph [{}] list targets" , graph ) ; HugeGraph g = graph ( manager , graph ) ; List < HugeTarget > targets = manager . authManager ( ) . listAllTargets ( limit ) ; return manager . serializer ( g ) . writeAuthElements ( "targets" , targets ) ; }
@ DELETE @ Timed @ Path ( "{id}" ) public void delete ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph , @ PathParam ( "id" ) long id ) { LOG . debug ( "Graph [{}] delete task: {}" , graph , id ) ; TaskScheduler scheduler = graph ( manager , graph ) . taskScheduler ( ) ; HugeTask < ? > task = scheduler . delete ( IdGenerator . of ( id ) ) ; E . checkArgument ( task != null , "There is no task with id '%s'" , id ) ; }
@ GET @ Timed @ Produces ( APPLICATION_JSON_WITH_CHARSET ) public Map < String , Object > list ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph ) { LOG . debug ( "Graph [{}] list data" , graph ) ; HugeGraph g = graph ( manager , graph ) ; return g . variables ( ) . asMap ( ) ; }
@ Override public void close ( ) { LOG . debug ( "Store close: {}" , this . store ) ; this . sessions . close ( ) ; }
private SysTransaction openSystemTransaction ( ) throws HugeException { this . checkGraphNotClosed ( ) ; try { return new SysTransaction ( this . params , loadSystemStore ( ) ) ; } catch ( BackendException e ) { String message = "Failed to open system transaction" ; LOG . error ( "{}" , message , e ) ; throw new HugeException ( message ) ; } }
protected final void notifyAndWaitEvent ( String event ) { Future < ? > future = this . storeEventHub . notify ( event , this ) ; try { future . get ( ) ; } catch ( Throwable e ) { LOG . warn ( "Error when waiting for event execution: {}" , event , e ) ; } }
public boolean close ( ) { logger . debug ( "Closing session" ) ; Pair < Integer , Integer > result = Pair . of ( - 1 , - 1 ) ; try { result = this . closeSession ( ) ; } finally { if ( result . getLeft ( ) == 0 ) { this . doClose ( ) ; } } return result . getLeft ( ) == 0 ; }
@ Override public Iterator < BackendEntry > query ( Query query ) { InMemoryDBTable table = this . table ( InMemoryDBTable . tableType ( query ) ) ; Iterator < BackendEntry > rs = table . query ( null , query ) ; LOG . debug ( "[store {}] get result({}) for query: {}" , this . store , rs , query ) ; return rs ; }
@ Override public synchronized BackendStore loadSchemaStore ( final String name ) { if ( this . schemaStore == null ) { LOG . info ( "Init raft backend schema store" ) ; BackendStore store = this . provider . loadSchemaStore ( name ) ; this . checkNonSharedStore ( store ) ; this . schemaStore = new RaftBackendStore ( store , this . context ) ; this . context . addStore ( StoreType . SCHEMA , this . schemaStore ) ; } return this . schemaStore ; }
@ Override public void run ( Status status ) { if ( status . isOk ( ) ) { this . complete ( status , ( ) -> null ) ; } else { String msg = "Failed to apply command in raft node with error: " + status . getErrorMsg ( ) ; LOG . warn ( msg ) ; this . failure ( status , new BackendException ( msg ) ) ; } }
@ Override public void onLeaderStart ( long term ) { LOG . info ( "The node {} abdicated from leader" , this . node ( ) . nodeId ( ) ) ; this . node ( ) . onLeaderInfoChange ( this . context . endpoint ( ) , true ) ; super . onLeaderStart ( term ) ; }
@ Watched ( prefix = "tx" ) @ Override public void rollback ( ) throws BackendException { log . debug ( "rollback" ) ; this . reset ( ) ; if ( this . committing2Backend ) { this . committing2Backend = false ; this . store . rollbackTx ( ) ; } }
private HugeVertex parseEntry ( BackendEntry entry ) { try { HugeVertex vertex = this . serializer . readVertex ( graph ( ) , entry ) ; assert vertex != null ; return vertex ; } catch ( ForbiddenException | SecurityException e ) { throw e ; } catch ( Throwable e ) { if ( this . ignoreInvalidEntry ) { LOG . warn ( "Invalid edge: {}" , entry , e ) ; return null ; } throw e ; } }
public boolean fail ( Throwable e ) { E . checkNotNull ( e , "exception" ) ; if ( ! ( this . cancelled ( ) && HugeException . isInterrupted ( e ) ) ) { if ( this . result ( TaskStatus . FAILED , e . toString ( ) ) ) { LOG . error ( "The query failed: {}" , e . toString ( ) , e ) ; return true ; } } return false ; }
private void scheduleOrExecuteJob ( ) { try { for ( TaskScheduler entry : this . schedulers . values ( ) ) { StandardTaskScheduler scheduler = ( StandardTaskScheduler ) entry ; synchronized ( scheduler ) { this . scheduleOrExecuteJobForGraph ( scheduler ) ; } } } catch ( Throwable e ) { LOG . error ( "Exception while scheduling or execute job" , e ) ; } }
public void start ( String name ) { this . ending = false ; this . exception = null ; if ( this . executor == null ) { return ; } for ( int i = 0 ; i < this . workers ; i ++ ) { this . executor . submit ( new ContextCallable < > ( this :: runAndDone ) ) ; } log . info ( "Started " + name ) ; }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer stopped" ) ; }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer stopped" ) ; }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer started" ) ; }
public static void showFeatures ( final HugeGraph graph ) { LOG . debug ( "Graph [{}] showFeatures" , graph ) ; }
public static void main ( String [ ] args ) throws Exception { LOG . info ( "ExampleUtil start!" ) ; HugeGraph graph = ExampleUtil . loadGraph ( ) ; testTask ( graph ) ; graph . close ( ) ; HugeFactory . shutdown ( 30L ) ; }
protected void truncateTable ( Session session ) { LOG . debug ( "Truncate table: {}" , this . table ( ) ) ; String sql = this . buildTruncateTemplate ( ) ; try { session . execute ( sql ) ; } catch ( SQLException e ) { throw new BackendException ( "Failed to truncate table with '%s'" , e , sql ) ; } }
@ Override public void close ( ) { this . checkOpened ( ) ; this . closeSessions ( ) ; LOG . debug ( "Store closed: {}" , this . store ) ; }
private void markDataError ( String s ) { dataErrors . add ( s ) ; LOGGER . warn ( "Data error: {}" , s ) ; }
public void Verify ( ) { List < Document > docs = getAllDocs ( ) ; for ( Document doc : docs ) { try { org . apache . lucene . document . Document ldoc = this . getLuceneDoc ( doc . getUniqueId ( ) ) ; if ( ldoc == null ) { log . error ( "Lucene document not found" ) ; } } catch ( IOException e ) { e . printStackTrace ( ) ; } } }
public String getFromEmailAddress ( ) { if ( from != null && from . length > 0 ) { if ( from . length > 1 ) { log . warn ( "EMAIL ADDRESS is more than 1 bytes. " ) ; for ( Address f : from ) log . warn ( f ) ; } if ( from [ 0 ] instanceof InternetAddress ) return ( ( InternetAddress ) from [ 0 ] ) . getAddress ( ) . toLowerCase ( ) ; else return "<NOT INTERNET ADDRESS>" ; } return "<NO FROM EMAIL ADDRESS!?>" ; }
static private Directory createDirectory ( String baseDir , String name ) throws IOException { File f = new File ( baseDir ) ; f . mkdir ( ) ; String index_dir = baseDir + File . separator + INDEX_BASE_DIR_NAME ; f = new File ( index_dir ) ; boolean b = f . mkdir ( ) ; if ( ! f . exists ( ) || ! f . isDirectory ( ) ) { log . error ( "index directory " + index_dir + " does not exist or is a directory" ) ; return null ; } return FSDirectory . open ( new File ( index_dir + File . separator + name ) . toPath ( ) ) ; }
void setupForWrite ( ) throws IOException { setupDirectory ( ) ; LOG . debug ( "Setting up document id mapping for write directory {}" , directory ) ; if ( iwriter == null ) iwriter = openIndexWriter ( directory ) ; if ( iwriter_blob == null ) iwriter_blob = openIndexWriter ( directory_blob ) ; dirNameToDocIdMap = new LinkedHashMap < > ( ) ; }
public static Set < String > getTopAdjectives ( ) { if ( adjectives == null ) { adjectives = getCanonicalizedEntriesInFile ( adjFile ) ; log . info ( "Read " + adjectives . size ( ) + " entries from " + adjFile ) ; return adjectives ; } return adjectives ; }
public static Span [ ] tokenizeSentenceAsSpan ( String text ) { try { return sentenceDetector . sentPosDetect ( text ) ; } catch ( IllegalArgumentException e ) { e . printStackTrace ( ) ; log . error ( "Could not find a sentence to issue: " + text ) ; return null ; } }
public static Archive getArchive ( Multimap < String , String > params ) { String archiveID = JSPHelper . getParam ( params , "archiveID" ) ; if ( archiveID == null ) { log . error ( "No archive ID to get" ) ; return null ; } return ArchiveReaderWriter . getArchiveForArchiveID ( archiveID ) ; }
public Annotation [ ] getAnnotations ( ) { if ( model != null && this . refreshOnGet ) { try { Annotation [ ] refresh = findAnnotationPropertyValues ( SpdxRdfConstants . SPDX_NAMESPACE , SpdxRdfConstants . PROP_ANNOTATION ) ; if ( refresh == null || ! arraysEquivalent ( refresh , this . annotations , true ) ) { this . annotations = refresh ; } } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Invalid annotation in the model" ) ; } } return annotations ; }
public Relationship [ ] getRelationships ( ) { if ( model != null && this . refreshOnGet ) { try { Relationship [ ] refresh = findRelationshipPropertyValues ( SpdxRdfConstants . SPDX_NAMESPACE , SpdxRdfConstants . PROP_RELATIONSHIP ) ; if ( refresh != null && ! arraysEquivalent ( refresh , this . relationships , true ) ) { this . relationships = refresh ; } } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Invalid model relationship in model" ) ; } } return relationships ; }
@ Override public ReferenceType clone ( ) { try { return new ReferenceType ( this . referenceTypeUri , this . contextualExample , this . documentation , this . externalReferenceSite ) ; } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Failed to clone SPDX" , e ) ; throw new AssertionError ( "Clone should never cause an Invalid SPDX Exception" , e ) ; } }
@ Override public void sessionNegotiationCompleted ( boolean success , String msg ) { if ( success ) { if ( sender != null ) { sender . setZRTP ( null ) ; } if ( receiver != null ) { receiver . setZRTP ( null ) ; } String sas = zrtp . getSasString ( ) ; logger . debug ( "*** SAS: " + sas ) ; callSecured ( sas ) ; } else { logger . info ( "*** ZRTP failure - call proceeding un-encrypted ***" ) ; } }
@ Override public void sessionNegotiationCompleted ( boolean success , String msg ) { logger . info ( "*********** Got callback from ZRTP: " + success + ", " + msg ) ; if ( success ) { if ( sender != null ) { sender . setZRTP ( null ) ; } if ( receiver != null ) { receiver . setZRTP ( null ) ; } String sas = zrtp . getSasString ( ) ; callSecured ( sas ) ; } else { logger . info ( "*********** Got Bind callback from ZRTP to no receiver" ) ; } }
@ Override public void processDeliverSm ( DeliverSm deliverSm ) throws ProcessRequestException { try { fireAcceptDeliverSm ( deliverSm ) ; } catch ( ProcessRequestException e ) { throw e ; } catch ( Exception e ) { String msg = "Invalid runtime exception thrown when processing deliver_sm" ; logger . error ( msg , e ) ; throw new ProcessRequestException ( msg , SMPPConstant . STAT_ESME_RX_T_APPN ) ; } }
@ Override public void sendDataSmResp ( DataSmResult dataSmResult , int sequenceNumber ) throws IOException { try { pduSender ( ) . sendDataSmResp ( out , sequenceNumber , dataSmResult . getMessageId ( ) , dataSmResult . getOptionalParameters ( ) ) ; } catch ( PDUStringException e ) { logger . error ( "Failed sending data_sm_resp" , e ) ; } }
private void fireAcceptCancelSm ( CancelSm cancelSm ) throws ProcessRequestException { if ( messageReceiverListener != null ) { messageReceiverListener . onAcceptCancelSm ( cancelSm , this ) ; } else { logger . warn ( MESSAGE_RECEIVER_LISTENER_IS_NULL , "cancel_sm" ) ; throw new ProcessRequestException ( NO_MESSAGE_RECEIVER_LISTENER_REGISTERED , SMPPConstant . STAT_ESME_RX_R_APPN ) ; } }
private QueryBroadcastSmResult fireAcceptQueryBroadcastSm ( QueryBroadcastSm queryBroadcastSm ) throws ProcessRequestException { if ( messageReceiverListener != null ) { return messageReceiverListener . onAcceptQueryBroadcastSm ( queryBroadcastSm , this ) ; } logger . warn ( MESSAGE_RECEIVER_LISTENER_IS_NULL , "query_broadcast_sm" ) ; throw new ProcessRequestException ( NO_MESSAGE_RECEIVER_LISTENER_REGISTERED , SMPPConstant . STAT_ESME_RX_R_APPN ) ; }
@ Override public void sendBindResp ( String systemId , InterfaceVersion interfaceVersion , BindType bindType , int sequenceNumber ) throws IOException { sessionContext . bound ( bindType ) ; try { pduSender ( ) . sendBindResp ( out , bindType . responseCommandId ( ) , sequenceNumber , systemId , interfaceVersion ) ; } catch ( PDUStringException e ) { logger . error ( "Failed sending bind response" , e ) ; } }
@ Override public void processReplaceSm ( ReplaceSm replaceSm ) throws ProcessRequestException { try { fireAcceptReplaceSm ( replaceSm ) ; } catch ( Exception e ) { String msg = "Invalid runtime exception thrown when processing replace_sm" ; logger . error ( msg , e ) ; throw new ProcessRequestException ( msg , SMPPConstant . STAT_ESME_RSYSERR ) ; } }
private void notifyNoActivity ( ) { logger . trace ( "No activity notified, sending enquire_link" ) ; enquireLinkSender . enquireLink ( ) ; }
@ Override public void run ( ) { while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . debug ( "{} stopped" , this . getName ( ) ) ; logger . trace ( "{} stopped" , this . getName ( ) ) ; }
@ Override public void run ( ) { logger . info ( "Starting PDUReaderWorker" ) ; while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . debug ( "{} stopped" , this . getName ( ) ) ; }
@ Override public void run ( ) { logger . info ( "Starting PDUReaderWorker" ) ; while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . info ( "PDUReaderWorker stopped" ) ; }
public void processUnbindResp ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { PendingResponse < Command > pendingResp = responseHandler . removeSentItem ( pduHeader . getSequenceNumber ( ) ) ; if ( pendingResp != null ) { UnbindResp resp = pduDecomposer . unbindResp ( pdu ) ; pendingResp . done ( resp ) ; } else { logger . error ( NO_REQUEST_FIND_FOR_SEQUENCE_NUMBER + pduHeader . getSequenceNumber ( ) ) ; } }
@ Override public void processDeliverSm ( Command pduHeader , byte [ ] pdu , OutboundServerResponseHandler responseHandler ) throws IOException { logger . info ( "Received deliver_sm in OUTBOUND state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override public void processEnquireLinkResp ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { PendingResponse < Command > pendingResp = responseHandler . removeSentItem ( pduHeader . getSequenceNumber ( ) ) ; if ( pendingResp != null ) { EnquireLinkResp resp = pduDecomposer . enquireLinkResp ( pdu ) ; pendingResp . done ( resp ) ; } else { logger . error ( "No request found for {}" , pduHeader ) ; } }
@ Override public void processUnbind ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { logger . info ( "Received unbind in OUTBOUND state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override public void processUnbind ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { logger . info ( "Received unbind in OUTBOUND state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override protected void doGet ( final HttpServletRequest request , final HttpServletResponse response ) throws IOException { try { handlePonyResource ( request , response ) ; } catch ( final IOException e ) { log . error ( "Cannot stream request" , e ) ; } }
public static void main ( String [ ] args ) { try { mainHelper ( args ) ; } catch ( ArgumentParserException exception ) { exception . getParser ( ) . handleError ( exception ) ; System . exit ( 1 ) ; } catch ( Throwable exception ) { LOGGER . error ( "Unexpected exception from command execution" , exception ) ; System . exit ( 1 ) ; } }
@ Override public void close ( ) throws IOException { log . info ( "Closing reader on {}" , path ) ; inputStream . close ( ) ; }
private void logAndPropagateException ( IOException e ) { LOGGER . error ( "Exception while handling request" , e ) ; throw new UncheckedIOException ( e ) ; }
public int deleteCoexpressionsProfile ( String experimentAccession ) { LOGGER . debug ( "Deleting RNASEQ_BSLN_CE_PROFILES and EXPERIMENT=?" ) ; return jdbcTemplate . update ( "DELETE FROM RNASEQ_BSLN_CE_PROFILES WHERE EXPERIMENT=?" , experimentAccession ) ; }
@ Override public void onTestFailure ( ITestResult result ) { LOGGER . debug ( "CarinaListener->onTestFailure" ) ; String errorMessage = getFailureReason ( result ) ; takeScreenshot ( result , "TEST FAILED - " + errorMessage ) ; onTestFinish ( result ) ; super . onTestFailure ( result ) ; }
@ Override public void onTestSkipped ( ITestResult result ) { LOGGER . debug ( "CarinaListener->onTestSkipped" ) ; onTestFinish ( result ) ; super . onTestSkipped ( result ) ; }
@ Test @ QTestCases ( id = TEST_ID ) @ QTestCases ( id = FIRST_TEST_ID ) public void testQTestMix ( ) { ITestResult result = Reporter . getCurrentTestResult ( ) ; Set < String > QTestUdids = getQTestCasesUuid ( result ) ; LOGGER . info ( "QTest: " + QTestUdids . toString ( ) ) ; Assert . assertTrue ( QTestUdids . contains ( VERIFICATION_PREFIX + FIRST_TEST_ID ) , "QTest should contain id=" + FIRST_TEST_ID ) ; Assert . assertEquals ( QTestUdids . size ( ) , 4 ) ; }
public static String getSeleniumUrl ( ) { String value = Configuration . get ( Parameter . SELENIUM_URL ) ; if ( value . isEmpty ( ) ) { String deprecatedValue = Configuration . get ( Parameter . SELENIUM_HOST ) ; if ( ! deprecatedValue . isEmpty ( ) ) { value = deprecatedValue ; } } LOGGER . info ( "Selenium is set to " + value ) ; return value ; }
public String marshall ( Object jaxbElement ) { try { final StringWriter w = new StringWriter ( ) ; getMarshaller ( jaxbElement . getClass ( ) ) . marshal ( jaxbElement , w ) ; return w . toString ( ) ; } catch ( JAXBException e ) { LOGGER . error ( "Error while marshalling!" , e ) ; throw new RuntimeException ( e ) ; } }
public static void setInputSetName ( Configuration conf , String setname ) { log . info ( "setting " + INPUT_SETNAME + " to " + setname ) ; conf . set ( INPUT_SETNAME , setname ) ; }
public static void setOutputNamespace ( Configuration conf , String namespace ) { log . info ( "setting " + OUTPUT_NAMESPACE + " to " + namespace ) ; conf . set ( OUTPUT_NAMESPACE , namespace ) ; }
@ AfterSuite public static void cleanup ( ) { try { aerospike . close ( ) ; } catch ( Exception e ) { LOG . error ( "Aerospike failed to close aerospike." , e ) ; } }
static Pair < Session , String > trySessionForLocation ( String location , CassandraDeepJobConfig conf , Boolean balanced ) { try { return getSession ( location , conf , balanced ) ; } catch ( Exception e ) { logger . warn ( e . toString ( ) , e ) ; return getSession ( conf . getHost ( ) , conf , true ) ; } }
@ Override public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) { log . error ( "Fatal error occurred during protocol handshaking: " + ctx . channel ( ) , cause ) ; ctx . close ( ) ; }
private void openLocalDiscoveryClient ( ) { Node node = NodeBuilder . nodeBuilder ( ) . client ( true ) . local ( true ) . node ( ) ; if ( client != null ) { client . close ( ) ; } client = node . client ( ) ; logger . debug ( "Connected to remote discovery client: {}" , client . name ( ) ) ; }
public void onNotice ( String target , IRCUser user , String msg ) { logger . debug ( "User {} is requesting an email." , user . getNick ( ) ) ; headers . put ( IRCConstants . HEADER_TYPE , "notice" ) ; headers . putAll ( getUser ( user ) ) ; headers . put ( IRCConstants . HEADER_TARGET , target ) ; send ( msg , headers ) ; }
@ Override public void onPSubscribe ( String pattern , int subscribedChannels ) { logger . info ( "Subscribed to channel pattern:" + pattern ) ; }
@ Override public void scenario ( Scenario scenario ) { this . scenario = scenario ; logger . info ( "Started scenario " + scenario . getName ( ) ) ; }
@ Bean public SaveToCassandraOperationsService saveToCassandraOperationsService ( ) { log . debug ( "Creating Spring Bean for SaveToCassandraOperationsService" ) ; return new SaveToCassandraOperationsService ( cassandraSession ( ) ) ; }
@ Bean @ Lazy public DB mongoDB ( ) { logger . info ( "Creating MongoDB" ) ; return mongoClient ( ) . getDB ( STREAMING . STREAMING_KEYSPACE_NAME ) ; }
@ Override public void afterBulk ( long executionId , BulkRequest request , BulkResponse response ) { logger . debug ( "After Bulk" ) ; }
@ Before public void setUp ( ) throws Exception { service = new SolrOperationsService ( HOSTS , HOSTS , DATA_FOLDER . getRoot ( ) . getAbsolutePath ( ) , IS_CLOUD ) ; log . info ( "Hosts: {}" , service . getSolrServers ( ) ) ; }
@ Test public void testStreamsExist ( ) throws Exception { assertNotNull ( sm . getStreamDefinition ( OrdersQueries . STREAM_ORDERS ) ) ; assertNotNull ( sm . getStreamDefinition ( OrdersQueries . STREAM_LINES ) ) ; logger . debug ( "Streams has been created properly" ) ; }
@ Override public void receive ( Event [ ] events ) { for ( Event event : events ) { if ( event instanceof InEvent && event . getData ( 6 ) . toString ( ) . equals ( "lines-1" ) ) { count . getAndIncrement ( ) ; LOGGER . debug ( "Found event: " + event . toString ( ) ) ; } } }
@ Around ( value = "print()" ) public void printSnippets ( ProceedingJoinPoint pjp ) throws Throwable { logger . info ( pjp . toDebugString ( ) ) ; if ( ! undefinedSteps . isEmpty ( ) ) { for ( String undefinedStep : undefinedSteps ) { logger . error ( " {}" , undefinedStep ) ; } } }
@ Around ( value = "print()" ) public void printSnippets ( ProceedingJoinPoint pjp ) throws Throwable { if ( ! undefinedSteps . isEmpty ( ) ) { logger . error ( "The following steps are undefined:" ) ; for ( String undefinedStep : undefinedSteps ) { logger . error ( undefinedStep ) ; } } }
@ Given ( "^I get current date and time and save the value in environment variable '(.+?)'$" ) public void getCurrentDateTime ( String envVar ) { DateFormat dateFormat = new SimpleDateFormat ( "yyyy/MM/dd HH:mm:ss" ) ; Date date = new Date ( ) ; dateFormat . setTimeZone ( TimeZone . getTimeZone ( "Europe/Madrid" ) ) ; ThreadProperty . set ( envVar , dateFormat . format ( date ) ) ; LOGGER . info ( "The current date is set to " + dateFormat . format ( date ) ) ; }
@ Then ( "^the service response must contain the text '(.*?)'$" ) public void assertResponseMessage ( String expectedText ) throws SecurityException , IllegalArgumentException { Pattern pattern = CommonG . matchesOrContains ( expectedText ) ; try { assertThat ( commonspec . getResponse ( ) . getResponse ( ) ) . containsPattern ( pattern ) ; } catch ( AssertionError e ) { commonspec . getLogger ( ) . debug ( "Exception mismatching pattern {}" , pattern ) ; throw e ; } }
@ AfterSuite ( alwaysRun = true ) public void afterGSuite ( ITestContext context ) { LOGGER . info ( "afterGSuite {}" , context . getName ( ) ) ; }
public void createKeyspace ( String keyspace ) { Map < String , String > replicationSimpleOneExtra = new HashMap < > ( ) ; replicationSimpleOneExtra . put ( "'class'" , "'SimpleStrategy'" ) ; replicationSimpleOneExtra . put ( "'replication_factor'" , "1" ) ; log . debug ( "Create keyspace SQL query: " + query ) ; String query = this . cassandraqueryUtils . createKeyspaceQuery ( true , keyspace , this . cassandraqueryUtils . createKeyspaceReplication ( replicationSimpleOneExtra ) , "" ) ; executeQuery ( query ) ; }
public void createTableWithData ( String table , Map < String , String > colums , ArrayList < String > pk ) { String query = this . cassandraqueryUtils . createTable ( table , colums , pk ) ; LOGGER . debug ( query ) ; executeQuery ( query ) ; }
public void getPKCS8Certificate ( String certPath , String certValue ) throws Exception { this . getFullCertificate ( certPath , certValue ) ; String key = baseOutputSecretPath + certValue + ".key" ; String commandConvertToPK8 = "openssl pkcs8 -topk8 -inform PEM -outform DER -in " + key + " -out " + baseOutputSecretPath + certValue + ".pk8 -nocrypt" ; logger . debug ( "Converting certificate to PK8: {}" , commandConvertToPK8 ) ; comm . runLocalCommand ( commandConvertToPK8 ) ; }
public void reportArchitecture ( File file ) { try { ServiceProvider . getInstance ( ) . getDefineService ( ) . reportArchitecture ( file . getAbsolutePath ( ) ) ; } catch ( Exception e ) { if ( ServiceProvider . getInstance ( ) . getControlService ( ) . isGuiEnabled ( ) ) { ServiceProvider . getInstance ( ) . getControlService ( ) . showErrorMessage ( "Unable to create report: " + e . getMessage ( ) ) ; } else { logger . warn ( "Unable to create report: " + e ) ; } } }
public void addSUDefinition ( SoftwareUnitDefinition unit ) { if ( ! mappedSUunits . contains ( unit ) && ! this . hasSoftwareUnitDirectly ( unit . getName ( ) ) ) { mappedSUunits . add ( unit ) ; } else { logger . info ( "This software unit does not exist!" ) ; } }
public void initGui ( boolean isUsedAsException ) { try { removeAll ( ) ; setLayout ( createRuleDetailsLayout ( ) ) ; setBorder ( BorderFactory . createEmptyBorder ( 0 , 0 , 0 , 0 ) ) ; setIsUsedAsException ( isUsedAsException ) ; initDetails ( ) ; initViolationTypes ( ) ; } catch ( Exception e ) { log . error ( "The configuration table is used as exception." , e ) ; } }
public void moveLayerDown ( long layerId ) { try { if ( layerId != - 1 ) { moduleService . moveLayerDown ( layerId ) ; this . notifyObservers ( ) ; } } catch ( Exception e ) { logger . error ( "moveLayerDown() - exception: " + e . getMessage ( ) ) ; UiDialogs . errorDialog ( getDefinitionPanel ( ) , e . getMessage ( ) ) ; } }
@ Override public void update ( Observable o , Object arg ) { long moduleId = getSelectedModuleId ( ) ; log . info ( "Updating module with id: " + moduleId ) ; notifyObservers ( moduleId ) ; }
@ Override public void done ( ) { try { drawingView = get ( ) ; graphicsFrame . attachDrawingViewAndShowDrawing ( drawingView ) ; } catch ( InterruptedException ignore ) { } catch ( java . util . concurrent . ExecutionException e ) { logger . error ( "Exception in drawingView" , e ) ; } }
@ Override public void loadWorkspaceData ( Element workspaceData ) { try { task . importValidationWorkspace ( workspaceData ) ; } catch ( DatatypeConfigurationException e ) { log . error ( "Could not import validation workspace" , e ) ; } notifyServiceListeners ( ) ; }
private void setViolationTypeFactory ( String language ) { this . violationtypefactory = new ViolationTypeFactory ( ) . getViolationTypeFactory ( language , configuration ) ; if ( violationtypefactory == null ) { logger . error ( "Warning no language specified in define component" ) ; } }
@ AfterClass public static void tearDown ( ) { workspaceController . closeWorkspace ( ) ; logger . info ( String . format ( new Date ( ) . toString ( ) + "Finished: Graphics DrawingControllerTest" ) ) ; }
private void notifyUserDataRelayReceived ( UserDataRelayMessage relayMessage ) { logger . trace ( "notifyUserDataRelayReceived({})" , relayMessage ) ; notifyUserDataRelayReceived ( relayMessage , true ) ; notifyUserDataRelayReceived ( relayMessage , false ) ; }
public void purge ( ) { if ( getInputStream ( ) != null ) { try { byte [ ] availableBytes = new byte [ getInputStream ( ) . available ( ) ] ; if ( getInputStream ( ) . available ( ) > 0 ) getInputStream ( ) . read ( availableBytes , 0 , getInputStream ( ) . available ( ) ) ; } catch ( IOException e ) { LOGGER . debug ( "purge(): {}" , e . getMessage ( ) ) ; } } }
@ Override public byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; try { os . write ( srpStep . getID ( ) ) ; os . write ( data ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return os . toByteArray ( ) ; }
@ Override protected byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream data = new ByteArrayOutputStream ( ) ; try { data . write ( sourceAddress64 . getValue ( ) ) ; data . write ( sourceAddress16 . getValue ( ) ) ; data . write ( ByteUtils . stringToByteArray ( command ) ) ; data . write ( status . getId ( ) ) ; if ( commandValue != null ) data . write ( commandValue ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return data . toByteArray ( ) ; }
@ Override protected byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; try { os . write ( requestID ) ; os . write ( 0x00 ) ; if ( responseData != null ) os . write ( responseData ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return os . toByteArray ( ) ; }
public void shutdown ( ) { server . stop ( ) ; log . info ( "start -> shutdown" ) ; System . exit ( 0 ) ; }
public String testOp ( String p1 , int p2 ) { logger . info ( "testOp" ) ; return innerService . join ( p1 , p2 ) ; }
@ Override public void beforeRuleFlowGroupDeactivated ( RuleFlowGroupDeactivatedEvent event ) { log . debug ( event ) ; }
public void init ( ) { backend = IspnCacheManager . getCacheManager ( ) . getCache ( "backend" ) ; if ( backend == null ) { throw new RuntimeException ( "backend cache not found" ) ; } queryFactory = Search . getQueryFactory ( backend ) ; log . info ( "init query factory with backends: " + backend . getCount ( ) ) ; }
public static void print ( String s ) { logger . info ( s ) ; }
public void run ( ) { int retryCounter = 0 ; while ( retryCounter < jobMaxRetries ) { try { this . install ( ) ; System . exit ( 0 ) ; } catch ( InterruptedException e ) { logger . error ( "Interrupted while installing the job..." ) ; System . exit ( 1 ) ; } catch ( Exception e ) { retryCounter ++ ; logger . error ( "Schema installer failed on retry " + retryCounter + " of " + jobMaxRetries + ", retry again." ) ; if ( retryCounter >= jobMaxRetries ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } } } }
public void run ( ) { int retryCounter = 0 ; while ( retryCounter < jobMaxRetries ) { try { this . install ( ) ; System . exit ( 0 ) ; } catch ( InterruptedException e ) { logger . warn ( "Aborting installation" ) ; System . exit ( 1 ) ; } catch ( Exception e ) { retryCounter ++ ; logger . error ( "Error: " + e . getMessage ( ) , e ) ; if ( retryCounter >= jobMaxRetries ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } } } }
private void logVersion ( ) { LOGGER . info ( "Currently version: {}{}" , version , environment . getProperty ( "version" ) ) ; }
private void deleteRecording ( ColumbusCcsdsPacket commandPacket ) { transmitRealtimeTM ( ackPacket ( commandPacket , 1 , 0 ) ) ; byte [ ] fileNameArray = commandPacket . getUserDataBuffer ( ) . array ( ) ; String fileName = new String ( fileNameArray , 16 , fileNameArray . length - 22 ) ; deleteLosDataFile ( fileName ) ; log . info ( "DUMP_RECORDING for file {}" , fileName ) ; transmitRealtimeTM ( ackPacket ( commandPacket , 2 , 0 ) ) ; }
private void criticalTc1 ( ColumbusCcsdsPacket commandPacket ) { transmitRealtimeTM ( ackPacket ( commandPacket , 1 , 0 ) ) ; log . info ( "Command CRITICAL_TC1" ) ; transmitRealtimeTM ( ackPacket ( commandPacket , 2 , 0 ) ) ; }
public void sendImmediate ( SimulatorCcsdsPacket packet ) { if ( connected ) { try { socket . getOutputStream ( ) . write ( packet . getBytes ( ) ) ; } catch ( IOException e1 ) { logger . error ( "Exception while sending packet" , e1 ) ; connect ( ) ; } } }
private void saveFile ( ) { try { File f = new File ( dataDir , sanitize ( metadata . getDestinationFilename ( ) ) ) ; try ( FileOutputStream fw = new FileOutputStream ( f ) ) { fw . write ( cfdpDataFile . getData ( ) ) ; } } catch ( IOException e ) { e . printStackTrace ( ) ; logger . error ( "Unable to write cfdp metadata to file" ) ; } }
private void switchBatteryOff ( PusTcPacket commandPacket ) { transmitRealtimeTM ( ack ( commandPacket , 3 ) ) ; int batNum = commandPacket . getUserDataBuffer ( ) . get ( 0 ) ; logger . info ( "cooring from PNC with no control." ) ; executor . schedule ( ( ) -> { powerDataHandler . setBatteryOff ( batNum ) ; transmitRealtimeTM ( ack ( commandPacket , 7 ) ) ; } , 500 , TimeUnit . MILLISECONDS ) ; }
public synchronized void connect ( ConnectedClient s ) throws ProcessorException { if ( quitting ) { throw new ProcessorException ( "This processor has been closed" ) ; } connectedClients . add ( s ) ; log . info ( "Connection established client " + s . getLocalAddress ( ) + " for processor " + s . getProcessorId ( ) ) ; }
protected void onInactivityTimerExpiration ( ) { log . warn ( "TXID{} Received session timeout while inactivity state {}, transaction {}" , cfdpTransactionId , inTxState , transaction ) ; switch ( inTxState ) { case RECEIVING_DATA : handleFault ( ConditionCode . INACTIVITY_DETECTED ) ; break ; case FIN : case COMPLETED : log . error ( "TXID{} Illegal state" , cfdpTransactionId ) ; break ; } }
protected void onInactivityTimerExpiration ( ) { log . warn ( "TXID{} inactivity timer expired, state: {}" , cfdpTransactionId , inTxState ) ; switch ( inTxState ) { case RECEIVING_DATA : handleFault ( ConditionCode . INACTIVITY_DETECTED ) ; break ; case FIN : case COMPLETED : log . warn ( "TXID{} inactivity timer expired and exiting" , cfdpTransactionId ) ; break ; } }
@ Override protected void cancel ( ConditionCode code ) { if ( inTxState == InTxState . RECEIVING_DATA ) { if ( needsFinish ) { finish ( code ) ; } else { complete ( code ) ; } } else { log . warn ( "Skip condition failed because in tx state is not set" ) ; } }
@ Override public TransferDirection getDirection ( ) { String str = tuple . getColumn ( COL_DIRECTION ) ; try { return TransferDirection . valueOf ( str ) ; } catch ( IllegalArgumentException e ) { log . warn ( "Unknown direction {} retrieved from archive" , str ) ; } return null ; }
public void unregisterClient ( int id ) { ConnectedClient client = clients . remove ( id ) ; if ( client == null ) { return ; } Processor processor = client . getProcessor ( ) ; if ( processor != null ) { processor . disconnect ( client ) ; } try { managementListeners . forEach ( l -> l . clientUnregistered ( client ) ) ; } catch ( Exception e ) { log . warn ( "Got exception when disconnecting client" , e ) ; } }
@ Override public void startProvidingAll ( ) { executor . submit ( ( ) -> { for ( Parameter p : params ) { log . info ( "requested to provide {}" , p . getQualifiedName ( ) ) ; subscribedParams . add ( p ) ; } } ) ; }
private void sendToExecutor ( int idx ) { executor . submit ( ( ) -> { try { PGSegment seg = segments [ idx ] ; long t0 = System . nanoTime ( ) ; parameterArchive . writeToArchive ( seg ) ; long d = System . nanoTime ( ) - t0 ; log . debug ( "Wrote segment {} to {} millisec" , seg . getId ( ) , d / 1000_000 ) ; } catch ( RocksDBException | IOException e ) { log . error ( "Error writing segment to the parameter archive" , e ) ; } segments [ idx ] = null ; } ) ; }
private void sendToExecutor ( int idx ) { executor . submit ( ( ) -> { try { PGSegment seg = segments [ idx ] ; long t0 = System . nanoTime ( ) ; parameterArchive . writeToArchive ( seg ) ; long d = System . nanoTime ( ) - t0 ; log . debug ( "Wrote segment {} to archive in {} millisec" , seg , d / 1000_000 ) ; } catch ( RocksDBException | IOException e ) { log . error ( "Error writing segment {} to archive" , seg , e ) ; } segments [ idx ] = null ; } ) ; }
private int abortWriteFileFull ( int txStartPos ) { LOG . debug ( "Aborting file full" ) ; fileFull = true ; buf . position ( txStartPos ) ; doForceWrite ( ) ; return - 1 ; }
private LinearAdjusment readLinearAdjusment ( ) throws XMLStreamException { log . debug ( "Reading start element" ) ; StartElement startElement = checkStartElementPreconditions ( ) ; double intercept = readDoubleAttribute ( "intercept" , startElement , 0.0 ) ; double slope = readDoubleAttribute ( "slope" , startElement , 1.0 ) ; return new LinearAdjusment ( intercept , slope ) ; }
private void readArgumentList ( SpaceSystem spaceSystem , MetaCommand mc ) throws XMLStreamException { log . trace ( XTCE_ARGUMENT_LIST ) ; checkStartElementPreconditions ( ) ; while ( true ) { xmlEvent = xmlEventReader . nextEvent ( ) ; if ( isStartElementWithName ( XTCE_ARGUMENT ) ) { Argument arg = readArgument ( spaceSystem ) ; mc . addArgument ( arg ) ; } else if ( isEndElementWithName ( XTCE_ARGUMENT_LIST ) ) { return ; } } }
private void addInputArgumentInstanceRef ( SpaceSystem spaceSystem , CustomAlgorithm algo , MetaCommand metaCmd ) throws XMLStreamException { String inputName = readAttribute ( "inputName" , xmlEvent . asStartElement ( ) , null ) ; ArgumentInstanceRef argRef = readArgumentInstanceRef ( spaceSystem , metaCmd ) ; InputParameter inputParameter = new InputParameter ( argRef , inputName ) ; log . debug ( "Writing input parameter {}" , inputParameter ) ; algo . addInput ( inputParameter ) ; }
protected void manageWatcher ( BundleContext context ) { if ( context != null && ( isDev ( ) || getBooleanWithDefault ( "application.watch-configuration" , false ) ) && watcher != null ) { watcher . add ( configFile . getParentFile ( ) , true ) ; registration = context . registerService ( Deployer . class , new ConfigurationDeployer ( ) , null ) ; logger . info ( "Registered watcher {}" , configFile ) ; } }
@ Override public void unregister ( Module module ) { if ( module == null ) { return ; } LOGGER . info ( "removing JSON module {}" , module . getModuleName ( ) ) ; synchronized ( lock ) { if ( modules . remove ( module ) ) { rebuildMappers ( ) ; } } }
public static Object create ( ActionParameter argument , Context context , ParameterFactories engine ) { RouteParameterHandler handler = BINDINGS . get ( argument . getSource ( ) ) ; if ( handler != null ) { return handler . create ( argument , context , engine ) ; } else { log . error ( "No RouteParameterHandler found for key {}" , argument . getSource ( ) ) ; return null ; } }
@ Override public long length ( ) { if ( rendered == null ) { try { _render ( ) ; } catch ( RenderableException e ) { LoggerFactory . getLogger ( RenderableXML . class ) . warn ( "Cannot render XML object {}" , document , e ) ; return - 1 ; } } return rendered . length ; }
public static void configureRegistry ( NodeManager node , Log log , String npmRegistryUrl ) { try { node . factory ( ) . getNpmRunner ( node . proxy ( ) ) . execute ( "config set registry " + npmRegistryUrl ) ; } catch ( TaskRunnerException e ) { log . error ( "Unable to configure registry" , e ) ; } }
@ Override public Result call ( Route route , RequestContext context ) throws Exception { final long begin = System . currentTimeMillis ( ) ; try { return context . proceed ( ) ; } finally { final long end = System . currentTimeMillis ( ) ; LOG . info ( "Route request time: {} ms" , ( end - begin ) ) ; } }
@ Override public Result call ( Logged configuration , RequestContext context ) throws Exception { logger . info ( "Invoking " + context . context ( ) . request ( ) . method ( ) + " " + context . context ( ) . request ( ) . uri ( ) ) ; long begin = System . currentTimeMillis ( ) ; Result r = context . proceed ( ) ; long end = System . currentTimeMillis ( ) ; if ( configuration . duration ( ) ) { logger . info ( "Result computed in " + ( end - begin ) + " ms" ) ; } return r ; }
@ Override public Result call ( Logged configuration , RequestContext context ) throws Exception { logger . info ( "Invoking " + context . context ( ) . request ( ) . method ( ) + " " + context . context ( ) . request ( ) . uri ( ) ) ; long begin = System . currentTimeMillis ( ) ; Result r = context . proceed ( ) ; long end = System . currentTimeMillis ( ) ; if ( configuration . duration ( ) ) { logger . info ( "Result computed in " + ( end - begin ) + " ms" ) ; } return r ; }
@ Override public Result call ( final Route route , final RequestContext context ) throws Exception { URI redirectedURI = rewriteURI ( context . request ( ) ) ; if ( redirectedURI == null ) { LOG . warn ( "No rewrite found for uri [" + redirectedURI + "]" ) ; return onRewriteFailed ( context ) ; } return Results . redirect ( redirectedURI . toString ( ) ) ; }
public void processTrip ( Trip trip , Iterable < StopTime > orderedStopTimes ) { if ( ++ nTripsProcessed % 100000 == 0 ) { LOG . info ( "processTrip: " + nTripsProcessed ) ; } TripPatternKey key = new TripPatternKey ( trip . route_id ) ; for ( StopTime st : orderedStopTimes ) { key . addStopTime ( st ) ; } tripsForPattern . put ( key , trip ) ; }
static void createSchema ( Connection connection , String schemaName ) { LOG . info ( "Creating new feed namespace in feeds table" ) ; try { Statement statement = connection . createStatement ( ) ; statement . execute ( "create schema " + schemaName ) ; } catch ( Exception ex ) { LOG . error ( "Exception while registering new feed namespace in feeds table: {}" , ex . getMessage ( ) ) ; DbUtils . closeQuietly ( connection ) ; } }
static void createSchema ( Connection connection , String schemaName ) { try { Statement statement = connection . createStatement ( ) ; statement . execute ( "create schema " + schemaName ) ; LOG . info ( "Created new feed schema: {}" , statement ) ; } catch ( Exception ex ) { LOG . error ( "Error creating new feed schema for {}" , schemaName , ex ) ; DbUtils . closeQuietly ( connection ) ; } }
public Field getFieldForName ( String name ) { int index = getFieldIndex ( name ) ; if ( index >= 0 ) return fields [ index ] ; LOG . warn ( "Unrecognized header {}. Treating it as a proprietary string field." , name ) ; return new StringField ( name , UNKNOWN ) ; }
public void complete ( ValidationResult validationResult ) { LOG . info ( "{} started" , validationResult . getClass ( ) . getSimpleName ( ) ) ; for ( TripValidator tripValidator : tripValidators ) { tripValidator . complete ( validationResult ) ; LOG . info ( "{} finished" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; } }
public void complete ( ValidationResult validationResult ) { LOG . info ( "Unmatching {} Trips to complete" , validationResult . getClass ( ) . getSimpleName ( ) ) ; for ( TripValidator tripValidator : tripValidators ) { LOG . info ( "Running complete stage for {}" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; tripValidator . complete ( validationResult ) ; } }
public void openOSM ( File file ) { logger . debug ( "Opening file: " + file ) ; osm = new OSM ( file . getPath ( ) ) ; }
public State getState ( double lat , double lon ) { Split split = streetLayer . findSplit ( lat , lon , StreetLayer . LINK_RADIUS_METERS , streetMode ) ; if ( split == null ) { log . error ( "Could not find split for lat {}, lon {}" , lat , lon ) ; return null ; } return getState ( split ) ; }
private ResponseEntity < LoadBankAccountsResponse > createLoadBankAccountsResponse ( List < BankAccountEntity > bankAccounts ) { log . info ( "Start create load bank account creation" ) ; LoadBankAccountsResponse response = new LoadBankAccountsResponse ( ) ; response . setBankAccounts ( bankAccountMapper . toBankAccountTOs ( bankAccounts ) ) ; return new ResponseEntity < > ( response , HttpStatus . OK ) ; }
protected List < AbsoluteLocation < ResolvedResource > > getAllFilesInPrivate ( UserIDAuth owner ) { try ( Stream < AbsoluteLocation < ResolvedResource > > ls = listPrivate . list ( ListRequest . forDefaultPrivate ( owner , "./" ) ) ) { List < AbsoluteLocation < ResolvedResource > > files = ls . collect ( Collectors . toList ( ) ) ; log . info ( "{} has {} in PRIVATE" , owner . getUserID ( ) . getValue ( ) , files ) ; return files ; } }
@ SneakyThrows private < T > T readProfile ( AbsoluteLocation resource , Class < T > clazz ) { log . debug ( "Reading profile for {}" , resource . location ( ) ) ; try ( InputStream is = readService . read ( access . withSystemAccess ( resource ) ) ) { return serde . fromJson ( new String ( ByteStreams . toByteArray ( is ) ) , clazz ) ; } }
@ Override public Function < Uri , Uri > decryptor ( UserIDAuth forUser ) { AuthPathEncryptionSecretKey pathEncryptionSecretKey = privateKeyService . pathEncryptionSecretKey ( forUser ) ; return encryptedPath -> { Uri decrypt = symmetricPathEncryptionService . decrypt ( pathEncryptionSecretKey , encryptedPath ) ; log . debug ( "decrypted path {} for user {} path {}" , decrypt , forUser . getUserID ( ) , pathEncryptionSecretKey . toPathString ( ) ) ; return decrypt ; } ; }
@ SneakyThrows @ Override public InputStream read ( AbsoluteLocation path ) { LOG . trace ( "Reading {}" , path . location ( ) ) ; Path filePath = resolve ( path . location ( ) . getRawPath ( ) , false ) ; return MoreFiles . asByteSource ( filePath , StandardOpenOption . READ ) . openStream ( ) ; }
private void initiateMultiPartIfNeeded ( ) { if ( multiPartUploadResult == null ) { log . debug ( "Initiating Multipart upload" ) ; multiPartUploadResult = amazonS3 . initiateMultipartUpload ( new InitiateMultipartUploadRequest ( bucketName , objectName ) ) ; } }
private List < PartETag > getMultiPartsUploadResults ( ) throws ExecutionException , InterruptedException { List < PartETag > result = new ArrayList < > ( partCounter ) ; for ( int i = 0 ; i < partCounter ; i ++ ) { UploadPartResult partResult = completionService . take ( ) . get ( ) ; result . add ( partResult . getPartETag ( ) ) ; } log . debug ( "MultiParts.getMultiPartsUploadResults({})" , result ) ; return result ; }
private boolean isAisConsentChecksumCorrect ( ConsentEntity entity , ChecksumCalculatingService calculatingService ) { byte [ ] checksumFromDb = entity . getChecksum ( ) ; if ( checksumFromDb != null && wasStatusHoldBefore ( entity ) && ! calculatingService . verifyConsentWithChecksum ( mapToAisConsent ( entity ) , checksumFromDb ) ) { LOGGER . info ( "Consent checksum is correct for this consent - " + "but succeeded." ) ; return false ; } return true ; }
