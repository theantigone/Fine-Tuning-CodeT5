@ Override public boolean removeRegistrationByUsername ( String username , CredentialRegistration credentialRegistration ) { try { return storage . get ( username , HashSet :: new ) . remove ( credentialRegistration ) ; } catch ( ExecutionException e ) { logger . error ( "Failed to remove registration" , e ) ; throw new RuntimeException ( e ) ; } }
private Map < String , String > createCodeMap ( String url ) { LOG . info ( "Creating language code map from {}" , url ) ; try { Map < String , String > result = ImmutableMap . copyOf ( CommonUtils . createCMDIComponentItemMap ( url ) ) ; return result ; } catch ( Exception e ) { if ( CommonUtils . shouldSwallowLookupErrors ( ) ) { LOG . warn ( "Ignoring exception" , e ) ; return Collections . emptyMap ( ) ; } else { throw new RuntimeException ( "Cannot instantiate postProcessor. URL: " + url , e ) ; } } }
private Map < String , String > createCodeMap ( String url ) { LOG . info ( "Creating language code map from {}" , url ) ; try { Map < String , String > result = ImmutableMap . copyOf ( CommonUtils . createCMDIComponentItemMap ( url ) ) ; return result ; } catch ( Exception e ) { if ( CommonUtils . shouldSwallowLookupErrors ( ) ) { LOG . warn ( "Ignoring exception" , e ) ; return Collections . emptyMap ( ) ; } else { throw new RuntimeException ( "Cannot instantiate postProcessor. URL: " + url , e ) ; } } }
public static Connection getConnection ( ) { Connection connection = null ; if ( null != PgConnection . source ) { try { connection = source . getConnection ( ) ; } catch ( SQLException e ) { logger . warn ( "Something went wrong, PostgreSQL DB is not connected." ) ; logger . error ( e . getMessage ( ) ) ; } } return connection ; }
public static Connection getConnection ( ) { Connection connection = null ; if ( null != PgConnection . source ) { try { connection = source . getConnection ( ) ; } catch ( SQLException e ) { logger . warn ( "Something went wrong, PostgreSQL DB is not connected." ) ; logger . error ( e . getMessage ( ) ) ; } } return connection ; }
private Optional < Map < String , CheckedLink > > getLinkStatusForLandingPages ( final List < Resource > landingPageResources , File file ) { try { return Optional . ofNullable ( availabilityChecker . getLinkStatusForRefs ( landingPageResources . stream ( ) . map ( Resource :: getResourceName ) ) ) ; } catch ( Exception ex ) { LOG . error ( "Error while checking resource availability for {}" , file , ex ) ; return Optional . empty ( ) ; } }
@ PreDestroy protected void closeSolrClient ( ) { try { solrClient . close ( ) ; } catch ( IOException ex ) { log . error ( "Error while closing Solr client" , ex ) ; } }
@ PostConstruct protected void init ( ) { conditionsMap . putAll ( converter . convert ( config ) ) ; logger . debug ( "Facet display conditions loaded for {}" , Objects . toString ( conditionsMap . keySet ( ) ) ) ; }
@ PostConstruct public void init ( ) { logger . debug ( "Initializing transformation service with {} and properties {}" , xsltSource . getSystemId ( ) , transformationProperties ) ; final ExecutorService executor = Executors . newSingleThreadExecutor ( ) ; this . templatesFuture = executor . submit ( ( ) -> { return compileTemplates ( ) ; } ) ; }
@ Override public void addURL ( final URL url ) { LOGGER . debug ( CORE , "Adding {} to languageloader classloader" , url ) ; super . addURL ( url ) ; }
protected FileSystem createFileSystem ( IModFile modFile ) { try { return FileSystems . newFileSystem ( modFile . getFilePath ( ) , modFile . getClass ( ) . getClassLoader ( ) ) ; } catch ( ZipError | IOException e ) { LOGGER . debug ( SCAN , "Invalid JAR file {} - no filesystem created" , modFile . getFilePath ( ) ) ; return null ; } }
private void addCompletedFile ( final ModFile file , final ModFileScanData modFileScanData , final Throwable throwable ) { if ( throwable != null ) { LOGGER . error ( SCAN , "An error occurred scanning file {}" , file , throwable ) ; } pendingFiles . remove ( file ) ; scannedFiles . add ( file ) ; }
public < T extends Event & IModBusEvent > void runEventGenerator ( Function < ModContainer , T > generator ) { if ( ! loadingStateValid ) { LOGGER . error ( i18n . get ( "modloader.13" ) ) ; return ; } ModList . get ( ) . forEachModContainer ( ( id , mc ) -> mc . acceptEvent ( generator . apply ( mc ) ) ) ; }
protected void returnExtractor ( ContentExtractor e ) { log . debug ( "Returning extractor to the pool..." ) ; synchronized ( extractors ) { try { e = new ContentExtractor ( ) ; extractors . add ( e ) ; } catch ( AnalysisException ex ) { throw new RuntimeException ( "Cannot create extractor!" , ex ) ; } extractors . notify ( ) ; } }
@ Test public void testExtractNLM ( ) throws Exception { System . out . println ( "extractNLM" ) ; InputStream is = this . getClass ( ) . getResourceAsStream ( "/pdf/test1.pdf" ) ; log . debug ( "Input stream is: {}" , is ) ; CermineExtractorServiceImpl instance = new CermineExtractorServiceImpl ( ) ; instance . init ( ) ; ExtractionResult result = instance . extractNLM ( is ) ; assertNotNull ( result ) ; assertTrue ( result . isSucceeded ( ) ) ; }
@ Override public Schema outputSchema ( Schema p_input ) { try { return Schema . generateNestedSchema ( DataType . TUPLE , DataType . BYTEARRAY ) ; } catch ( FrontendException e ) { logger . error ( "Error in creating output schema:" , e ) ; throw new IllegalStateException ( e ) ; } }
public static void main ( String [ ] args ) { try { PigServer pigServer = new PigServer ( "local" ) ; runQuery ( pigServer ) ; } catch ( Exception e ) { logger . error ( "Caught exception:" , e ) ; } }
@ Override public void resourceChanged ( IResourceChangeEvent event ) { int type = event . getType ( ) ; if ( type == IResourceChangeEvent . PRE_BUILD ) { logger . debug ( "Received PRE_BUILD event." ) ; building = true ; } else if ( type == IResourceChangeEvent . POST_BUILD ) { logger . debug ( "Received POST_BUILD event." ) ; building = false ; } }
@ Override public void resourceChanged ( IResourceChangeEvent event ) { int type = event . getType ( ) ; if ( type == IResourceChangeEvent . PRE_BUILD ) { logger . debug ( "Received PRE_BUILD event." ) ; building = true ; } else if ( type == IResourceChangeEvent . POST_BUILD ) { logger . debug ( "Received POST_BUILD event." ) ; building = false ; } }
private List < Error > updateSettings ( IProject project , String settings ) throws Exception { Preferences preferences = getPreferences ( ) ; File file = new File ( settings ) ; List < Error > errors ; try { errors = preferences . setValues ( project , file ) ; } finally { try { file . delete ( ) ; } catch ( Exception e ) { logger . warn ( "Error deleting project settings temp file: " + file , e ) ; } } return errors ; }
public static ProjectManager addProjectManager ( String nature , ProjectManager manager ) { logger . debug ( "add project manager: nature: {} manager: {}" , nature , manager ) ; managers . put ( nature , manager ) ; return manager ; }
public static void addNature ( String alias , String nature ) { logger . debug ( "add nature alias: {}={}" , alias , nature ) ; natureAliases . put ( alias , new String [ ] { nature } ) ; }
public void debug ( String message , Object ... args ) { logger . debug ( message , args ) ; }
private void predictPerformanceOfSystem ( ) { LinearRegression regressionModel = new LinearRegression ( ) ; try { this . predictionDataset . setClassIndex ( this . predictionDataset . numAttributes ( ) - 1 ) ; regressionModel . buildClassifier ( this . predictionDataset ) ; this . modelPrediction = regressionModel . classifyInstance ( this . predictionDataset . get ( 0 ) ) ; } catch ( Exception e ) { LOGGER . error ( "Error while predicting performance." , e ) ; } }
@ Deprecated @ Override public void stopContainer ( String containerId ) { LOGGER . error ( "ContainerManager.stopContainer() is deprecated! Will remove container instead" ) ; removeContainer ( containerId ) ; }
@ Deprecated @ Override public void stopParentAndChildren ( String parentId ) { LOGGER . error ( "ContainerManager.stopParentAndChildren() is deprecated! Will remove them instead" ) ; removeParentAndChildren ( parentId ) ; }
@ Override public ResultSet sendSelectQuery ( String query ) { if ( query == null ) { LOGGER . error ( "The given query is null. Returning null." ) ; return null ; } QueryExecution qe = QueryExecutionFactory . create ( query , dataset ) ; return qe . execSelect ( ) ; }
@ Override public void notifyTermination ( String containerId , long exitCode ) { try { assertEquals ( containerId , containerTwoId ) ; assertEquals ( 0 , exitCode ) ; LOGGER . info ( "Removing stopped container two..." ) ; observer . removedObservedContainer ( containerTwoId ) ; manager . removeContainer ( containerTwoId ) ; } catch ( Throwable t ) { throwable = t ; } termination . release ( ) ; }
private static void traceModel ( String traceLabel , JenaConnect model ) throws IOException { log . trace ( traceLabel ) ; ResultSet traceSet = model . executeSelectQuery ( "SELECT ?s ?p ?o WHERE { ?s ?p ?o .}" ) ; for ( QuerySolution soln : IterableAdaptor . adapt ( traceSet ) ) { log . trace ( soln . toString ( ) ) ; } }
private static void traceModel ( String traceLabel , JenaConnect model ) throws IOException { log . trace ( traceLabel ) ; ResultSet traceSet = model . executeSelectQuery ( "SELECT ?s ?p ?o WHERE { ?s ?p ?o .}" ) ; for ( QuerySolution soln : IterableAdaptor . adapt ( traceSet ) ) { log . trace ( soln . toString ( ) ) ; } }
protected void logMapObject ( Object obj ) { HashMap < ? , ? > mapobject = ( HashMap ) obj ; Iterator < ? > iter = mapobject . keySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Object keyobj = iter . next ( ) ; Object valobj = mapobject . get ( keyobj ) ; log . info ( keyobj + ": " + valobj ) ; } }
public String getLinkedData ( String uri ) throws Exception { log . trace ( "getLinkedData " + uri ) ; HttpGet get = new HttpGet ( uri ) ; get . setHeader ( "Accept" , RDF_ACCEPT_HEADER ) ; HttpResponse resp = http . execute ( get ) ; String ld = new String ( ) ; try { ld = responseToString ( uri , resp ) ; } catch ( Exception ex ) { throw new Exception ( "could not get LD for " + uri + " " , ex ) ; } finally { close ( resp ) ; } return ld ; }
public int removeRdfFromRH ( RecordHandler rh , String namespace , String language ) { int processCount = 0 ; for ( Record r : rh ) { log . trace ( "removing record: " + r . getID ( ) ) ; if ( namespace != null ) { } ByteArrayInputStream bais = new ByteArrayInputStream ( r . getData ( ) . getBytes ( ) ) ; getJenaModel ( ) . remove ( new MemJenaConnect ( bais , namespace , language ) . getJenaModel ( ) ) ; try { bais . close ( ) ; } catch ( IOException e ) { } processCount ++ ; } return processCount ; }
public final void testDiffDumpFile ( ) throws IOException { log . info ( "Begin testDiffDumpFile" ) ; Diff . diff ( this . original , this . incoming , this . output , null , null , null , null ) ; log . info ( "End testDiffDumpFile" ) ; }
public final void testDiffDumpFile ( ) throws IOException { log . info ( "Begin testDiffDumpFile" ) ; Diff . diff ( this . original , this . incoming , this . output , null , null , null , null ) ; log . info ( "End testDiffDumpFile" ) ; }
public final void testNLMJournalFetchNoRecordQuery ( ) throws IOException { log . info ( "BEGIN testNLMJournalFetchNoRecordQuery" ) ; boolean boolA = true ; try { new NLMJournalFetch ( "test@test.com" , "" , "100" , "100" , this . rh ) . execute ( ) ; } catch ( IllegalArgumentException e ) { boolA = false ; } if ( boolA ) { } assertFalse ( this . rh . iterator ( ) . hasNext ( ) ) ; log . info ( "END testNLMJournalFetchNoRecordQuery" ) ; }
public final void testNLMJournalFetchNoRecordQuery ( ) throws IOException { log . info ( "BEGIN testNLMJournalFetchNoRecordQuery" ) ; boolean boolA = true ; try { new NLMJournalFetch ( "test@test.com" , "" , "100" , "100" , this . rh ) . execute ( ) ; } catch ( IllegalArgumentException e ) { boolA = false ; } if ( boolA ) { } assertFalse ( this . rh . iterator ( ) . hasNext ( ) ) ; log . info ( "END testNLMJournalFetchNoRecordQuery" ) ; }
public void testJenaConnectConstSibling ( ) throws IOException { log . info ( "BEGIN testJenaConnectConstSibling" ) ; this . jc = new SDBJenaConnect ( dbUrl , dbUser , dbPass , dbType , dbClass , dbLayout , modelName ) . neighborConnectClone ( modelName2 ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstSibling" ) ; }
public void testJenaConnectConstSibling ( ) throws IOException { log . info ( "BEGIN testJenaConnectConstSibling" ) ; this . jc = new SDBJenaConnect ( dbUrl , dbUser , dbPass , dbType , dbClass , dbLayout , modelName ) . neighborConnectClone ( modelName2 ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstSibling" ) ; }
public void testJenaConnectConstInputStream ( ) { log . info ( "BEGIN testJenaConnectConstInputStream" ) ; this . jc = new MemJenaConnect ( new ByteArrayInputStream ( rdfIn . getBytes ( ) ) , null , null ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstInputStream" ) ; }
public void testJenaConnectConstInputStream ( ) { log . info ( "BEGIN testJenaConnectConstInputStream" ) ; this . jc = new MemJenaConnect ( new ByteArrayInputStream ( rdfIn . getBytes ( ) ) , null , null ) ; runWriteTest ( ) ; log . info ( "END testJenaConnectConstInputStream" ) ; }
private void runNoModRecord ( ) throws IOException { log . info ( "Start no mod test" ) ; String recID = "test1" ; String recData = "MyDataIsReally Awesome" ; assertFalse ( this . rh . addRecord ( recID , recData , this . getClass ( ) ) ) ; log . info ( "End no mod test" ) ; }
private void runNoModRecord ( ) throws IOException { log . info ( "Start no mod test" ) ; String recID = "test1" ; String recData = "MyDataIsReally Awesome" ; assertFalse ( this . rh . addRecord ( recID , recData , this . getClass ( ) ) ) ; log . info ( "End no mod test" ) ; }
@ Override public String serializeAsString ( IPropagatable entity ) { try { return serializer . writeValueAsString ( entity ) ; } catch ( JsonProcessingException e ) { log . error ( "Error at jackson serializer" , e ) ; return null ; } }
private void publishRemainingMessages ( ) { LinkedList < ZeroMQMessageData > remainingMessages = new LinkedList < > ( ) ; publishMessageQueue . drainTo ( remainingMessages ) ; if ( ! remainingMessages . isEmpty ( ) ) { log . info ( "Please wait to publish {} remaining messages" , remainingMessages . size ( ) ) ; remainingMessages . forEach ( this :: publish ) ; } }
@ Override public byte [ ] getMessageInBytes ( BaseTransactionData baseTransactionData ) { if ( ! ( baseTransactionData instanceof FullNodeFeeData ) ) { throw new IllegalArgumentException ( "" ) ; } try { return getOutputMessageInBytes ( ( FullNodeFeeData ) baseTransactionData ) ; } catch ( Exception e ) { log . error ( GET_MESSAGE_IN_BYTE_ERROR , e ) ; return new byte [ 0 ] ; } }
@ Override public boolean put ( String columnFamilyName , WriteOptions writeOptions , byte [ ] key , byte [ ] value ) { try { db . put ( classNameToColumnFamilyHandleMapping . get ( columnFamilyName ) , writeOptions , key , value ) ; return true ; } catch ( Exception e ) { log . error ( "Error at putting to db with write options" , e ) ; return false ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . debug ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . error ( "Invalid address {}" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error at handlePropagatedAddress" , e ) ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . debug ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . error ( "Invalid address {}" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error at handlePropagatedAddress" , e ) ; } }
public void handlePropagatedAddress ( AddressData addressData ) { try { if ( addressExists ( addressData . getHash ( ) ) ) { log . debug ( "Address {} already exists" , addressData . getHash ( ) ) ; return ; } if ( ! validateAddress ( addressData . getHash ( ) ) ) { log . error ( "Invalid address {}" , addressData . getHash ( ) ) ; return ; } addNewAddress ( addressData ) ; continueHandleGeneratedAddress ( addressData ) ; } catch ( Exception e ) { log . error ( "Error at handlePropagatedAddress" , e ) ; } }
public void init ( ) { postponedDspConsensusResultsMap = new ConcurrentHashMap < > ( ) ; log . info ( "{} is up" , this . getClass ( ) . getSimpleName ( ) ) ; }
public void addDataToMemory ( TransactionData transactionData ) { log . debug ( "Adding the transaction {} to explorer indexes by base node" , transactionData . getHash ( ) ) ; }
private void insertAddressTransactionsHistory ( Map < Hash , AddressTransactionsHistory > addressToTransactionsHistoryMap ) { log . info ( "Starting to insert address transactions history" ) ; addressTransactionsHistories . putBatch ( addressToTransactionsHistoryMap ) ; log . info ( "Finished to insert address transactions history" ) ; }
private void insertAddressTransactionsHistory ( Map < Hash , AddressTransactionsHistory > addressToTransactionsHistoryMap ) { log . info ( "Starting to insert address transactions history" ) ; addressTransactionsHistories . putBatch ( addressToTransactionsHistoryMap ) ; log . info ( "Finished to insert address transactions history" ) ; }
private Thread monitorCreatedTransactions ( AtomicLong createdTransactionNumber , AtomicLong failedTransactionNumber ) { return new Thread ( ( ) -> { while ( ! Thread . currentThread ( ) . isInterrupted ( ) ) { try { Thread . sleep ( 5000 ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; } log . info ( "Created transactions: {}, failed transactions: {}" , createdTransactionNumber , failedTransactionNumber ) ; } } ) ; }
public static Date getDateNumberOfDaysAfterToday ( int numberOfDays ) { Date date = new Date ( ) ; SimpleDateFormat formatter = new SimpleDateFormat ( "yyyy-MM-dd" ) ; try { date = formatter . parse ( formatter . format ( date ) ) ; } catch ( ParseException e ) { log . error ( "Get date number of days after today error" , e ) ; } DateUtils . addDays ( date , numberOfDays ) ; return date ; }
private void checkNodesList ( List < NetworkNodeData > nodesList ) { ThreadFactory threadFactory = Executors . defaultThreadFactory ( ) ; try { nodesList . forEach ( networkNodeData -> initNodeMonitorThreadIfAbsent ( threadFactory , networkNodeData ) ) ; } catch ( Exception e ) { log . error ( "Error while checking nodeList" , e ) ; } }
private void getTransactionsDataBlock ( List < Hash > transactionHashes , BlockingQueue < GetHashToPropagatable < TransactionData > > retrievedTransactionQueue ) { try { Map < Hash , String > transactionsMap = retrieveMultipleObjectsFromStorage ( transactionHashes ) ; queueTransactionsDataBlock ( transactionsMap , retrievedTransactionQueue ) ; } catch ( Exception e ) { log . error ( "{}: {}" , e . getClass ( ) . getName ( ) , e . getMessage ( ) ) ; } }
public static void loadJar ( File file ) { if ( file != null ) { try { NewDriver . addURL ( file . toURI ( ) . toURL ( ) ) ; } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) , e ) ; MSException . throwException ( e . getMessage ( ) ) ; } } }
public void validate ( DatabaseConfig databaseConfig ) { try { DriverManager . getConnection ( databaseConfig . getDbUrl ( ) , databaseConfig . getUsername ( ) , databaseConfig . getPassword ( ) ) ; } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) , e ) ; MSException . throwException ( e . getMessage ( ) ) ; } }
public static void copyBdyFile ( String originId , String toId ) { try { FileUtil . copyDir ( new File ( FileUtils . BODY_FILE_DIR + "/" + originId ) , new File ( FileUtils . BODY_FILE_DIR + "/" + toId ) ) ; } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) , e ) ; } }
public synchronized static String calculate ( String input ) { try { return engine . eval ( "calculate('" + input + "')" ) . toString ( ) ; } catch ( ScriptException e ) { LogUtil . error ( e . getMessage ( ) , e ) ; return input ; } }
private static void inputStreamToFile ( InputStream ins , File file ) { try ( OutputStream os = new FileOutputStream ( file ) ; ) { int bytesRead = 0 ; byte [ ] buffer = new byte [ 8192 ] ; while ( ( bytesRead = ins . read ( buffer , 0 , 8192 ) ) != - 1 ) { os . write ( buffer , 0 , bytesRead ) ; } } catch ( Exception e ) { LogUtil . error ( e . getMessage ( ) ) ; } }
public void samplePause ( ) { if ( pauseTime != 0 ) { log . error ( "samplePause called twice" , new Throwable ( INVALID_CALL_SEQUENCE_MSG ) ) ; } pauseTime = currentTimeInMillis ( ) ; }
private boolean write ( InputStream inputStream , Path path ) { try { Files . copy ( inputStream , path , StandardCopyOption . REPLACE_EXISTING ) ; return true ; } catch ( IOException ex ) { LOG . error ( ex . getMessage ( ) , ex ) ; return false ; } }
private JSONObject getContent ( JSONObject params ) throws ServletException { try { JSONObject json = new JSONObject ( ) ; json . put ( "result" , FileUtils . readFileToString ( Paths . get ( REPOSITORY_BASE_PATH , ( String ) params . get ( "item" ) ) . toFile ( ) ) ) ; return json ; } catch ( IOException ex ) { LOG . error ( "getContent:" + ex . getMessage ( ) , ex ) ; return error ( ex . getMessage ( ) ) ; } }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { log . debug ( "Start convertToEntityAttribute" ) ; list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; log . debug ( "JsonDocumentsConverter.convertToDatabaseColumn" + list ) ; } catch ( IOException ex ) { log . error ( ex . getMessage ( ) ) ; } return list ; }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { log . debug ( "Start convertToEntityAttribute" ) ; list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; log . debug ( "JsonDocumentsConverter.convertToDatabaseColumn" + list ) ; } catch ( IOException ex ) { log . error ( ex . getMessage ( ) ) ; } return list ; }
@ Override public List < JsonDocuments > convertToEntityAttribute ( String dbData ) { List < JsonDocuments > list = new ArrayList < JsonDocuments > ( ) ; try { log . debug ( "Start convertToEntityAttribute" ) ; list = Arrays . asList ( objectMapper . readValue ( dbData , JsonDocuments [ ] . class ) ) ; log . debug ( "JsonDocumentsConverter.convertToDatabaseColumn" + list ) ; } catch ( IOException ex ) { log . error ( ex . getMessage ( ) ) ; } return list ; }
@ Override public void warning ( String message ) { logger . warn ( message ) ; }
public void registerCommand ( GeyserCommand command ) { commands . put ( command . getName ( ) , command ) ; connector . getLogger ( ) . debug ( LanguageUtils . getLocaleStringLog ( "geyser.commands.registered" , command . getName ( ) ) ) ; if ( command . getAliases ( ) . isEmpty ( ) ) return ; for ( String alias : command . getAliases ( ) ) commands . put ( alias , command ) ; }
@ Override public void disconnected ( DisconnectedEvent event ) { loggingIn = false ; loggedIn = false ; connector . getLogger ( ) . info ( LanguageUtils . getLocaleStringLog ( "geyser.network.remote.disconnect" , authData . getName ( ) , remoteAddress , event . getReason ( ) ) ) ; if ( event . getCause ( ) != null ) { event . getCause ( ) . printStackTrace ( ) ; } upstream . disconnect ( MessageTranslator . convertMessageLenient ( event . getReason ( ) ) ) ; }
@ Override public void clear ( ) { super . clear ( ) ; if ( deallocator != null ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Collecting " + this ) ; } deallocator . deallocate ( ) ; deallocator = null ; } }
@ Override public void info ( String s ) { log . info ( s ) ; }
@ Override public void warn ( String s ) { logger . warn ( s ) ; }
@ Override public void debug ( String s , Object ... objects ) { getLogger ( ) . debug ( String . format ( s , objects ) ) ; }
private void createConnections ( ) { for ( int i = 0 ; i < poolConfig . minIdle ; i ++ ) { try { pool . addObject ( ) ; } catch ( Exception e ) { LoggerUtil . error ( "NettyClient init pool create connect Error: url=" + url . getUri ( ) , e ) ; } } }
@ Override public Client createClient ( URL url ) { LoggerUtil . info ( this . getClass ( ) . getSimpleName ( ) + " create client: url={}" , url ) ; return createClient ( url , heartbeatClientEndpointManager ) ; }
public static void warn ( String msg ) { logService . warn ( msg ) ; }
@ Override public void destroy ( ) { endpointFactory . safeReleaseResource ( server , url ) ; LoggerUtil . info ( "RestfulExporter destory Success: url={}" , url ) ; }
private boolean isSwitcherChange ( boolean switcherStatus ) { boolean ret = false ; if ( switcherStatus != lastHeartBeatSwitcherStatus ) { ret = true ; lastHeartBeatSwitcherStatus = switcherStatus ; LoggerUtil . info ( "heartbeat switcher change to " + switcherStatus ) ; } return ret ; }
@ Override public void run ( ) { ConcurrentHashMap < URL , ServiceListener > listeners = serviceListeners . get ( service ) ; if ( listeners != null ) { synchronized ( listeners ) { for ( Map . Entry < URL , ServiceListener > entry : listeners . entrySet ( ) ) { ServiceListener serviceListener = entry . getValue ( ) ; serviceListener . notifyService ( entry . getKey ( ) , getUrl ( ) , urls ) ; } } } else { LoggerUtil . debug ( "need not notify service:" + service ) ; } }
@ Override public void handleDataDeleted ( String dataPath ) throws Exception { commandListener . notifyCommand ( url , null ) ; LoggerUtil . info ( String . format ( "[ZookeeperRegistry] command deleted: path=%s" , dataPath ) ) ; }
@ Override public void destroyObject ( final Object obj ) throws Exception { if ( obj instanceof NettyChannel ) { NettyChannel client = ( NettyChannel ) obj ; URL url = nettyClient . getUrl ( ) ; try { client . close ( ) ; LoggerUtil . info ( factoryName + " client disconnect Success: " + url . getUri ( ) ) ; } catch ( Exception e ) { LoggerUtil . error ( factoryName + " client disconnect Error: " + url . getUri ( ) , e ) ; } } }
@ Override public void destroyObject ( final Object obj ) throws Exception { if ( obj instanceof NettyChannel ) { NettyChannel client = ( NettyChannel ) obj ; URL url = nettyClient . getUrl ( ) ; try { client . close ( ) ; LoggerUtil . info ( factoryName + " client disconnect Success: " + url . getUri ( ) ) ; } catch ( Exception e ) { LoggerUtil . error ( factoryName + " client disconnect Error: " + url . getUri ( ) , e ) ; } } }
@ Override public void close ( ) { try { channel . close ( ) ; } catch ( Throwable e ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Error closing socket: " + Util . getErrorMessage ( e ) ) ; } } }
private final void waitTillStabilized ( boolean failIfNotConnected ) throws AerospikeException { int count = - 1 ; for ( int i = 0 ; i < 3 ; i ++ ) { tend ( failIfNotConnected ) ; if ( count == nodes . length ) { return ; } Util . sleep ( 1 ) ; count = nodes . length ; } String message = "Cluster not stabilized after multiple tend attempts" ; if ( failIfNotConnected ) { throw new AerospikeException ( message ) ; } else { Log . warn ( message ) ; } }
protected final void refreshRacks ( ) { if ( failures > 0 || ! active ) { return ; } try { if ( Log . debugEnabled ( ) ) { Log . debug ( "Update racks for node " + this ) ; } RackParser parser = new RackParser ( tendConnection , this ) ; rebalanceGeneration = parser . getGeneration ( ) ; racks = parser . getRacks ( ) ; } catch ( Exception e ) { refreshFailed ( e ) ; } }
@ Override protected void sendCancel ( ) { inputQueue . clear ( ) ; resultSet . abort ( ) ; while ( ! inputQueue . offer ( LuaValue . NIL ) ) { if ( inputQueue . poll ( ) == null ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Lua input queue " + statement . taskId + " both offer and poll failed on abort" ) ; } break ; } } }
public static byte [ ] resizeBuffer ( int size ) { if ( size > THREAD_LOCAL_CUTOFF ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " allocate buffer on heap " + size ) ; } return new byte [ size ] ; } if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " resize buffer to " + size ) ; } BufferThreadLocal . set ( new byte [ size ] ) ; return BufferThreadLocal . get ( ) ; }
public static byte [ ] resizeBuffer ( int size ) { if ( size > THREAD_LOCAL_CUTOFF ) { if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " allocate buffer on heap " + size ) ; } return new byte [ size ] ; } if ( Log . debugEnabled ( ) ) { Log . debug ( "Thread " + Thread . currentThread ( ) . getId ( ) + " resize buffer to " + size ) ; } BufferThreadLocal . set ( new byte [ size ] ) ; return BufferThreadLocal . get ( ) ; }
@ Override public void onFailure ( MessageProtos . Message message ) { logger . info ( "Send hello failed {}" , message . toString ( ) ) ; }
private void printUuidNodeMap ( ) { uuidNodeMap . keySet ( ) . forEach ( entry -> { logger . debug ( entry . toString ( ) + " -> " + uuidNodeMap . get ( entry ) . get ( Constants . TYPE_STR_JSON_LD ) ) ; } ) ; }
public void tellToSource ( MessageProtos . Message request ) { logger . info ( "REPLY ok to Source actor {}" , sender ( ) . path ( ) . toSerializationFormat ( ) ) ; sender ( ) . tell ( request , getSelf ( ) ) ; }
public ResponseEntity < Object > sendAttestationResponseToRequester ( Claim claim , JsonNode request ) { String url = openSaberUrl + OpensaberApiUrlPaths . ATTEST . replace ( ENTITY_ID , claim . getEntityId ( ) ) . replace ( ENTITY , claim . getEntity ( ) ) . replace ( PROPERTY_URI , claim . getPropertyURI ( ) ) ; logger . info ( "Sending attestation request to {}" , url ) ; return restTemplate . exchange ( url , HttpMethod . POST , new HttpEntity < > ( request ) , Object . class ) ; }
private void compileSequence ( ) { try { if ( ! subSequences . isEmpty ( ) ) { log . warn ( "A sequence is defined - ByteSequence is clearing any sub-objects (probably from XML parsing) before compiling: " + sequence ) ; subSequences . clear ( ) ; } ByteSequenceCompiler . COMPILER . compile ( this , sequence , getAnchor ( ) ) ; } catch ( CompileException e ) { log . warn ( "Compilation error in signature for sequence: " + sequence + "n" + e . getMessage ( ) , e ) ; isInvalidByteSequence = true ; } }
private void compileSequence ( ) { try { if ( ! subSequences . isEmpty ( ) ) { log . warn ( "A sequence is defined - ByteSequence is clearing any sub-objects (probably from XML parsing) before compiling: " + sequence ) ; subSequences . clear ( ) ; } ByteSequenceCompiler . COMPILER . compile ( this , sequence , getAnchor ( ) ) ; } catch ( CompileException e ) { log . warn ( "Compilation error in signature for sequence: " + sequence + "n" + e . getMessage ( ) , e ) ; isInvalidByteSequence = true ; } }
private void logUnknownProperty ( String propertyName , Object target ) { log . warn ( "Unknown property " + propertyName + " requested for " + target . getClass ( ) . getSimpleName ( ) ) ; }
@ Override public ProfileInstance openProfile ( String profileId ) { log . info ( "Opening profile: " + profileId ) ; if ( ! profileContextLocator . hasProfileContext ( profileId ) ) { throw new IllegalArgumentException ( String . format ( "No such profile id [%s]" , profileId ) ) ; } ProfileInstance profile = profileContextLocator . getProfileInstance ( profileId ) ; profileContextLocator . openProfileInstanceManager ( profile ) ; profile . fireListeners ( ) ; return profile ; }
@ Override public Future < ? > start ( String profileId ) throws IOException { log . info ( "Starting profile: " + profileId ) ; ProfileInstanceManager profileInstanceManager = getProfileInstanceManager ( profileId ) ; return profileInstanceManager . start ( ) ; }
@ Override public void close ( ) { log . debug ( String . format ( "Closing database [%s]" , config . getJdbcUrl ( ) ) ) ; super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( e . getMessage ( ) ) ; } else { log . error ( e . getMessage ( ) , e ) ; } } }
@ Override public void close ( ) { log . debug ( String . format ( "Closing database [%s]" , config . getJdbcUrl ( ) ) ) ; super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( e . getMessage ( ) ) ; } else { log . error ( e . getMessage ( ) , e ) ; } } }
@ Override public void close ( ) { log . debug ( String . format ( "Closing database [%s]" , config . getJdbcUrl ( ) ) ) ; super . close ( ) ; String url = config . getJdbcUrl ( ) + ";shutdown=true" ; try { DriverManager . getConnection ( url ) ; } catch ( SQLException e ) { if ( "08006" . equals ( e . getSQLState ( ) ) ) { log . debug ( e . getMessage ( ) ) ; } else { log . error ( e . getMessage ( ) , e ) ; } } }
private void closeRequest ( ) { requests . remove ( request ) ; try { request . close ( ) ; } catch ( IOException e ) { log . error ( String . format ( "Error closing request [%s]" , request . getIdentifier ( ) . getUri ( ) ) , e ) ; } }
@ Override public void handleExport ( final ExportReportAction action ) { final Path target = action . exportFileChooser . getSelectedFile ( ) . toPath ( ) ; logReportExport ( target . toAbsolutePath ( ) . toString ( ) ) ; try { Files . copy ( action . droidReportXml , target ) ; } catch ( IOException e ) { log . error ( e . getMessage ( ) , e ) ; throw new RuntimeException ( e ) ; } }
@ Override public void windowClosed ( final WindowEvent e ) { if ( reportFile != null ) { if ( Files . exists ( reportFile ) ) { try { Files . deleteIfExists ( reportFile ) ; } catch ( final IOException ex ) { String message = String . format ( "Could not delete report file: %s. " + "Will try to delete on exit." , reportFile . toAbsolutePath ( ) . toString ( ) ) ; log . warn ( message ) ; reportFile . toFile ( ) . deleteOnExit ( ) ; } } } }
@ DELETE @ Path ( "setting/{settingId}" ) public Response removeSetting ( @ PathParam ( "settingId" ) String settingId ) throws IOException { logger . info ( "Remove interpreterSetting {}" , settingId ) ; interpreterSettingManager . remove ( settingId ) ; zeppelinResource . persistToDB ( this . project ) ; return new JsonResponse ( Status . OK ) . build ( ) ; }
private void checkIfUserIsAnon ( String errorMsg ) { boolean isAuthenticated = SecurityUtils . isAuthenticated ( ) ; if ( isAuthenticated && SecurityUtils . getPrincipal ( ) . equals ( "anonymous" ) ) { LOG . info ( "Anonymous user cannot set any permissions for this note." ) ; throw new ForbiddenException ( errorMsg ) ; } }
@ Override public void visit ( Hayes hayes ) { LOGGER . info ( hayes + " used with Dos configurator." ) ; }
private static void log ( String msg ) { LOGGER . info ( msg ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "The knight receives an enchanted sword." ) ; var enchantedSword = new Sword ( new SoulEatingEnchantment ( ) ) ; enchantedSword . wield ( ) ; enchantedSword . swing ( ) ; enchantedSword . unwield ( ) ; LOGGER . info ( "The valkyrie receives an enchanted hammer." ) ; var hammer = new Hammer ( new FlyingEnchantment ( ) ) ; hammer . wield ( ) ; hammer . swing ( ) ; hammer . unwield ( ) ; }
public static void main ( String [ ] args ) { LOGGER . info ( "The knight receives an enchanted sword." ) ; var enchantedSword = new Sword ( new SoulEatingEnchantment ( ) ) ; enchantedSword . wield ( ) ; enchantedSword . swing ( ) ; enchantedSword . unwield ( ) ; LOGGER . info ( "The valkyrie receives an enchanted hammer." ) ; var hammer = new Hammer ( new FlyingEnchantment ( ) ) ; hammer . wield ( ) ; hammer . swing ( ) ; hammer . unwield ( ) ; }
@ Override public void swing ( ) { LOGGER . info ( "The sword is swinged." ) ; enchantment . apply ( ) ; }
public void playSound ( ) { LOGGER . info ( "Playing sound" ) ; numberOfPlayedSounds ++ ; }
private void handleEvent ( StartingData data ) { started = data . getWhen ( ) ; LOGGER . info ( "Receiver {} sees application started at {}" , id , started ) ; }
@ Override public void attack ( ) { LOGGER . info ( "The troll tries to grab you!" ) ; }
@ Override public void run ( ) { var countries = world . fetch ( ) ; LOGGER . info ( "Our world currently has the following countries:-" ) ; countries . stream ( ) . map ( country -> "t" + country ) . forEach ( LOGGER :: info ) ; }
@ Override public void status ( ) { if ( ! isComplete ) { LOGGER . info ( "[{}] is not done." , eventId ) ; } else { LOGGER . info ( "[{}] is done." , eventId ) ; } }
@ Override public void status ( ) { if ( ! isComplete ) { LOGGER . info ( "[{}] is not done." , eventId ) ; } else { LOGGER . info ( "[{}] is done." , eventId ) ; } }
@ Override public void sergeantReady ( ) { LOGGER . info ( "[Sergeant] " + unit . getName ( ) + " is ready!" ) ; }
public static void main ( String [ ] args ) { var car1 = CarsFactory . getCar ( CarType . FORD ) ; var car2 = CarsFactory . getCar ( CarType . FERRARI ) ; LOGGER . info ( car1 . getDescription ( ) ) ; LOGGER . info ( car2 . getDescription ( ) ) ; }
public static void main ( String [ ] args ) { var car1 = CarsFactory . getCar ( CarType . FORD ) ; var car2 = CarsFactory . getCar ( CarType . FERRARI ) ; LOGGER . info ( car1 . getDescription ( ) ) ; LOGGER . info ( car2 . getDescription ( ) ) ; }
@ Override public void drink ( ) { LOGGER . info ( "You feel blessed. (Potion={})" , System . identityHashCode ( this ) ) ; }
@ Override public void display ( ) { LOGGER . info ( "Displaying catapults" ) ; }
private static long ap ( long i ) { try { Thread . sleep ( i ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; } return i * ( i + 1 ) / 2 ; }
@ Override public void resetLottery ( ) { administration . resetLottery ( ) ; logger . info ( "The lottery ticket database was cleared." ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
private static void printMainMenu ( ) { LOGGER . info ( "" ) ; LOGGER . info ( "### Lottery Service Console ###" ) ; LOGGER . info ( "(1) Query lottery account funds" ) ; LOGGER . info ( "(2) Add funds to lottery account" ) ; LOGGER . info ( "(3) Submit ticket" ) ; LOGGER . info ( "(4) Check ticket" ) ; LOGGER . info ( "(5) Exit" ) ; }
public static void main ( String [ ] args ) { var mw = new ArrayTransposeMasterWorker ( ) ; var rows = 10 ; var columns = 20 ; var inputMatrix = ArrayUtilityMethods . createRandomIntMatrix ( rows , columns ) ; var input = new ArrayInput ( inputMatrix ) ; var result = ( ArrayResult ) mw . getResult ( input ) ; if ( result != null ) { ArrayUtilityMethods . printMatrix ( inputMatrix ) ; ArrayUtilityMethods . printMatrix ( result . data ) ; } else { LOGGER . info ( "Please enter non-zero input" ) ; } }
@ Override public void partyAction ( Action action ) { LOGGER . info ( "{} {}" , this , action . getDescription ( ) ) ; }
private static String readFirstLine ( final String file ) { String firstLine = null ; try ( var bufferedReader = new BufferedReader ( new FileReader ( file ) ) ) { while ( bufferedReader . ready ( ) ) { firstLine = bufferedReader . readLine ( ) ; } LOGGER . info ( "ModuleTest::readFirstLine() : firstLine : " + firstLine ) ; } catch ( final IOException e ) { LOGGER . error ( "ModuleTest::readFirstLine()" , e ) ; } return firstLine ; }
private static String readFirstLine ( final String file ) { String firstLine = null ; try ( var bufferedReader = new BufferedReader ( new FileReader ( file ) ) ) { while ( bufferedReader . ready ( ) ) { firstLine = bufferedReader . readLine ( ) ; } LOGGER . info ( "ModuleTest::readFirstLine() : firstLine : " + firstLine ) ; } catch ( final IOException e ) { LOGGER . error ( "ModuleTest::readFirstLine()" , e ) ; } return firstLine ; }
@ Override public WebRequest newWebRequest ( HttpServletRequest servletRequest , String filterPath ) { if ( ! DEMO_MODE_USING_CREDENTIALS_AS_QUERYARGS ) { return super . newWebRequest ( servletRequest , filterPath ) ; } try { var uname = servletRequest . getParameter ( "user" ) ; if ( uname != null ) { servletRequest . getSession ( ) . invalidate ( ) ; } } catch ( Exception e ) { LOGGER . error ( e . getMessage ( ) ) ; } return super . newWebRequest ( servletRequest , filterPath ) ; }
public AlbumPage selectAlbum ( String albumTitle ) { var albumLinks = ( List < HtmlAnchor > ) page . getByXPath ( "//tr[@class='album']//a" ) ; for ( var anchor : albumLinks ) { if ( anchor . getTextContent ( ) . equals ( albumTitle ) ) { try { anchor . click ( ) ; return new AlbumPage ( webClient ) ; } catch ( IOException e ) { LOGGER . error ( "An error occured on selectAlbum" , e ) ; } } } throw new IllegalArgumentException ( "No links with the album title: " + albumTitle ) ; }
@ Test void shouldExecuteApplicationWithoutException ( ) { App . main ( new String [ ] { } ) ; LOGGER . info ( "Executed successfully without exception." ) ; }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void consume ( ) { while ( true ) { try { var msg = queue . take ( ) ; if ( Message . POISON_PILL . equals ( msg ) ) { LOGGER . info ( "Consumer {} receive request to terminate." , name ) ; break ; } var sender = msg . getHeader ( Headers . SENDER ) ; var body = msg . getBody ( ) ; LOGGER . info ( "Message [{}] from [{}] received by [{}]" , body , sender , name ) ; } catch ( InterruptedException e ) { LOGGER . error ( "Exception caught." , e ) ; return ; } } }
public void print ( ) { for ( var i = 0 ; i <= size / 2 ; i ++ ) { LOGGER . info ( " PARENT : " + queue [ i ] + " LEFT CHILD : " + left ( i ) + " RIGHT CHILD :" + right ( i ) ) ; } }
public Message retrieveMsg ( ) { try { return blkQueue . poll ( ) ; } catch ( Exception e ) { LOGGER . error ( e . getMessage ( ) ) ; } return null ; }
@ Override public void run ( ) { writeLock . lock ( ) ; try { write ( ) ; } catch ( InterruptedException e ) { LOGGER . info ( "InterruptedException when writing" , e ) ; Thread . currentThread ( ) . interrupt ( ) ; } finally { writeLock . unlock ( ) ; } }
public Service getService ( String serviceName ) { if ( serviceCache . containsKey ( serviceName ) ) { var cachedService = serviceCache . get ( serviceName ) ; var name = cachedService . getName ( ) ; var id = cachedService . getId ( ) ; LOGGER . info ( "(cache call) Fetched service {}({}) from cache... !" , name , id ) ; return cachedService ; } return null ; }
public boolean ifNonZero ( int ... nums ) { LOGGER . info ( SOURCE_MODULE , VERSION ) ; return Arrays . stream ( nums ) . allMatch ( num -> num != 0 ) ; }
public int accumulateSum ( int ... nums ) { LOGGER . info ( "Source module {}" , VERSION ) ; var sum = 0 ; for ( final var num : nums ) { sum += num ; } return sum ; }
protected void spawnParticles ( String particleType , int count ) { logger . info ( "Spawn " + count + " particle with type " + particleType ) ; }
@ Override protected void confuseTarget ( String target ) { LOGGER . info ( "Approach the {} from behind." , target ) ; }
public void steal ( ) { var target = pickTarget ( ) ; LOGGER . info ( "The target has been chosen as {}." , target ) ; confuseTarget ( target ) ; stealTheItem ( target ) ; }
private static int printAndCountExceptions ( Result res ) { var counter = 0 ; for ( var ex : res . getExceptionList ( ) ) { counter ++ ; LOGGER . info ( ex ) ; } return counter ; }
public static void main ( String [ ] args ) { try { var world = new World ( ) ; var skeleton1 = new Skeleton ( 1 , 10 ) ; var skeleton2 = new Skeleton ( 2 , 70 ) ; var statue = new Statue ( 3 , 20 ) ; world . addEntity ( skeleton1 ) ; world . addEntity ( skeleton2 ) ; world . addEntity ( statue ) ; world . run ( ) ; Thread . sleep ( GAME_RUNNING_TIME ) ; world . stop ( ) ; } catch ( InterruptedException e ) { LOGGER . error ( e . getMessage ( ) ) ; } }
@ Override public void visitSoldier ( Soldier soldier ) { LOGGER . info ( "Greetings {}" , soldier ) ; }
public void blockInbound ( Collection < Address > destinations ) { for ( Address destination : destinations ) { inboundSettings . put ( destination , new InboundSettings ( false ) ) ; } LOGGER . debug ( "[{}] Blocked inbound from {}" , address , destinations ) ; }
public void unblockInbound ( Collection < Address > destinations ) { destinations . forEach ( inboundSettings :: remove ) ; LOGGER . debug ( "[{}] Unblocked inbound from {}" , address , destinations ) ; }
private Mono < Void > doShutdown ( ) { return Mono . defer ( ( ) -> { LOGGER . info ( "[{}][doShutdown] Shutting down" , localMember ) ; return Flux . concatDelayError ( leaveCluster ( ) , dispose ( ) , transport . stop ( ) ) . then ( ) . doFinally ( s -> scheduler . dispose ( ) ) . doOnSuccess ( avoid -> LOGGER . info ( "[{}][doShutdown] Shutdown" , localMember ) ) ; } ) ; }
private ByteBuffer encodeMetadata ( ) { ByteBuffer result = null ; try { result = config . metadataCodec ( ) . serialize ( localMetadata ) ; } catch ( Exception e ) { LOGGER . error ( "[{}] Failed to encode metadata: {}, cause: {}" , localMember , localMetadata , e . toString ( ) ) ; } return Optional . ofNullable ( result ) . orElse ( EMPTY_BUFFER ) ; }
public void onMessage ( ByteBuf byteBuf ) { try { if ( byteBuf == Unpooled . EMPTY_BUFFER ) { return ; } if ( ! byteBuf . isReadable ( ) ) { ReferenceCountUtil . safeRelease ( byteBuf ) ; return ; } final Message message = messageDecoder . apply ( byteBuf ) ; sink . emitNext ( message , RETRY_NOT_SERIALIZED ) ; } catch ( Exception e ) { LOGGER . error ( "[{}][onMessage] Exception occurred:" , address , e ) ; } }
CompletableFuture < List < KeyValueConfigEntity > > loadConfig ( KeyValueConfigName configName ) { return CompletableFuture . supplyAsync ( ( ) -> { List < KeyValueConfigEntity > result ; try { result = repository . findAll ( configName ) ; } catch ( Exception e ) { LOGGER . warn ( "Exception at {}.findAll({}), cause: {}" , repository . getClass ( ) . getSimpleName ( ) , configName , e ) ; result = Collections . emptyList ( ) ; } return result ; } , executor ) ; }
public static boolean safestRelease ( Object msg ) { try { return ( msg instanceof ReferenceCounted ) && ( ( ReferenceCounted ) msg ) . refCnt ( ) > 0 && ( ( ReferenceCounted ) msg ) . release ( ) ; } catch ( Throwable t ) { LOGGER . warn ( "Failed to release reference counted object: {}, cause: {}" , msg , t . toString ( ) ) ; return false ; } }
@ BeforeEach public final void baseSetUp ( TestInfo testInfo ) { LOGGER . info ( "***** Test started  : " + getClass ( ) . getSimpleName ( ) + "." + testInfo . getDisplayName ( ) + " *****" ) ; }
@ Override public void trace ( String msg ) { commonLogger . trace ( msg ) ; auditLogger . trace ( msg ) ; }
@ Override public void trace ( String msg ) { commonLogger . trace ( msg ) ; auditLogger . trace ( msg ) ; }
@ Override public void trace ( Marker marker , String msg ) { commonLogger . trace ( marker , msg ) ; auditLogger . trace ( marker , msg ) ; }
@ Override public void trace ( Marker marker , String msg ) { commonLogger . trace ( marker , msg ) ; auditLogger . trace ( marker , msg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg ) { commonLogger . trace ( marker , format , arg ) ; auditLogger . trace ( marker , format , arg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg ) { commonLogger . trace ( marker , format , arg ) ; auditLogger . trace ( marker , format , arg ) ; }
@ Override public void trace ( Marker marker , String format , Object arg1 , Object arg2 ) { commonLogger . trace ( marker , format , arg1 , arg2 ) ; auditLogger . trace ( marker , format , arg1 , arg2 ) ; }
@ Override public void trace ( Marker marker , String format , Object arg1 , Object arg2 ) { commonLogger . trace ( marker , format , arg1 , arg2 ) ; auditLogger . trace ( marker , format , arg1 , arg2 ) ; }
@ Override public void debug ( Marker marker , String msg ) { commonLogger . debug ( marker , msg ) ; auditLogger . debug ( marker , msg ) ; }
@ Override public void debug ( Marker marker , String msg ) { commonLogger . debug ( marker , msg ) ; auditLogger . debug ( marker , msg ) ; }
@ Override public void debug ( Marker marker , String msg , Throwable t ) { commonLogger . debug ( marker , msg , t ) ; auditLogger . debug ( marker , msg , t ) ; }
@ Override public void debug ( Marker marker , String msg , Throwable t ) { commonLogger . debug ( marker , msg , t ) ; auditLogger . debug ( marker , msg , t ) ; }
@ Override public void error ( String format , Object ... arguments ) { commonLogger . error ( format , arguments ) ; auditLogger . error ( format , arguments ) ; }
@ Override public void error ( String format , Object ... arguments ) { commonLogger . error ( format , arguments ) ; auditLogger . error ( format , arguments ) ; }
private Optional < ConfigurationModel > getSettingsConfiguration ( ) { try { return settingsUtility . getConfiguration ( ) ; } catch ( AlertException ex ) { logger . error ( "Could not find the settings configuration for proxy data" , ex ) ; } return Optional . empty ( ) ; }
private OffsetDateTime parseAuditDateString ( String dateString ) { OffsetDateTime date = null ; try { date = DateUtils . parseDate ( dateString , DateUtils . AUDIT_DATE_FORMAT ) ; } catch ( ParseException e ) { logger . error ( e . toString ( ) ) ; } return date ; }
protected void handleJobDetailsMissing ( DistributionEvent event ) { String failureMessage = "Received a distribution event for a Job that no longer exists" ; logger . warn ( "{}. Destination: {}" , failureMessage , event . getDestination ( ) ) ; auditAccessor . setAuditEntryFailure ( event . getJobId ( ) , event . getNotificationIds ( ) , failureMessage , null ) ; }
public void startTask ( ) { checkTaskEnabled ( ) ; String taskName = getTaskName ( ) ; if ( ! getEnabled ( ) ) { logger . info ( "{} is disabled and will not be scheduled to run." , taskName ) ; return ; } taskManager . registerTask ( this ) ; taskManager . scheduleCronTask ( scheduleCronExpression ( ) , taskName ) ; String nextRun = taskManager . getNextRunTime ( taskName ) . orElse ( "" ) ; logger . info ( "{} next run:     {}" , taskName , nextRun ) ; postTaskStartup ( ) ; }
public void startTask ( ) { checkTaskEnabled ( ) ; String taskName = getTaskName ( ) ; if ( ! getEnabled ( ) ) { logger . info ( "{} is disabled and will not be scheduled to run." , taskName ) ; return ; } taskManager . registerTask ( this ) ; taskManager . scheduleCronTask ( scheduleCronExpression ( ) , taskName ) ; String nextRun = taskManager . getNextRunTime ( taskName ) . orElse ( "" ) ; logger . info ( "{} next run:     {}" , taskName , nextRun ) ; postTaskStartup ( ) ; }
private Optional < String > retrieveProviderConfigEmailAddress ( Long providerConfigId ) { try { ProviderUserModel providerConfigUser = providerDataAccessor . getProviderConfigUserById ( providerConfigId ) ; return Optional . of ( providerConfigUser . getEmailAddress ( ) ) ; } catch ( AlertConfigurationException e ) { logger . warn ( "Failed to retrieve provider config user" , e ) ; return Optional . empty ( ) ; } }
private String getEntityString ( String entityKey ) { try { ConfigurationModel currentConfiguration = samlContext . getCurrentConfiguration ( ) ; return samlContext . getFieldValueOrEmpty ( currentConfiguration , entityKey ) ; } catch ( AlertException e ) { logger . error ( "Could not get the SAML entity." , e ) ; } return "" ; }
private void logField ( ConfigurationFieldModel fieldModel ) { String value = fieldModel . isSensitive ( ) ? "**********" : String . valueOf ( fieldModel . getFieldValues ( ) ) ; logger . info ( "    {} = {}" , fieldModel . getFieldKey ( ) , value ) ; }
private boolean isEnvironmentVariableActivated ( String environmentVariable ) { boolean activated = environmentVariableUtility . getEnvironmentValue ( environmentVariable ) . map ( Boolean :: valueOf ) . orElse ( false ) ; logger . info ( "{} = {}" , environmentVariable , activated ) ; return activated ; }
@ Override public List < String > process ( final List < String > input ) { final List < String > results = new ArrayList < > ( ) ; for ( final String inputItem : input ) { final String [ ] splitLines = inputItem . split ( regex ) ; results . addAll ( Arrays . asList ( splitLines ) ) ; } logger . trace ( String . format ( "SplitEach returning %d lines" , results . size ( ) ) ) ; return results ; }
@ Override protected DetectorEvaluationTree performEvaluation ( DetectorEvaluationTree rootEvaluation ) { logger . debug ( "Starting detector extraction." ) ; extractionEvaluation ( rootEvaluation ) ; return rootEvaluation ; }
private void deleteDirectoryIfEmpty ( @ NotNull File directory ) throws IOException { File [ ] files = directory . listFiles ( ) ; boolean noFiles = files == null || files . length == 0 ; if ( noFiles && directory . exists ( ) ) { logger . info ( "Cleaning up directory: " + directory . getAbsolutePath ( ) ) ; FileUtils . forceDelete ( directory ) ; } }
@ Override public void printDescription ( final Logger logger ) { logger . debug ( "No unique detector was found. Project info could not be found in a detector." ) ; }
private void safelyPhoneHome ( final Map < String , String > metadata , final String ... artifactModules ) { endPhoneHome ( ) ; try { currentPhoneHomeResponse = phoneHome ( metadata , artifactModules ) ; } catch ( final IllegalStateException e ) { logger . debug ( e . getMessage ( ) , e ) ; } }
@ Override public void writeLine ( final String line , final Exception e ) { logger . error ( line , e ) ; }
@ Override public void writeLine ( final String line , final Exception e ) { logger . info ( line , e ) ; }
@ Override public String getAlbumTitle ( URL url ) throws MalformedURLException { try { Element el = getFirstPage ( ) . select ( ".headtext" ) . first ( ) ; if ( el == null ) { throw new IOException ( "Unable to get album title" ) ; } String title = el . text ( ) ; return getHost ( ) + "_" + getGID ( url ) + "_" + title . trim ( ) ; } catch ( IOException e ) { LOGGER . info ( "Unable to find title at " + url ) ; } return super . getAlbumTitle ( url ) ; }
public List < String > getTags ( Document doc ) { List < String > tags = new ArrayList < > ( ) ; LOGGER . info ( "Getting tags" ) ; for ( Element tag : doc . select ( "td > div > a" ) ) { LOGGER . info ( "Found tag " + tag . text ( ) ) ; tags . add ( tag . text ( ) ) ; } return tags ; }
public List < String > getTags ( Document doc ) { List < String > tags = new ArrayList < > ( ) ; LOGGER . info ( "Getting tags" ) ; for ( Element tag : doc . select ( "td > div > a" ) ) { LOGGER . info ( "Found tag " + tag . text ( ) ) ; tags . add ( tag . text ( ) ) ; } return tags ; }
@ Override protected void downloadURL ( URL url , int index ) { if ( Utils . getConfigBoolean ( "instagram.download_images_only" , false ) && url . toString ( ) . contains ( ".mp4?" ) ) { LOGGER . info ( "Skipped video url: " + url ) ; return ; } addURLToDownload ( url , itemPrefixes . get ( index - 1 ) , "" , null , cookies ) ; }
public void getImage ( ) { try { Document doc = Http . url ( url ) . get ( ) ; String imageUrl = doc . getElementsByClass ( "pure-img" ) . attr ( "src" ) ; if ( imageUrl != "" ) { addURLToDownload ( new URL ( imageUrl ) , getPrefix ( index ) , "" , null , null , getImageName ( ) ) ; } else { LOGGER . error ( "Couldnt find image from url: " + url ) ; } } catch ( IOException e ) { LOGGER . error ( "[!] Exception while downloading image: " + url , e ) ; } }
public void getImage ( ) { try { Document doc = Http . url ( url ) . get ( ) ; String imageUrl = doc . getElementsByClass ( "pure-img" ) . attr ( "src" ) ; if ( imageUrl != "" ) { addURLToDownload ( new URL ( imageUrl ) , getPrefix ( index ) , "" , null , null , getImageName ( ) ) ; } else { LOGGER . error ( "Couldnt find image from url: " + url ) ; } } catch ( IOException e ) { LOGGER . error ( "[!] Exception while downloading image: " + url , e ) ; } }
public String getImageName ( ) { String name = this . url . toExternalForm ( ) ; try { name = name . substring ( name . lastIndexOf ( "/" ) + 1 ) ; } catch ( Exception e ) { LOGGER . info ( "Failed to get name for the image." ) ; name = null ; } return name + ".jpg" ; }
@ Override public List < String > getURLsFromPage ( Document doc ) { List < String > result = new ArrayList < > ( ) ; for ( Element e : doc . select ( "img.img" ) ) { String imageName = e . parent ( ) . attr ( "href" ) ; LOGGER . info ( getFullSizedImageFromURL ( imageName . split ( "/" ) [ 2 ] ) ) ; result . add ( getFullSizedImageFromURL ( imageName . split ( "/" ) [ 2 ] ) ) ; } return result ; }
private String getImageLinkFromDLLink ( String url ) { try { Connection . Response response = Jsoup . connect ( url ) . userAgent ( USER_AGENT ) . timeout ( 10000 ) . cookies ( cookies ) . followRedirects ( false ) . execute ( ) ; String imageURL = response . header ( "Location" ) ; LOGGER . info ( imageURL ) ; return imageURL ; } catch ( IOException e ) { LOGGER . info ( "Got error message " + e . getMessage ( ) + " trying to download " + url ) ; return null ; } }
private String getImageLinkFromDLLink ( String url ) { try { Connection . Response response = Jsoup . connect ( url ) . userAgent ( USER_AGENT ) . timeout ( 10000 ) . cookies ( cookies ) . followRedirects ( false ) . execute ( ) ; String imageURL = response . header ( "Location" ) ; LOGGER . info ( imageURL ) ; return imageURL ; } catch ( IOException e ) { LOGGER . info ( "Got error message " + e . getMessage ( ) + " trying to download " + url ) ; return null ; } }
public void displayAndLogError ( String line , Color color ) { appendLog ( line , color ) ; LOGGER . error ( line ) ; }
public static void saveConfig ( ) { try { config . save ( getConfigFilePath ( ) ) ; LOGGER . info ( "Saved configuration to " + getConfigFilePath ( ) ) ; } catch ( ConfigurationException e ) { LOGGER . error ( "Error while saving configuration: " , e ) ; } }
public static void saveConfig ( ) { try { config . save ( getConfigFilePath ( ) ) ; LOGGER . info ( "Saved configuration to " + getConfigFilePath ( ) ) ; } catch ( ConfigurationException e ) { LOGGER . error ( "Error while saving configuration: " , e ) ; } }
public static String removeCWD ( File saveAs ) { String prettySaveAs = saveAs . toString ( ) ; try { prettySaveAs = saveAs . getCanonicalPath ( ) ; String cwd = new File ( "." ) . getCanonicalPath ( ) + File . separator ; prettySaveAs = prettySaveAs . replace ( cwd , "." + File . separator ) ; } catch ( Exception e ) { LOGGER . error ( "Exception: " , e ) ; } return prettySaveAs ; }
public double getMajorIsotopeMass ( int elem ) { if ( this . majorIsotope [ elem ] != null ) return this . majorIsotope [ elem ] . getExactMass ( ) ; IIsotope major = getMajorIsotope ( elem ) ; if ( major == null ) { logger . warn ( "No major isotope for elem" + elem ) ; return 2 * elem ; } return major . getExactMass ( ) ; }
@ Override public Integer getCharge ( ) { Integer charge = super . getCharge ( ) ; logger . debug ( "Getting charge: " , charge ) ; return charge ; }
@ Override public Iterable < IIsotope > isotopes ( ) { logger . debug ( "Getting isotope iterator.." ) ; return super . isotopes ( ) ; }
@ Override public void removeMolecularFormula ( int position ) { logger . debug ( "Removing the formula at position: " , position ) ; super . removeMolecularFormula ( position ) ; }
@ Override public IAtom getAtom ( int idx ) { logger . debug ( "Getting atom at: " , idx ) ; return super . getAtom ( idx ) ; }
@ Override public ILonePair getLonePair ( int idx ) { logger . debug ( "Getting lone pair at: " , idx ) ; return super . getLonePair ( idx ) ; }
@ Override public IAtom getLastAtom ( ) { logger . debug ( "Getting last atom: " , super . getLastAtom ( ) ) ; return super . getLastAtom ( ) ; }
@ Override public List < ISingleElectron > getConnectedSingleElectronsList ( IAtom atom ) { logger . debug ( "Getting single electrons at atom: atom=" + atom , " single electrons=" + super . getConnectedSingleElectronsCount ( atom ) ) ; return super . getConnectedSingleElectronsList ( atom ) ; }
@ Override public double getBondOrderSum ( IAtom atom ) { logger . debug ( "Getting bond order sum for atom: " , atom ) ; return super . getBondOrderSum ( atom ) ; }
@ Override public void removeAtomOnly ( int position ) { logger . debug ( "Removing atom: " , position ) ; super . removeAtomOnly ( position ) ; }
@ Override public ISingleElectron removeSingleElectron ( int pos ) { logger . debug ( "Removing bond at " + pos ) ; return super . removeSingleElectron ( pos ) ; }
@ Override public Iterable < IBond > bonds ( ) { logger . debug ( "Getting connected bonds on base Atom class" ) ; throw new UnsupportedOperationException ( ) ; }
@ Override public Point3d getPoint3d ( ) { Point3d point3d = super . getPoint3d ( ) ; if ( point3d == null ) { logger . debug ( "Getting point3d: null" ) ; } else { logger . debug ( "Getting point3d: x=" + point3d . x + ", y=" + point3d . y , ", z=" + point3d . z ) ; } return point3d ; }
@ Override public Point3d getPoint3d ( ) { Point3d point3d = super . getPoint3d ( ) ; if ( point3d == null ) { logger . debug ( "Getting point3d: null" ) ; } else { logger . debug ( "Getting point3d: x=" + point3d . x + ", y=" + point3d . y , ", z=" + point3d . z ) ; } return point3d ; }
@ Override public Integer getValency ( ) { logger . debug ( "Getting valency: " , super . getValency ( ) ) ; return super . getValency ( ) ; }
@ Override public void setExactMass ( Double exactMass ) { logger . debug ( "Setting exact mass: " , exactMass ) ; super . setExactMass ( exactMass ) ; }
@ Override public void setSymbol ( String symbol ) { logger . debug ( "Setting symbol: " , symbol ) ; super . setSymbol ( symbol ) ; }
@ Override public List < IAtom > getConnectedAtomsList ( IAtom atom ) { logger . debug ( "Getting connecting atoms list for atom: " , atom ) ; return super . getConnectedAtomsList ( atom ) ; }
@ Override public Collection < String > getMonomerNames ( ) { logger . debug ( "Getting monomer names" ) ; return super . getMonomerNames ( ) ; }
@ Override public IStrand getStrand ( String cName ) { logger . debug ( "Getting strand by name: " , cName ) ; return super . getStrand ( cName ) ; }
@ Override public IBond clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IBond ) clone ; }
@ Override public IBond clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IBond ) clone ; }
@ Override public IAtom getOther ( IAtom atom ) { logger . debug ( "Getting connected atom to atom: " , atom ) ; return super . getOther ( atom ) ; }
@ Override public void setAtom ( IAtom atom , int position ) { logger . debug ( "Setting atom at position: " , atom ) ; super . setAtom ( atom , position ) ; }
@ Override public IChemModel getChemModel ( int number ) { logger . debug ( "Getting chemModel at: " , number ) ; return super . getChemModel ( number ) ; }
@ Override public ICrystal clone ( ) throws CloneNotSupportedException { ICrystal clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return clone ; }
@ Override public ICrystal clone ( ) throws CloneNotSupportedException { ICrystal clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return clone ; }
@ Override public Vector3d getA ( ) { logger . debug ( "Getting A axis: " , super . getA ( ) ) ; return super . getA ( ) ; }
@ Override public void setB ( Vector3d newAxis ) { logger . debug ( "Setting B axis to: " , newAxis ) ; super . setB ( newAxis ) ; }
@ Override public void setZ ( Integer value ) { logger . debug ( "Settting Z to: " , value ) ; super . setZ ( value ) ; }
@ Override public void setExpanded ( boolean bool ) { logger . debug ( "Setting the isExpanded state: " + bool ) ; super . setExpanded ( bool ) ; }
@ Override public String getLabel ( ) { logger . debug ( "Getting label: " , super . getLabel ( ) ) ; return super . getLabel ( ) ; }
@ Override public IPseudoAtom clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IPseudoAtom ) clone ; }
@ Override public IPseudoAtom clone ( ) throws CloneNotSupportedException { Object clone = null ; try { clone = super . clone ( ) ; } catch ( Exception exception ) { logger . error ( "Could not clone DebugAtom: " + exception . getMessage ( ) , exception ) ; logger . debug ( exception ) ; } return ( IPseudoAtom ) clone ; }
@ Override public IAtomContainerSet getReactants ( ) { logger . debug ( "Getting reactants: " , super . getReactants ( ) ) ; return super . getReactants ( ) ; }
@ Override public void addReactant ( IAtomContainer reactant ) { logger . debug ( "Adding reactant: " , reactant ) ; super . addReactant ( reactant ) ; }
@ Override public void addProduct ( IAtomContainer product ) { logger . debug ( "Adding product: " , product ) ; super . addProduct ( product ) ; }
@ Override public Map < String , IMonomer > getMonomers ( ) { logger . debug ( "Getting monomers as hashtable" ) ; return super . getMonomers ( ) ; }
public static void translateAllPositive ( IAtomContainer atomCon ) { double minX = Double . MAX_VALUE ; double minY = Double . MAX_VALUE ; for ( IAtom atom : atomCon . atoms ( ) ) { if ( atom . getPoint2d ( ) != null ) { if ( atom . getPoint2d ( ) . x < minX ) { minX = atom . getPoint2d ( ) . x ; } if ( atom . getPoint2d ( ) . y < minY ) { minY = atom . getPoint2d ( ) . y ; } } } logger . debug ( "Translating: minx=" + minX + ", minY=" + minY ) ; translate2D ( atomCon , minX * - 1 , minY * - 1 ) ; }
public boolean allSaturated ( IAtomContainer ac ) throws CDKException { logger . debug ( "Are all atoms saturated?" ) ; for ( int f = 0 ; f < ac . getAtomCount ( ) ; f ++ ) { if ( ! isSaturated ( ac . getAtom ( f ) , ac ) ) return false ; } return true ; }
@ Test public void testInfo_Object_int ( ) throws Exception { ILoggingTool logger = getLoggingTool ( ) ; logger . info ( this , 1 ) ; }
protected AtomTypeFactory getAtomTypeFactory ( IChemObjectBuilder builder ) throws CDKException { if ( structgenATF == null ) { try { structgenATF = AtomTypeFactory . getInstance ( atomTypeList , builder ) ; } catch ( Exception exception ) { logger . debug ( exception ) ; throw new CDKException ( "Could not instantiate AtomTypeFactory!" , exception ) ; } } return structgenATF ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber + ":" , line ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber + ":" , line ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
public String readLine ( ) throws CDKException { String line = null ; try { line = input . readLine ( ) ; lineNumber ++ ; logger . debug ( "read line " + lineNumber + ":" , line ) ; } catch ( Exception exception ) { String error = "Unexpected error while reading file: " + exception . getMessage ( ) ; logger . error ( error ) ; logger . debug ( exception ) ; throw new CDKException ( error , exception ) ; } return line ; }
@ Override public void processIOSettingQuestion ( IOSetting setting ) { if ( "ForceReadAs3DCoordinates" . equals ( setting . getName ( ) ) ) { try { setting . setSetting ( "true" ) ; } catch ( CDKException e ) { logger . error ( "Could not set forceReadAs3DCoords setting: " , e . getMessage ( ) ) ; logger . debug ( e ) ; } } }
@ Override public void processIOSettingQuestion ( IOSetting setting ) { if ( "ForceReadAs3DCoordinates" . equals ( setting . getName ( ) ) ) { try { setting . setSetting ( "true" ) ; } catch ( CDKException e ) { logger . error ( "Could not set forceReadAs3DCoords setting: " , e . getMessage ( ) ) ; logger . debug ( e ) ; } } }
@ Override public void write ( IChemObject object ) throws CDKException { customizeJob ( ) ; if ( object instanceof IAtomContainer ) { try { writeAtomContainer ( ( IAtomContainer ) object ) ; writer . flush ( ) ; } catch ( Exception ex ) { logger . error ( ex . getMessage ( ) ) ; logger . debug ( ex ) ; throw new CDKException ( "Exception while writing to CDK source code: " + ex . getMessage ( ) , ex ) ; } } else { throw new CDKException ( "Only supported is writing of IAtomContainer objects." ) ; } }
@ Override public void write ( IChemObject object ) throws CDKException { customizeJob ( ) ; if ( object instanceof IAtomContainer ) { try { writeAtomContainer ( ( IAtomContainer ) object ) ; writer . flush ( ) ; } catch ( Exception ex ) { logger . error ( ex . getMessage ( ) ) ; logger . debug ( ex ) ; throw new CDKException ( "Exception while writing to CDK source code: " + ex . getMessage ( ) , ex ) ; } } else { throw new CDKException ( "Only supported is writing of IAtomContainer objects." ) ; } }
@ Override public void endDocument ( ) { logger . debug ( "Closing document" ) ; logger . info ( "End CDO Object" ) ; }
@ Override public void endDocument ( ) { logger . debug ( "Closing document" ) ; logger . info ( "End CDO Object" ) ; }
@ Override public void setWriter ( final Writer writer ) throws CDKException { logger . warn ( "possible loss of encoding when using a Writer with CMLWriter" ) ; this . output = new OutputStream ( ) { @ Override public void write ( int b ) throws IOException { writer . write ( b ) ; } } ; }
@ Test public void testFingerprints ( ) throws Exception { logger . info ( "Bayesian/Fingerprints test: verifying circular fingerprints for a single molecule" ) ; checkFP ( REF_MOLECULE , CircularFingerprinter . CLASS_ECFP6 , 0 , REF_ECFP6_0 ) ; checkFP ( REF_MOLECULE , CircularFingerprinter . CLASS_ECFP6 , 1024 , REF_ECFP6_1024 ) ; }
private List < IAtomContainer > removeDuplicates ( List < IAtomContainer > tautomers ) throws CDKException { Set < String > cansmis = new HashSet < > ( ) ; List < IAtomContainer > result = new ArrayList < > ( ) ; for ( IAtomContainer tautomer : tautomers ) { if ( cansmis . add ( CANSMI . create ( tautomer ) ) ) result . add ( tautomer ) ; } LOGGER . debug ( "# tautomers after clean up : " , tautomers . size ( ) ) ; return result ; }
private GTRasterDataBinding parseTiff ( File file ) { Hints hints = new Hints ( Hints . FORCE_LONGITUDE_FIRST_AXIS_ORDER , Boolean . TRUE ) ; GeoTiffReader reader ; try { reader = new GeoTiffReader ( file , hints ) ; GridCoverage2D coverage = ( GridCoverage2D ) reader . read ( null ) ; return new GTRasterDataBinding ( coverage ) ; } catch ( Exception e ) { LOGGER . error ( "Exception while trying to create GTRasterDataBinding out of tiff." , e ) ; throw new RuntimeException ( e ) ; } }
private REXP internalEval ( String command ) throws RserveException { if ( logAllEval ) log . debug ( "[R] {}" , command ) ; return super . eval ( command ) ; }
@ Override public void shutdown ( ) { LOGGER . info ( "Shutting down ..." ) ; this . algorithms . clear ( ) ; }
@ Override public void propertyChange ( PropertyChangeEvent evt ) { LOGGER . info ( "received PropertyChangeEvent: " + evt . getPropertyName ( ) ) ; updateRepositoryConfiguration ( ) ; CustomDataTypeManager . getInstance ( ) . update ( ) ; }
public boolean getEnableBatchStart ( ) { boolean isBatch = DEFAULT_ENABLEBATCHSTART ; String batch_c = getConfigVariable ( RWPSConfigVariables . ENABLE_BATCH_START ) ; if ( batch_c != null && ! batch_c . equals ( "" ) ) { try { isBatch = Boolean . parseBoolean ( batch_c ) ; } catch ( NumberFormatException e ) { LOGGER . warn ( "Config variable " + RWPSConfigVariables . RSERVE_PORT + " does not contain a parseble boolean. Using default port " + isBatch ) ; } } return isBatch ; }
private void logException ( Exception exception ) { StringBuilder errorBuilder = new StringBuilder ( exception . getMessage ( ) ) ; Throwable cause = getRootCause ( exception ) ; if ( cause != exception ) { errorBuilder . append ( ", exception message: " ) . append ( cause . getMessage ( ) ) ; } LOGGER . error ( errorBuilder . toString ( ) ) ; }
protected void cleanupDrivers ( Set < String > provided ) { LOGGER . debug ( "Deregistering JDBC driver is enabled!" ) ; Enumeration < Driver > drivers = DriverManager . getDrivers ( ) ; while ( drivers . hasMoreElements ( ) ) { deregisterDriver ( drivers . nextElement ( ) , provided ) ; } }
public static void close ( ResultSet closable ) { if ( closable != null ) { try { closable . close ( ) ; } catch ( SQLException ex ) { LOG . error ( "Error closing ResultSet!" , ex ) ; } } }
@ Override public void removeProcedure ( String procedure ) { CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Removing Procedure {}" , procedure ) ; this . procedures . remove ( procedure ) ; }
@ Override public void setMaxPhenomenonTimeForOffering ( String offering , DateTime maxTime ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Setting maximal EventTime for Offering {} to {}" , offering , maxTime ) ; if ( maxTime == null ) { this . maxPhenomenonTimeForOfferings . remove ( offering ) ; } else { this . maxPhenomenonTimeForOfferings . put ( offering , DateTimeHelper . toUTC ( maxTime ) ) ; } }
@ Override public void addOfferingForObservableProperty ( String observableProperty , String offering ) { CacheValidation . notNullOrEmpty ( OBSERVABLE_PROPERTY , observableProperty ) ; CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Adding offering {} to observableProperty {}" , offering , observableProperty ) ; this . offeringsForObservableProperties . computeIfAbsent ( observableProperty , createSynchronizedSet ( ) ) . add ( offering ) ; }
@ Override public void addProcedureForFeatureOfInterest ( String featureOfInterest , String procedure ) { CacheValidation . notNullOrEmpty ( FEATURE_OF_INTEREST , featureOfInterest ) ; CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Adding procedure {} to featureOfInterest {}" , procedure , featureOfInterest ) ; this . proceduresForFeaturesOfInterest . computeIfAbsent ( featureOfInterest , createSynchronizedSet ( ) ) . add ( procedure ) ; }
@ Override public void addProcedureForOffering ( String offering , String procedure ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( PROCEDURE , procedure ) ; LOG . trace ( "Adding procedure {} to offering {}" , procedure , offering ) ; this . proceduresForOfferings . computeIfAbsent ( offering , createSynchronizedSet ( ) ) . add ( procedure ) ; }
@ Override public void removeObservablePropertiesForOffering ( String offering ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Removing observableProperties for offering {}" , offering ) ; this . observablePropertiesForOfferings . remove ( offering ) ; }
@ Override public void removeObservablePropertyForOffering ( String offering , String observableProperty ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( OBSERVABLE_PROPERTY , observableProperty ) ; LOG . trace ( "Removing observableProperty {} from offering {}" , observableProperty , offering ) ; this . observablePropertiesForOfferings . getOrDefault ( offering , Collections . emptySet ( ) ) . remove ( observableProperty ) ; }
@ Override public void removeRolesForRelatedFeature ( String relatedFeature ) { CacheValidation . notNullOrEmpty ( RELATED_FEATURE , relatedFeature ) ; LOG . trace ( "Removing roles for relatedFeature {}" , relatedFeature ) ; this . rolesForRelatedFeatures . remove ( relatedFeature ) ; }
@ Override public void setObservablePropertiesForResultTemplate ( String resultTemplate , Collection < String > observableProperties ) { CacheValidation . notNullOrEmpty ( RESULT_TEMPLATE , resultTemplate ) ; final Set < String > newValue = newSynchronizedSet ( observableProperties ) ; LOG . trace ( "Setting observableProperties for resultTemplate {} to {}" , resultTemplate , newValue ) ; this . observedPropertiesForResultTemplates . put ( resultTemplate , newValue ) ; }
@ Override public void clearRelatedFeaturesForOfferings ( ) { LOG . trace ( "Clearing related features for offerings" ) ; this . relatedFeaturesForOfferings . clear ( ) ; }
@ Override public void removeOffering ( String offering ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; LOG . trace ( "Removing Offering {}" , offering ) ; this . offerings . remove ( offering ) ; }
@ Override public void removeFeatureOfInterestTypeForOffering ( String offering , String featureOfInterestType ) { CacheValidation . notNullOrEmpty ( OFFERING , offering ) ; CacheValidation . notNullOrEmpty ( FEATURE_OF_INTEREST_TYPE , featureOfInterestType ) ; LOG . trace ( "Removing featureOfInterestType {} from offering {}" , featureOfInterestType , offering ) ; this . featureOfInterestTypesForOfferings . getOrDefault ( offering , Collections . emptySet ( ) ) . remove ( featureOfInterestType ) ; }
@ Override public void clearSupportedLanguage ( ) { LOG . trace ( "Clearing supported languages" ) ; this . supportedLanguages . clear ( ) ; }
@ Override public void removeProcedureHumanReadableNameForIdentifier ( String identifier ) { CacheValidation . notNullOrEmpty ( PROCEDURE , identifier ) ; LOG . trace ( "Removing procedure human readable name for identifier {}" , identifier ) ; procedureIdentifierHumanReadableName . remove ( identifier ) ; }
@ Override public void clearCompositePhenomenon ( ) { LOG . trace ( "Clearing composite phenomenon" ) ; this . compositePhenomenons . clear ( ) ; }
@ Override public void clearCompositePhenomenonsForObservableProperty ( ) { LOG . trace ( "Clearing composite phenomenon for observable properties" ) ; this . compositePhenomenonsForObservableProperty . clear ( ) ; }
@ Override public void addPublishedOffering ( String offering ) { CacheValidation . notNullOrEmpty ( PUBLISHED_OFFERING , offering ) ; LOG . trace ( "Adding published offering {}" , offering ) ; publishedOffering . add ( offering ) ; }
private void logAndWait ( CompleteUpdate update , CompleteUpdate waitFor ) throws OwsExceptionReport { LOGGER . trace ( "{} waiting for {}" , update , waitFor ) ; waitFor . waitForCompletion ( ) ; LOGGER . trace ( "{} stopped waiting for {}" , update , waitFor ) ; }
private void logAndWait ( CompleteUpdate update , CompleteUpdate waitFor ) throws OwsExceptionReport { LOGGER . trace ( "{} waiting for {}" , update , waitFor ) ; waitFor . waitForCompletion ( ) ; LOGGER . trace ( "{} stopped waiting for {}" , update , waitFor ) ; }
void waitForCompletion ( ) throws OwsExceptionReport { lock ( ) ; try { while ( ! isFinished ( ) ) { try { finished . await ( ) ; } catch ( InterruptedException ex ) { LOGGER . warn ( "Error while waiting for finishing!" , ex ) ; } } if ( getState ( ) == State . FAILED ) { throw getUpdate ( ) . getFailureCause ( ) ; } } finally { unlock ( ) ; } }
private static String createFeatureStatement ( int featureId , Double [ ] coordinates ) { String featureStatement = String . format ( SQL_INSERT_FEATURE , Integer . toString ( featureId ) , Double . toString ( coordinates [ X_COORD_INDEX ] ) . replaceAll ( "," , "." ) , Double . toString ( coordinates [ Y_COORD_INDEX ] ) . replaceAll ( "," , "." ) ) ; LOGGER . debug ( featureStatement ) ; return featureStatement ; }
public ProcedureEntity getProcedureForIdentifierIncludeDeleted ( final String identifier , final Session session ) { Criteria criteria = session . createCriteria ( ProcedureEntity . class ) . add ( Restrictions . eq ( ProcedureEntity . IDENTIFIER , identifier ) ) ; LOGGER . trace ( "QUERY getProcedureForIdentifierIncludeDeleted(identifier): {}" , HibernateHelper . getSqlString ( criteria ) ) ; return ( ProcedureEntity ) criteria . uniqueResult ( ) ; }
public EReportingAssessmentTypeEntity getEReportingAssessmentType ( AssessmentType assessmentType , Session session ) { Criteria c = getDefaultCriteria ( session ) ; c . add ( Restrictions . eq ( EReportingAssessmentTypeEntity . ID , assessmentType . getId ( ) ) ) ; LOGGER . trace ( LOG_TEMPLATE , HibernateHelper . getSqlString ( c ) ) ; return ( EReportingAssessmentTypeEntity ) c . uniqueResult ( ) ; }
public Criteria getSeriesCriteria ( Collection < String > procedures , Collection < String > observedProperties , Collection < String > features , Session session ) { final Criteria c = createCriteriaFor ( procedures , observedProperties , features , session ) ; LOGGER . trace ( "QUERY getSeries(procedures, observableProperteies, features): {}" , HibernateHelper . getSqlString ( c ) ) ; return c ; }
public DataEntity < ? > getFirstObservationFor ( DatasetEntity series , Session session ) { Criteria c = getDefaultObservationCriteria ( session ) ; c . add ( Restrictions . eq ( DataEntity . PROPERTY_DATASET_ID , series . getId ( ) ) ) ; c . addOrder ( Order . asc ( DataEntity . PROPERTY_SAMPLING_TIME_START ) ) ; c . setMaxResults ( 1 ) ; LOGGER . trace ( "QUERY getFirstObservationFor(series): {}" , HibernateHelper . getSqlString ( c ) ) ; return ( DataEntity ) c . uniqueResult ( ) ; }
protected void close ( Statement stmt ) { if ( stmt != null ) { try { stmt . close ( ) ; } catch ( SQLException e ) { LOG . error ( "Error closing statement" , e ) ; } } }
private Document read ( ) throws ConfigurationError { LOCK . readLock ( ) . lock ( ) ; try { try { if ( cache == null ) { cache = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) . parse ( configuration ) ; } return cache ; } catch ( ParserConfigurationException | SAXException | IOException ex ) { LOG . error ( UNPARSABLE_ERROR_MESSAGE , ex ) ; throw new ConfigurationError ( UNPARSABLE_ERROR_MESSAGE , ex ) ; } } finally { LOCK . readLock ( ) . unlock ( ) ; } }
private void runCurrent ( ) throws OwsExceptionReport { LOGGER . trace ( "Starting update {}" , this . current ) ; this . current . execute ( ) ; LOGGER . trace ( "Finished update {}" , this . current ) ; lock ( ) ; try { persistenceStrategy . persistOnCompleteUpdate ( getCache ( ) ) ; CompleteUpdate u = this . current ; this . current = null ; u . signalWaiting ( ) ; } finally { unlock ( ) ; } }
private void runCurrent ( ) throws OwsExceptionReport { LOGGER . trace ( "Starting update {}" , this . current ) ; this . current . execute ( ) ; LOGGER . trace ( "Finished update {}" , this . current ) ; lock ( ) ; try { persistenceStrategy . persistOnCompleteUpdate ( getCache ( ) ) ; CompleteUpdate u = this . current ; this . current = null ; u . signalWaiting ( ) ; } finally { unlock ( ) ; } }
@ Override public void run ( ) { Map < String , Object > data = new HashMap < > ( ) ; try { eventsResolvers . stream ( ) . forEach ( l -> data . putAll ( l . resolve ( ) ) ) ; dataHandler . persist ( data ) ; } catch ( Throwable e ) { logger . error ( "Cannot persist event" , e ) ; } }
private void initEmbeddedMode ( ) { embeddedServer = new EmbeddedElasticsearch ( ) ; embeddedServer . setHomePath ( context . getRealPath ( "/WEB-INF" ) . concat ( "/config" ) . concat ( "/elasticsearch" ) ) ; embeddedServer . init ( ) ; setClient ( embeddedServer . getClient ( ) ) ; logger . info ( "ElasticSearch data handler starting in EMBEDDED mode" ) ; }
@ Override public void destroy ( ) { try { if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { logger . info ( "Closing ElasticSearch client" ) ; getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { logger . info ( "Closing ElasticSearch node" ) ; node . close ( ) ; } } } catch ( ElasticsearchException | IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ Override public void destroy ( ) { try { if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { logger . info ( "Closing ElasticSearch client" ) ; getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { logger . info ( "Closing ElasticSearch node" ) ; node . close ( ) ; } } } catch ( ElasticsearchException | IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ Override public void destroy ( ) { try { if ( embeddedServer != null ) { embeddedServer . destroy ( ) ; } if ( getClient ( ) != null ) { logger . info ( "Closing ElasticSearch client" ) ; getClient ( ) . close ( ) ; } if ( node != null ) { if ( ! node . isClosed ( ) ) { logger . info ( "Closing ElasticSearch node" ) ; node . close ( ) ; } } } catch ( ElasticsearchException | IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
private void logConnectionError ( String i , UnknownHostException e ) { logger . error ( "Could not create address for given host and port: {}" , i , e ) ; }
@ Override public void unregister ( OwsCode id ) throws ProcessNotFoundException , UndeletableProcessException { LOG . debug ( "unregistering {}" , id ) ; checkProcessExists ( id ) ; getRepository ( id ) . unregister ( id ) ; }
@ Override public void interrupt ( ) throws UnableToInterruptJobException { LOGGER . info ( "Marked job to interrupt." ) ; }
@ FindbugsSuppressWarnings ( "OBL_UNSATISFIED_OBLIGATION" ) private PreRenderingConfig readJobConfig ( String file ) { try ( InputStream taskConfig = getClass ( ) . getResourceAsStream ( file ) ) { ObjectMapper om = new ObjectMapper ( ) ; return om . readValue ( taskConfig , PreRenderingConfig . class ) ; } catch ( IOException e ) { LOGGER . error ( "Could not load {}. Using empty config." , file , e ) ; return new PreRenderingConfig ( ) ; } }
private DataCollection < Data < QuantityValue > > getTimeseriesData ( IoParameters parameters ) { Stopwatch stopwatch = Stopwatch . startStopwatch ( ) ; DataCollection < Data < QuantityValue > > timeseriesData = parameters . isGeneralize ( ) ? new GeneralizingQuantityService ( timeseriesDataService ) . getData ( parameters ) : timeseriesDataService . getData ( parameters ) ; LOGGER . debug ( "Processing request took {} seconds." , stopwatch . stopInSeconds ( ) ) ; return timeseriesData ; }
private Object encodeGeometry ( GeoJSONFeature value ) { try { final GeoJSONEncoder enc = new GeoJSONEncoder ( ) ; final Geometry geometry = value . getGeometry ( ) ; return enc . encodeGeometry ( geometry ) ; } catch ( GeoJSONException e ) { LOGGER . error ( "could not properly encode geometry." , e ) ; return null ; } }
public static JsonNode getJsonNodeFrom ( Object object ) { if ( object == null ) { return null ; } try { return OBJECT_MAPPER . readTree ( OBJECT_MAPPER . writeValueAsString ( object ) ) ; } catch ( IOException e ) { LOGGER . error ( "Could not parse parameter" , e ) ; return null ; } }
@ Override public void updateBounds ( ) { Logger . getLogger ( EmulGLDrawableImage . class ) . warn ( "not implemented" ) ; }
@ Override public void mount ( IPainter painter ) { try { loader . load ( painter , this ) ; hasMountedOnce = true ; } catch ( Exception e ) { e . printStackTrace ( ) ; Logger . getLogger ( DrawableVBO . class ) . error ( e , e ) ; } }
@ Override public Coord2d getPixelScale ( ) { Logger . getLogger ( OffscreenCanvas . class ) . info ( "getPixelScale() not implemented. Will return {1,1}" ) ; return new Coord2d ( 1 , 1 ) ; }
protected void log ( IEventLog event ) { logger . info ( "replay: " + event ) ; }
public static boolean sendToServer ( String message ) { logger . debug ( "sendToServer( " + message + " )" ) ; try { out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside  sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside  sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public static boolean sendToServer ( String message ) { logger . debug ( "sendToServer( " + message + " )" ) ; try { out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside  sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside  sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public static boolean sendToServer ( String message ) { logger . debug ( "sendToServer( " + message + " )" ) ; try { out . writeUTF ( message + "END" ) ; } catch ( SocketException se ) { logger . debug ( "Inside  sendToServer( " + message + " )" , se ) ; return false ; } catch ( IOException ioe ) { logger . debug ( "Inside  sendToServer( " + message + " )" , ioe ) ; return false ; } return true ; }
public void setStoragePath ( String storagePath ) { this . storagePath = storagePath ; this . rootLocation = Paths . get ( storagePath ) ; try { Files . createDirectories ( rootLocation ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ Override public Resource loadAsResource ( String keyName ) { try { URL url = new URL ( getBaseUrl ( ) + keyName ) ; Resource resource = new UrlResource ( url ) ; if ( resource . exists ( ) || resource . isReadable ( ) ) { return resource ; } } catch ( MalformedURLException e ) { logger . error ( e . getMessage ( ) , e ) ; } return null ; }
public static Boolean parseBoolean ( String body , String field ) { ObjectMapper mapper = new ObjectMapper ( ) ; JsonNode node ; try { node = mapper . readTree ( body ) ; JsonNode leaf = node . get ( field ) ; if ( leaf != null ) return leaf . asBoolean ( ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return null ; }
@ Override protected int executeCommand ( ) throws CommandException { try { RestoreManager mgr = new RestoreManager ( request ) ; logger . info ( mgr . restore ( ) ) ; } catch ( BackupWarningException bwe ) { logger . info ( bwe . getMessage ( ) ) ; } catch ( BackupException be ) { throw new CommandException ( be ) ; } return 0 ; }
@ Override protected int executeCommand ( ) throws CommandException { try { RestoreManager mgr = new RestoreManager ( request ) ; logger . info ( mgr . restore ( ) ) ; } catch ( BackupWarningException bwe ) { logger . info ( bwe . getMessage ( ) ) ; } catch ( BackupException be ) { throw new CommandException ( be ) ; } return 0 ; }
@ Test public void testOverrideForDefaultEntries ( ) { logger . info ( "BEGIN overrideGetDefaultEntries TEST" ) ; AuthConfigFactory f = new _ExtendsBaseAuthConfigFactory ( ) ; f = new _Extends_ExtendsAuthConfigFactory ( ) ; }
private void checkDisposed ( ) { String instanceRoot = System . getProperty ( "com.sun.aas.instanceRoot" ) ; logger . info ( "Checking whether " + instanceRoot + " is disposed or not" ) ; if ( new File ( instanceRoot ) . exists ( ) ) { throw new RuntimeException ( "Directory " + instanceRoot + " is not cleaned up after glassfish.dispose()" ) ; } }
private void init ( AdminCommandContext context ) throws IOException { logger = context . getLogger ( ) ; props = Globals . get ( StartupContext . class ) . getArguments ( ) ; verbose = Boolean . parseBoolean ( props . getProperty ( "-verbose" , "false" ) ) ; logger . info ( strings . get ( "restart.server.init" ) ) ; }
@ Override public void onThrowable ( Throwable t ) { if ( decoratedAsyncHandler != null ) { decoratedAsyncHandler . onThrowable ( t ) ; } else { logger . debug ( "" , t ) ; } }
public STATE onBodyPartReceived ( HttpResponseBodyPart e ) throws Exception { byte [ ] bytes = e . getBodyPartBytes ( ) ; if ( bytes . length != 0 ) { String s = new String ( bytes ) ; log . info ( "got part: {}" , s ) ; log . warn ( "Sampling stacktrace." , new Throwable ( "trace that, we should not get called for empty body." ) ) ; queue . put ( s ) ; } return STATE . CONTINUE ; }
public STATE onBodyPartReceived ( HttpResponseBodyPart e ) throws Exception { byte [ ] bytes = e . getBodyPartBytes ( ) ; if ( bytes . length != 0 ) { String s = new String ( bytes ) ; log . info ( "got part: {}" , s ) ; log . warn ( "Sampling stacktrace." , new Throwable ( "trace that, we should not get called for empty body." ) ) ; queue . put ( s ) ; } return STATE . CONTINUE ; }
public void onThrowable ( Throwable t ) { t . printStackTrace ( ) ; log . debug ( t . getMessage ( ) , t ) ; }
@ Deprecated public TrainableStorableClassifier getDefaultClassifier ( ) throws ClassifierException { logger . info ( "getDefaultClassifier()" ) ; return getByPoolLinearClassifier ( ) ; }
public static void printSamplesAsSvmLightInput ( List < LabeledSample > samples , Logger logger ) { logger . info ( printSamplesAsSvmLightInput ( samples , true ) . toString ( ) ) ; }
public T getClassifier ( Vector < LabeledSample > samples ) throws ClassifierException { T ret = null ; synchronized ( this ) { if ( pool . containsKey ( samples ) ) { logger . info ( "Classifier exists in pool" ) ; ret = pool . get ( samples ) ; } } if ( null == ret ) { logger . info ( "Creating a new classifier, since it does not exist in pool" ) ; ret = createClassifier ( ) ; ret . train ( samples ) ; synchronized ( this ) { pool . put ( samples , ret ) ; } } return ret ; }
public T getClassifier ( Vector < LabeledSample > samples ) throws ClassifierException { T ret = null ; synchronized ( this ) { if ( pool . containsKey ( samples ) ) { logger . info ( "Classifier exists in pool" ) ; ret = pool . get ( samples ) ; } } if ( null == ret ) { logger . info ( "Creating a new classifier, since it does not exist in pool" ) ; ret = createClassifier ( ) ; ret . train ( samples ) ; synchronized ( this ) { pool . put ( samples , ret ) ; } } return ret ; }
public void setDoNotScale ( Set < Integer > doNotScale ) { this . doNotScale = doNotScale ; StringBuilder sb = new StringBuilder ( ) ; sb . append ( "Will not scale features: " ) ; boolean firstIteration = true ; for ( Integer i : this . doNotScale ) { if ( firstIteration ) firstIteration = false ; else sb . append ( ", " ) ; sb . append ( i ) ; } logger . info ( sb . toString ( ) ) ; }
protected Vector < LabeledSample > samplesForPredictions ( Vector < LabeledSample > samples , List < Vector < LabeledSample > > olderSamples ) { logger . warn ( "DOES NOT USE SAMPLES FROM EARLIER ITERATIONS. THIS SHOULD BE CHANGED." ) ; return super . samplesForPredictions ( samples , olderSamples ) ; }
@ Override public AdaptedVersion marshal ( Version v ) throws Exception { logger . debug ( "VersionAdapter marshal" ) ; return new AdaptedVersion ( v . getProduct ( ) , v . getMajor ( ) , v . getMinor ( ) , v . getBuildType ( ) ) ; }
private void initializeTestDir ( CommonConfig config ) throws ConfigurationException { NameValueTable EDA = null ; try { EDA = config . getSection ( this . getClass ( ) . getName ( ) ) ; } catch ( ConfigurationException e ) { throw new ConfigurationException ( e . getMessage ( ) + " No EDA section." ) ; } this . testDIR = EDA . getString ( "testDir" ) ; if ( null == testDIR ) { logger . warn ( "Warning: Please specify the testing data directory." ) ; } }
private void loadChunkerModel ( String chunkerModelPath ) { InputStream modelIn = null ; ChunkerModel model = null ; try { modelIn = new FileInputStream ( chunkerModelPath ) ; model = new ChunkerModel ( modelIn ) ; } catch ( IOException e ) { logger . warn ( "Could not load Chunker model" ) ; } finally { if ( modelIn != null ) { try { modelIn . close ( ) ; } catch ( IOException e ) { } } } this . chunker = new opennlp . tools . chunker . ChunkerME ( model ) ; }
private void intializeIgnorePosSet ( CommonConfig config , String sectionName ) throws ConfigurationException { NameValueTable comp = config . getSection ( sectionName ) ; this . ignorePosSet = new HashSet < String > ( ) ; try { for ( String str : ( Files . readAllLines ( Paths . get ( comp . getString ( "ignorePosPath" ) ) , Charset . forName ( "UTF-8" ) ) ) ) this . ignorePosSet . add ( str ) ; } catch ( IOException e1 ) { logger . error ( "Could not read POS tags file" ) ; } }
protected IExtractor getRedirectExtractor ( ) { IExtractor extractor = null ; try { Lemmatizer lemmatizer = new TextProLemmatizer ( processingToolsConf ) ; extractor = new RedirectExtractor ( lemmatizer ) ; } catch ( LemmatizerException e ) { m_logger . error ( "error initializing  RedirectExtractor. " + e . getMessage ( ) ) ; } return extractor ; }
public void terminate ( ) { try { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Terminating rule base: " + this . ruleBaseName ) ; } this . mapTemplateToId = null ; this . mapAllRules = null ; if ( this . connection != null ) this . connection . close ( ) ; } catch ( SQLException e ) { logger . warn ( "Connection could not be closed for rule base: " + this . ruleBaseName ) ; } }
public void terminate ( ) { try { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Terminating rule base: " + this . ruleBaseName ) ; } this . mapTemplateToId = null ; this . mapAllRules = null ; if ( this . connection != null ) this . connection . close ( ) ; } catch ( SQLException e ) { logger . warn ( "Connection could not be closed for rule base: " + this . ruleBaseName ) ; } }
public void cleanUp ( ) { try { connection . close ( ) ; } catch ( SQLException e ) { logger . error ( "Cannot close connection of GEO rule base. Program will continue." , e ) ; } }
public JCas runLAP ( String text , String hypothesis ) { JCas aJCas = null ; try { aJCas = lap . generateSingleTHPairCAS ( text , hypothesis ) ; PlatformCASProber . probeCasAndPrintContent ( aJCas , System . out ) ; } catch ( LAPException e ) { logger . error ( "Error running the LAP" ) ; e . printStackTrace ( ) ; } return aJCas ; }
@ Override public List < DifferBotMapping > readAllDifferBotMappings ( ) { try { return differBotMappingStore . readAllDifferBotMappings ( ) ; } catch ( IResourceStore . ResourceStoreException e ) { log . error ( e . getLocalizedMessage ( ) , e ) ; throw new InternalServerErrorException ( ) ; } }
@ Override public void deleteBotUserIdFromDifferBotMappings ( String userId ) { try { differBotMappingStore . deleteBotUserIdFromDifferBotMappings ( userId ) ; availableBotUserIds . remove ( userId ) ; } catch ( IResourceStore . ResourceStoreException e ) { log . error ( e . getLocalizedMessage ( ) , e ) ; throw new InternalServerErrorException ( ) ; } }
private void initRestClient ( IRestInterfaceFactory restInterfaceFactory ) { try { restBehaviorStore = restInterfaceFactory . get ( IRestBehaviorStore . class ) ; } catch ( RestInterfaceFactory . RestInterfaceFactoryException e ) { restBehaviorStore = null ; log . error ( e . getLocalizedMessage ( ) , e ) ; } }
public static void put ( Object key , Object value ) { if ( key == null ) { throw new IllegalArgumentException ( "key cannot be null" ) ; } if ( value == null ) { remove ( key ) ; return ; } resources . get ( ) . put ( key , value ) ; if ( log . isTraceEnabled ( ) ) { String msg = "Bound value of type [" + value . getClass ( ) . getName ( ) + "] for key [" + key + "] to thread " + "[" + Thread . currentThread ( ) . getName ( ) + "]" ; log . trace ( msg ) ; } }
@ Override public void logVersion ( ) { log . info ( projectName + " v" + getVersion ( ) ) ; }
@ Override public < T > ScheduledFuture < T > submitScheduledCallable ( final Callable < T > callable , long delay , TimeUnit timeUnit , final Map < Object , Object > threadBindings ) { return executorService . schedule ( ( ) -> { try { if ( threadBindings != null ) { ThreadContext . setResources ( threadBindings ) ; } return callable . call ( ) ; } catch ( Throwable t ) { log . error ( t . getLocalizedMessage ( ) , t ) ; return null ; } finally { ThreadContext . remove ( ) ; } } , delay , timeUnit ) ; }
@ Override public void run ( ) { executorService . shutdown ( ) ; try { if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { executorService . shutdownNow ( ) ; if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { log . error ( "Pool did not terminate" ) ; } } } catch ( InterruptedException e ) { executorService . shutdownNow ( ) ; Thread . currentThread ( ) . interrupt ( ) ; log . error ( e . getLocalizedMessage ( ) , e ) ; } }
@ Override public void run ( ) { executorService . shutdown ( ) ; try { if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { executorService . shutdownNow ( ) ; if ( ! executorService . awaitTermination ( 60 , TimeUnit . SECONDS ) ) { log . error ( "Pool did not terminate" ) ; } } } catch ( InterruptedException e ) { executorService . shutdownNow ( ) ; Thread . currentThread ( ) . interrupt ( ) ; log . error ( e . getLocalizedMessage ( ) , e ) ; } }
@ Override public void loginFailed ( final Throwable reason ) { logger . error ( "Login failed: " , reason ) ; }
public RootElementDifference findDifference ( final RootElement expected , final RootElement actual ) { final long startTime = System . currentTimeMillis ( ) ; final ElementDifference elementDifference = elementDifferenceFinder . differenceFor ( expected , actual ) ; logger . debug ( "Finding differences for window took {}ms." , System . currentTimeMillis ( ) - startTime ) ; return elementDifference != null ? new RootElementDifference ( elementDifference , expected , actual ) : null ; }
static void rollback ( Connection connection ) { if ( connection != null ) try { connection . rollback ( ) ; log . debug ( "rolled back" ) ; } catch ( SQLException e ) { throw new SQLRuntimeException ( e ) ; } }
public static Git cloneRepo ( String url , File destination ) { try { return Git . cloneRepository ( ) . setURI ( url ) . setDirectory ( destination ) . call ( ) ; } catch ( GitAPIException e ) { log . error ( "Error cloning repository at {}: {}" , url , e ) ; return null ; } }
@ ShellCommand ( "Load MARK rules from given file or directory. Rules must be loaded before starting analysis." ) @ SuppressWarnings ( "squid:S100" ) public void load_rules ( String fileName ) { AnalysisServer server = AnalysisServer . getInstance ( ) ; if ( server == null ) { log . error ( "Server not initialized" ) ; return ; } server . loadMarkRules ( new File ( fileName ) ) ; }
private void parseEntityContent ( List < EntityStatement > stmts , @ NonNull MEntity me ) { if ( stmts == null ) { return ; } for ( EntityStatement c : stmts ) { if ( c instanceof OpDeclaration ) { OpDeclaration op = ( OpDeclaration ) c ; parseOp ( op , me ) ; } else if ( c instanceof VariableDeclaration ) { VariableDeclaration op = ( VariableDeclaration ) c ; parseVar ( op , me ) ; } else { Log . warn ( "Entity not yet implemented: Handling of Mark {}" , c . getClass ( ) . getName ( ) ) ; } } }
protected void stopTcpServer ( ) { LOG . info ( "Stopping TCP server instance" ) ; tcpServer . stop ( ) ; }
protected void processAssetChange ( PersistenceEvent < EnergyOptimisationAsset > persistenceEvent ) { LOG . info ( "Processing optimisation asset change: " + persistenceEvent ) ; stopOptimisation ( persistenceEvent . getEntity ( ) . getId ( ) ) ; if ( persistenceEvent . getCause ( ) != PersistenceEvent . Cause . DELETE ) { if ( ! persistenceEvent . getEntity ( ) . isOptimisationDisabled ( ) . orElse ( false ) ) { startOptimisation ( persistenceEvent . getEntity ( ) ) ; } } }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle : " + theObject ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( attributeHandle . toString ( ) ) ; } System . out . println ( ) ; }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle : " + theObject ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( attributeHandle . toString ( ) ) ; } System . out . println ( ) ; }
@ Override public void provideAttributeValueUpdate ( ObjectInstanceHandle theObject , AttributeHandleSet theAttributes , byte [ ] userSuppliedTag ) throws FederateInternalError { LOGGER . info ( "Object handle : " + theObject ) ; LOGGER . info ( "Attributes : " ) ; for ( AttributeHandle attributeHandle : theAttributes ) { LOGGER . info ( attributeHandle . toString ( ) ) ; } System . out . println ( ) ; }
@ Override public void run ( ) { while ( _keepRunning ) { _read ( ) ; try { Thread . sleep ( 100 ) ; } catch ( Exception e ) { log . error ( "Error in StreamReaderThread while sleeping!" ) ; } } }
@ Override public String getErrorPageName ( SlingHttpServletRequest request ) { String servletName = String . valueOf ( getStatusCode ( request ) ) ; servletName = StringUtils . lowerCase ( servletName ) ; log . debug ( "Error page name to (try to) use: {} " , servletName ) ; return servletName ; }
public static void setCurrentItem ( String item ) { ActionManager manager = getCurrentActionManager ( ) ; if ( manager != null ) { manager . setCurrentItem ( item ) ; } else { LOG . error ( "Could not identify current action manager." , new IllegalStateException ( ) ) ; } }
@ Activate public void activate ( FileFetchConfiguration config ) { this . config = config ; log . info ( "Activating FileFetcher with configuration {}" , getConfigurationAsString ( ) ) ; run ( ) ; }
public static void updateUserData ( Session jcrSession ) { if ( jcrSession != null ) { try { jcrSession . getWorkspace ( ) . getObservationManager ( ) . setUserData ( "changedByWorkflowProcess" ) ; } catch ( RepositoryException e ) { LOGGER . error ( "Error in repository operation::" , e ) ; } } else { LOGGER . error ( "JCR session object is null." ) ; } }
public static void updateUserData ( Session jcrSession ) { if ( jcrSession != null ) { try { jcrSession . getWorkspace ( ) . getObservationManager ( ) . setUserData ( "changedByWorkflowProcess" ) ; } catch ( RepositoryException e ) { LOGGER . error ( "Error in repository operation::" , e ) ; } } else { LOGGER . error ( "JCR session object is null." ) ; } }
public FieldComponent generateDefaultChildComponent ( ) { try { return defaultChildComponent . getDeclaredConstructor ( ) . newInstance ( ) ; } catch ( RuntimeException | ReflectiveOperationException ex ) { LOG . error ( "got exception" , ex ) ; return null ; } }
@ Override public boolean isFile ( ) { try { retrieveDetails ( ) ; } catch ( JSchException | SftpException ex ) { LOG . error ( "Cannot access remote system: {}" , ex . getMessage ( ) ) ; } return isFile ; }
private void addMoveAuditEntries ( ActionManager manager ) { manager . deferredWithResolver ( rr -> { moves . forEach ( node -> { node . visit ( childNode -> { LOG . debug ( "adding audit entry for move of {} to {}" , childNode . getSourcePath ( ) , childNode . getDestinationPath ( ) ) ; childNode . addAuditRecordForMove ( rr , auditLog ) ; } ) ; } ) ; } ) ; }
public static void serializeToMap ( Map < String , Object > map , Object sourceObject ) { if ( sourceObject == null ) { return ; } FieldUtils . getAllFieldsList ( sourceObject . getClass ( ) ) . stream ( ) . filter ( IntrospectionUtil :: isSimple ) . forEach ( f -> { try { Object value = FieldUtils . readField ( f , sourceObject , true ) ; if ( value != null ) { map . put ( f . getName ( ) , value ) ; } } catch ( IllegalAccessException ex ) { LOG . error ( "Exception while serializing" , ex ) ; } } ) ; }
@ Override public Transformer createTransformer ( ) { LOG . trace ( "Content Variable Transformer" ) ; return new ContentVariableTransformer ( propertyAggregatorService , propertyConfigService ) ; }
Generator createGenerator ( final SAXParserFactory saxParserFactory ) { try { if ( saxParserFactory == null ) { return new XMLParserGenerator ( ) ; } else { return new XMLParserGenerator ( saxParserFactory ) ; } } catch ( Exception e ) { log . error ( "Unable to create parser" , e ) ; return null ; } }
public int getMaxRequestPerMinute ( ) { int cpuLoad ; try { cpuLoad = getCpuLoad ( ) ; return calculateRequests ( cpuLoad , tc . startThrottlingPercentage , tc . maxRequests ) ; } catch ( JMException e ) { LOG . warn ( "Cannot query mbean %s, do not throttle at all!" , name . toString ( ) , e ) ; return tc . maxRequests ; } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { log . info ( "No bundles specified. Consider specifying bundles or removing this service config" ) ; return ; } log . trace ( "Disabling bundles {}" , disabledBundles ) ; for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Unable to stop bundle {}" , bundle . getSymbolicName ( ) , be ) ; } } } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { log . info ( "No bundles specified. Consider specifying bundles or removing this service config" ) ; return ; } log . trace ( "Disabling bundles {}" , disabledBundles ) ; for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Unable to stop bundle {}" , bundle . getSymbolicName ( ) , be ) ; } } } }
private void disableBundles ( ) { if ( disabledBundles . isEmpty ( ) ) { log . info ( "No bundles specified. Consider specifying bundles or removing this service config" ) ; return ; } log . trace ( "Disabling bundles {}" , disabledBundles ) ; for ( Bundle bundle : bundleContext . getBundles ( ) ) { if ( isOnBundleStopList ( bundle ) ) { try { disableBundle ( bundle ) ; } catch ( BundleException be ) { log . error ( "Unable to stop bundle {}" , bundle . getSymbolicName ( ) , be ) ; } } } }
@ Override public void initialize ( Config config ) throws PersistenceException , RepositoryException { Workspace workspace = config . getWorkspace ( ) ; if ( workspace . isInitialized ( ) ) { log . warn ( "Refusing to re-initialize an already initialized Bulk Workflow Manager." ) ; } else { workspace . getRunner ( ) . initialize ( queryHelper , config ) ; } }
private long getCapacity ( Config config ) { final Queue queue = jobManager . getQueue ( JOB_QUEUE_NAME ) ; if ( queue != null ) { final Statistics statistics = queue . getStatistics ( ) ; return config . getBatchSize ( ) - statistics . getNumberOfJobs ( ) ; } else { log . warn ( "Could not locate Job Queue named [ {} ] - this often happens on first run when no jobs have been added to the queue." , JOB_QUEUE_NAME ) ; return config . getBatchSize ( ) ; } }
@ Override protected void execute ( ) throws Exception { logger . info ( "Executing test script: OnDeployScriptTestExampleFlipFlop" ) ; if ( pass ) { pass = ! pass ; } else { pass = ! pass ; throw new RuntimeException ( "Oops, this script failed" ) ; } }
@ Before public void init ( ) { log . info ( "init" ) ; MockitoAnnotations . initMocks ( this ) ; when ( validResource . getResourceResolver ( ) ) . thenReturn ( resolver ) ; when ( invalidResource . getResourceResolver ( ) ) . thenReturn ( resolver ) ; when ( resolver . adaptTo ( PageManager . class ) ) . thenReturn ( pageManager ) ; when ( pageManager . getContainingPage ( validResource ) ) . thenReturn ( page ) ; when ( page . getPath ( ) ) . thenReturn ( VALID_PATH ) ; }
@ Test public void testReportRunner ( ) throws RepositoryException { log . info ( "testReportRunner" ) ; ReportRunner reportRunner = new ReportRunner ( validRequest , dynamicClassLoaderManager ) ; reportRunner . init ( ) ; assertTrue ( reportRunner . isSuccessful ( ) ) ; assertNull ( reportRunner . getFailureMessage ( ) ) ; assertNotNull ( reportRunner . getReportExecutor ( ) ) ; assertEquals ( exec , reportRunner . getReportExecutor ( ) ) ; log . info ( "Test Succeeded!" ) ; }
@ Test public void testReportRunner ( ) throws RepositoryException { log . info ( "testReportRunner" ) ; ReportRunner reportRunner = new ReportRunner ( validRequest , dynamicClassLoaderManager ) ; reportRunner . init ( ) ; assertTrue ( reportRunner . isSuccessful ( ) ) ; assertNull ( reportRunner . getFailureMessage ( ) ) ; assertNotNull ( reportRunner . getReportExecutor ( ) ) ; assertEquals ( exec , reportRunner . getReportExecutor ( ) ) ; log . info ( "Test Succeeded!" ) ; }
@ Test public void testExporter ( ) throws IllegalAccessException { log . info ( "testExporter" ) ; TagsCellValue val = new TagsCellValue ( ) ; FieldUtils . writeField ( val , "property" , "tags" , true ) ; FieldUtils . writeField ( val , "request" , request , true ) ; assertTrue ( ArrayUtils . isEquals ( new Tag [ ] { tag1 , tag2 } , val . getTags ( ) . toArray ( new Tag [ val . getTags ( ) . size ( ) ] ) ) ) ; log . info ( "Test successful!" ) ; }
@ Test public void testExporter ( ) throws IllegalAccessException { log . info ( "testExporter" ) ; TagsCellValue val = new TagsCellValue ( ) ; FieldUtils . writeField ( val , "property" , "tags" , true ) ; FieldUtils . writeField ( val , "request" , request , true ) ; assertTrue ( ArrayUtils . isEquals ( new Tag [ ] { tag1 , tag2 } , val . getTags ( ) . toArray ( new Tag [ val . getTags ( ) . size ( ) ] ) ) ) ; log . info ( "Test successful!" ) ; }
public void reportWarning ( String errorMessage ) { warnings . add ( errorMessage ) ; logger . warn ( errorMessage ) ; }
private void writeToFile ( File f , String output ) { f . getParentFile ( ) . mkdirs ( ) ; if ( f . exists ( ) ) { logger . warn ( f + " already exists!!" ) ; } try { try ( PrintWriter out = new PrintWriter ( f . getPath ( ) ) ) { out . println ( output ) ; out . close ( ) ; logger . trace ( "wrote " + f ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } }
private void writeToFile ( File f , String output ) { f . getParentFile ( ) . mkdirs ( ) ; if ( f . exists ( ) ) { logger . warn ( f + " already exists!!" ) ; } try { try ( PrintWriter out = new PrintWriter ( f . getPath ( ) ) ) { out . println ( output ) ; out . close ( ) ; logger . trace ( "wrote " + f ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } }
private CandyStore getCandiesStore ( ) { if ( candyStore == null ) { if ( candyStoreFile . exists ( ) ) { try { candyStore = gson . fromJson ( FileUtils . readFileToString ( candyStoreFile ) , CandyStore . class ) ; } catch ( Exception e ) { logger . error ( "cannot read candies index" , e ) ; } } if ( candyStore == null ) { candyStore = new CandyStore ( ) ; } } return candyStore ; }
public static void installGlobalNodePackage ( String nodePackageName , String version ) { logger . debug ( "installing " + nodePackageName + " with npm" ) ; initNode ( ) ; runCommand ( NPM_COMMAND , USER_HOME_DIR , false , null , null , null , "install" , "--prefix" , NPM_DIR . getPath ( ) , version == null ? nodePackageName : nodePackageName + "@" + version ) ; }
public void destroy ( ) { try { if ( objectName != null && mBeanServer != null ) { mBeanServer . unregisterMBean ( objectName ) ; } } catch ( Exception e ) { LOG . warn ( "Exception unregistering mbean: " , e ) ; throw new RuntimeException ( e ) ; } }
protected NotificationListener getNotificationListener ( ) { return ( notification , handback ) -> { LOG . debug ( "Got notification: {} for object {}" , notification , handback ) ; updateCounter . incrementAndGet ( ) ; } ; }
public String get ( String name , String defaultValue ) { String answer = null ; if ( envContext != null ) { try { answer = ( String ) envContext . lookup ( "hawtio/" + name ) ; } catch ( Exception e ) { } } if ( answer == null ) { answer = this . propertyResolver . apply ( name ) ; } if ( answer == null ) { answer = defaultValue ; } LOG . debug ( "Property {} is set to value {}" , name , answer ) ; return answer ; }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Allowlist MBean not available" ) ; return false ; } Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "No new proxy allowlist to update" ) ; return false ; } else { LOG . info ( "Updated proxy allowlist: {}" , allowlist ) ; return true ; } }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Allowlist MBean not available" ) ; return false ; } Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "No new proxy allowlist to update" ) ; return false ; } else { LOG . info ( "Updated proxy allowlist: {}" , allowlist ) ; return true ; } }
public boolean update ( ) { if ( ! mBeanServer . isRegistered ( fabricMBean ) ) { LOG . debug ( "Allowlist MBean not available" ) ; return false ; } Set < String > newAllowlist = invokeMBean ( ) ; int previousSize = allowlist . size ( ) ; allowlist . addAll ( newAllowlist ) ; if ( allowlist . size ( ) == previousSize ) { LOG . debug ( "No new proxy allowlist to update" ) ; return false ; } else { LOG . info ( "Updated proxy allowlist: {}" , allowlist ) ; return true ; } }
@ Override public boolean isAttributeWriteAllowed ( ObjectName objectName , String attribute ) { boolean allowed = delegate . isAttributeWriteAllowed ( objectName , attribute ) ; if ( allowed ) { allowed = mBeanInvoker . isWriteAllowed ( objectName , attribute ) ; } LOG . debug ( "isAttributeWriteAllowed(objectName = {}, attribute = {}) = {}" , objectName , attribute , allowed ) ; return allowed ; }
public static void clear ( HttpServletRequest request , AuthenticationConfiguration authConfig , boolean authenticatorLogout ) { HttpSession session = request . getSession ( false ) ; if ( ! isAuthenticated ( session ) ) { return ; } Subject subject = ( Subject ) session . getAttribute ( "subject" ) ; LOG . info ( "Logging out existing user: {}" , session . getAttribute ( "user" ) ) ; if ( authenticatorLogout ) { Authenticator . logout ( authConfig , subject ) ; } session . invalidate ( ) ; }
public static void close ( Closeable closeable , String name , Logger log ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { if ( log == null ) { log = LOG ; } if ( name != null ) { log . warn ( "Cannot close: " + name + ". Reason: " + e . getMessage ( ) , e ) ; } else { log . warn ( "Cannot close. Reason: " + e . getMessage ( ) , e ) ; } } } }
public static void close ( Closeable closeable , String name , Logger log ) { if ( closeable != null ) { try { closeable . close ( ) ; } catch ( IOException e ) { if ( log == null ) { log = LOG ; } if ( name != null ) { log . warn ( "Cannot close: " + name + ". Reason: " + e . getMessage ( ) , e ) ; } else { log . warn ( "Cannot close. Reason: " + e . getMessage ( ) , e ) ; } } } }
public void run ( String [ ] args ) throws Exception { parseArguments ( args ) ; LOG . info ( "Running Spring application" ) ; try { run ( ) ; } finally { LOG . info ( "Shutdown complete" ) ; } }
public void run ( String [ ] args ) throws Exception { parseArguments ( args ) ; LOG . info ( "Running Spring application" ) ; try { run ( ) ; } finally { LOG . info ( "Shutdown complete" ) ; } }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > domainUuids = abstractDomainRepository . findAllDomainIdentifiers ( ) ; logger . info ( domainUuids . size ( ) + " domain uuid have been found" ) ; return domainUuids ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > domainUuids = abstractDomainRepository . findAllDomainIdentifiers ( ) ; logger . info ( domainUuids . size ( ) + " domain uuid have been found" ) ; return domainUuids ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { SystemAccount account = getSystemAccount ( ) ; logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > entries = uploadRequestService . findOutdatedRequests ( account ) ; logger . info ( entries . size ( ) + " Upload Request(s) have been found to be closed" ) ; return entries ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { SystemAccount account = getSystemAccount ( ) ; logger . info ( getClass ( ) . toString ( ) + " job starting ..." ) ; List < String > entries = uploadRequestService . findOutdatedRequests ( account ) ; logger . info ( entries . size ( ) + " Upload Request(s) have been found to be closed" ) ; return entries ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "MonthlyThreadBatchImpl job starting." ) ; List < String > threads = threadWeeklyStatBusinessService . findUuidAccountBetweenTwoDates ( getFirstDayOfLastMonth ( ) , getLastDayOfLastMonth ( ) ) ; logger . info ( threads . size ( ) + "thread(s) have been found in ThreadWeeklyStat table." ) ; return threads ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "MonthlyThreadBatchImpl job starting." ) ; List < String > threads = threadWeeklyStatBusinessService . findUuidAccountBetweenTwoDates ( getFirstDayOfLastMonth ( ) , getLastDayOfLastMonth ( ) ) ; logger . info ( threads . size ( ) + "thread(s) have been found in ThreadWeeklyStat table." ) ; return threads ; }
@ Override public List < String > getAll ( BatchRunContext batchRunContext ) { logger . info ( "Starting synchronizing LDAP Groups" ) ; return domainRepository . findAllDomainIdentifiersWithGroupProviders ( ) ; }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public void setHost ( String host ) { logger . warn ( "Reconfiguring Clamav current host ..." ) ; synchronized ( clamdHost ) { try { clamdHost = host ; logger . warn ( "Clamav current host reconfigured to " + clamdHost ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( "Clamav reconfiguration failed ! " ) ; } } }
@ Override public Set < String > getMail ( String pattern ) throws BusinessException { User authUser = checkAuthentication ( Role . ADMIN ) ; Validate . notEmpty ( pattern , "pattern must be set." ) ; List < User > users = userService . autoCompleteUser ( authUser , pattern ) ; logger . debug ( "nb result for completion : " + users . size ( ) ) ; return getMailList ( users , AUTO_COMPLETE_LIMIT ) ; }
@ Override public AnonymousUrlDto find ( String uuid , String password ) { logger . debug ( "getting anonymousurl with uuid : " + uuid ) ; SystemAccount authUser = anonymousUrlService . getAnonymousURLAccount ( ) ; Account actor = null ; AnonymousUrl url = anonymousUrlService . find ( authUser , authUser , uuid , password ) ; for ( AnonymousShareEntry ase : url . getAnonymousShareEntries ( ) ) { actor = ase . getEntryOwner ( ) ; break ; } return new AnonymousUrlDto ( actor , url ) ; }
@ Override public ResetGuestPassword find ( String uuid ) throws BusinessException { Validate . notEmpty ( uuid , "Missing ResetGuestPassword uuid" ) ; logger . debug ( "getting ResetGuestPassword with uuid : " + uuid ) ; SystemAccount authUser = service . getGuestSystemAccount ( ) ; return service . find ( authUser , authUser , uuid ) ; }
private boolean guestFunctionalityStatus ( AbstractDomain domain ) { Functionality guestFunctionality = functionalityService . getGuests ( domain ) ; boolean status = guestFunctionality . getActivationPolicy ( ) . getStatus ( ) ; if ( ! status ) { logger . warn ( "guest functionality is disable." ) ; } return status ; }
@ Override public TopDomain createTopDomain ( Account actor , TopDomain topDomain ) throws BusinessException { if ( ! ( topDomain . getDefaultRole ( ) . equals ( Role . SIMPLE ) || topDomain . getDefaultRole ( ) . equals ( Role . ADMIN ) ) ) { topDomain . setDefaultRole ( Role . SIMPLE ) ; } logger . debug ( "TopDomain creation attempt : " + topDomain . toString ( ) ) ; return ( TopDomain ) createDomain ( actor , topDomain , getUniqueRootDomain ( ) ) ; }
@ Override public boolean apply ( Functionality input ) { if ( input . isDisplayable ( ) ) { return true ; } logger . debug ( "Functionality filtered: " + input . getIdentifier ( ) ) ; return false ; }
@ Override protected String runMyTask ( BatchTaskContext task ) { boolean execute = batchRunner . execute ( task . getBatch ( ) , batchRunContext ) ; if ( ! execute ) { logger . error ( "asyncTask for batches failed : " + task . getBatch ( ) . getBatchClassName ( ) ) ; throw new BusinessException ( BusinessErrorCode . BATCH_INCOMPLETE , "asyncTask for batches failed" ) ; } return batchRunContext . getUuid ( ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; workGroup = threadService . create ( jane , jane , "work_group_name_1" ) ; workGroupFolder = new WorkGroupFolder ( new AccountMto ( jane ) , "folder1" , null , workGroup . getLsUuid ( ) ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; workGroup = threadService . create ( jane , jane , "work_group_name_1" ) ; workGroupFolder = new WorkGroupFolder ( new AccountMto ( jane ) , "folder1" , null , workGroup . getLsUuid ( ) ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ Test public void test3 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userDomainName ( "domain" ) . userName ( "user" ) ; Assertions . assertEquals ( "domain:user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test3 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userDomainName ( "domain" ) . userName ( "user" ) ; Assertions . assertEquals ( "domain:user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test4 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userName ( "user" ) ; Assertions . assertEquals ( "user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test4 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . userName ( "user" ) ; Assertions . assertEquals ( "user" , ib . build ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( ib . toString ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( ib . toString ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void test9 ( ) { logger . debug ( LinShareTestConstants . BEGIN_TEST ) ; IdentityBuilder ib = IdentityBuilder . New ( ) . identity ( "" ) . tenantName ( "" ) . userDomainName ( "domain" ) . userName ( "" ) ; Assertions . assertThrows ( NoSuchElementException . class , ( ) -> { ib . build ( ) ; } ) ; logger . debug ( ib . toString ( ) ) ; logger . debug ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testMissingPrivateKey ( ) throws InvalidKeySpecException , NoSuchAlgorithmException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; RSAPrivateKey key = PemRsaKeyHelper . loadPrivateKey ( pemPrivateKeyPath + "foo" ) ; assertEquals ( null , key ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testMissingPrivateKey ( ) throws InvalidKeySpecException , NoSuchAlgorithmException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; RSAPrivateKey key = PemRsaKeyHelper . loadPrivateKey ( pemPrivateKeyPath + "foo" ) ; assertEquals ( null , key ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; jane = userRepository . findByMail ( LinShareTestConstants . JANE_ACCOUNT ) ; init . init ( ) ; }
@ AfterEach public void tearDown ( ) throws Exception { logger . debug ( "Begin tearDown" ) ; mailingListRepository . delete ( mailingList1 ) ; mailingListRepository . delete ( mailingList2 ) ; accountRepository . delete ( internal ) ; logger . debug ( "End tearDown" ) ; }
@ AfterEach public void tearDown ( ) throws Exception { logger . debug ( "Begin tearDown" ) ; mailingListRepository . delete ( mailingList1 ) ; mailingListRepository . delete ( mailingList2 ) ; accountRepository . delete ( internal ) ; logger . debug ( "End tearDown" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Current policy : " + policy . toString ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Current policy : " + policy . toString ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; policy = new DomainAccessPolicy ( ) ; logger . debug ( "Current policy : " + policy . toString ( ) ) ; domainAccessPolicyRepository . create ( policy ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; domain = abstractDomainRepository . findById ( DOMAIN_IDENTIFIER ) ; internal = new Internal ( FIRST_NAME , LAST_NAME , MAIL , UID ) ; internal . setLocale ( domain . getDefaultTapestryLocale ( ) ) ; internal . setCmisLocale ( domain . getDefaultTapestryLocale ( ) . toString ( ) ) ; internal . setDomain ( domain ) ; accountRepository . create ( internal ) ; logger . debug ( "End setUp" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( "Begin setUp" ) ; domain = abstractDomainRepository . findById ( DOMAIN_IDENTIFIER ) ; internal = new Internal ( FIRST_NAME , LAST_NAME , MAIL , UID ) ; internal . setLocale ( domain . getDefaultTapestryLocale ( ) ) ; internal . setCmisLocale ( domain . getDefaultTapestryLocale ( ) . toString ( ) ) ; internal . setDomain ( domain ) ; accountRepository . create ( internal ) ; logger . debug ( "End setUp" ) ; }
private void printDocs ( User user ) { logger . debug ( "begin : " + user . getLogin ( ) ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . debug ( "doc : " + ( ( DocumentEntry ) doc ) . getDocument ( ) . getUuid ( ) ) ; } } logger . debug ( "end" ) ; }
private void printDocs ( User user ) { logger . debug ( "begin : " + user . getLogin ( ) ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . debug ( "doc : " + ( ( DocumentEntry ) doc ) . getDocument ( ) . getUuid ( ) ) ; } } logger . debug ( "end" ) ; }
private void printDocs ( User user ) { logger . debug ( "begin : " + user . getLogin ( ) ) ; for ( Entry doc : user . getEntries ( ) ) { if ( doc . getEntryType ( ) == EntryType . DOCUMENT ) { logger . debug ( "doc : " + ( ( DocumentEntry ) doc ) . getDocument ( ) . getUuid ( ) ) ; } } logger . debug ( "end" ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; domain = domainRepository . findById ( LinShareTestConstants . TOP_DOMAIN ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; domain = domainRepository . findById ( LinShareTestConstants . TOP_DOMAIN ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ AfterEach public void tearDown ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_TEARDOWN ) ; }
@ Test public void testFind ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; addStubingUuid ( ) ; SharedSpacePermission toFindPermission = service . findByUuid ( authUser , authUser , "31cb4d80-c939-40f1-a79e-4d77392e0e0b" ) ; Assertions . assertNotNull ( toFindPermission , "Permission has not been found." ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void testFind ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; addStubingUuid ( ) ; SharedSpacePermission toFindPermission = service . findByUuid ( authUser , authUser , "31cb4d80-c939-40f1-a79e-4d77392e0e0b" ) ; Assertions . assertNotNull ( toFindPermission , "Permission has not been found." ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void findAllExistingDefaultRoles ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; List < SharedSpaceRole > toFindRoles = service . findAll ( authUser , authUser ) ; Assertions . assertNotNull ( toFindRoles , "Roles has not been not found" ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ Test public void findAllExistingDefaultRoles ( ) throws BusinessException { logger . info ( LinShareTestConstants . BEGIN_TEST ) ; List < SharedSpaceRole > toFindRoles = service . findAll ( authUser , authUser ) ; Assertions . assertNotNull ( toFindRoles , "Roles has not been not found" ) ; logger . info ( LinShareTestConstants . END_TEST ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; root = userRepository . findByMail ( LinShareTestConstants . ROOT_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
@ BeforeEach public void setUp ( ) throws Exception { logger . debug ( LinShareTestConstants . BEGIN_SETUP ) ; root = userRepository . findByMail ( LinShareTestConstants . ROOT_ACCOUNT ) ; logger . debug ( LinShareTestConstants . END_SETUP ) ; }
private ActiveSyncRequest getActiveSyncRequest ( HttpServletRequest request ) { String qs = request . getQueryString ( ) ; if ( qs . contains ( "Cmd=" ) ) { return new SimpleQueryString ( request ) ; } else { InputStream is = null ; try { is = request . getInputStream ( ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return new Base64QueryString ( request , is ) ; } }
private void sendErrorResponse ( Responder responder , ItemOperationsProtocol protocol , ItemOperationsStatus status , Exception exception ) { logger . error ( exception . getMessage ( ) , exception ) ; responder . sendWBXMLResponse ( NAMESPACE , protocol . encodeErrorResponse ( status ) ) ; }
private void logError ( SyncStatus errorStatus , Exception exception ) { if ( errorStatus == SyncStatus . SERVER_ERROR ) { logger . error ( exception . getMessage ( ) , exception ) ; } else { logger . warn ( exception . getMessage ( ) , exception ) ; } }
private void logError ( SyncStatus errorStatus , Exception exception ) { if ( errorStatus == SyncStatus . SERVER_ERROR ) { logger . error ( exception . getMessage ( ) , exception ) ; } else { logger . warn ( exception . getMessage ( ) , exception ) ; } }
@ Override public void cancel ( User user , Device device ) { try { logger . info ( "cancel {} {}" , device , user ) ; IContinuation continuation = continuationTransactionMap . getContinuationForDevice ( user , device ) ; continuationTransactionMap . delete ( user , device ) ; continuation . resume ( ) ; } catch ( ElementNotFoundException e ) { logger . info ( "cancel device {} for user {} not found" , device , user ) ; } }
@ Override public void cancel ( User user , Device device ) { try { logger . info ( "cancel {} {}" , device , user ) ; IContinuation continuation = continuationTransactionMap . getContinuationForDevice ( user , device ) ; continuationTransactionMap . delete ( user , device ) ; continuation . resume ( ) ; } catch ( ElementNotFoundException e ) { logger . info ( "cancel device {} for user {} not found" , device , user ) ; } }
private void logConfiguration ( ) { logger . info ( "LDAP configuration done, url={} basedn={} filter={} (valid conf={})" , url , baseDn , filter , isValidConfiguration ( ) ) ; if ( ! isValidConfiguration ( ) ) { logger . error ( "{} configuration seems not valid, ldap connection will not be activated" , LDAP_CONF_FILE ) ; } }
private void logConfiguration ( ) { logger . info ( "LDAP configuration done, url={} basedn={} filter={} (valid conf={})" , url , baseDn , filter , isValidConfiguration ( ) ) ; if ( ! isValidConfiguration ( ) ) { logger . error ( "{} configuration seems not valid, ldap connection will not be activated" , LDAP_CONF_FILE ) ; } }
@ Test public void updateShouldProduceMeaningfulLogsWhenEmptyCQL ( ) { Version fromVersion = Version . of ( 1 ) ; Version toVersion = Version . of ( 2 ) ; String schema = "" ; expect ( schemaProducer . schema ( fromVersion , toVersion ) ) . andReturn ( schema ) ; logger . info ( "No CQL migration found from version {} to {}" , fromVersion . get ( ) , toVersion . get ( ) ) ; expectLastCall ( ) ; mocks . replay ( ) ; testee . migrate ( fromVersion , toVersion ) ; mocks . verify ( ) ; }
private TextBody appendRepliedTextMailToHtml ( TextBody htmlPart , String repliedEmail ) throws NotQuotableEmailException { try { Reader textAsHtmlReader = textToHtmlReader ( htmlPart . getReader ( ) ) ; return appendRepliedMailToHtml ( textAsHtmlReader , Charset . forName ( htmlPart . getMimeCharset ( ) ) , repliedEmail ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new NotQuotableEmailException ( "Html part isn't quotable" , e ) ; } }
@ Override public SMTPProtocol getSmtpClient ( UserDataRequest udr ) throws SmtpLocatorException { try { String smtpHost = locatorService . getServiceLocation ( "mail/smtp_out" , udr . getUser ( ) . getLoginAtDomain ( ) ) ; logger . info ( "Using " + smtpHost + " as smtp host." ) ; SMTPProtocol proto = new SMTPProtocol ( smtpHost ) ; return proto ; } catch ( OpushLocatorException e ) { throw new SmtpLocatorException ( "Smtp server cannot be discovered" , e ) ; } }
private void setSmtpRcpts ( SMTPProtocol smtp , org . columba . ristretto . message . Address [ ] rcpts ) { for ( org . columba . ristretto . message . Address rcpt : rcpts ) { try { smtp . rcpt ( rcpt ) ; } catch ( SMTPException e ) { logger . error ( "Bad sender address syntax {from:" + rcpt . getMailAddress ( ) + "}" , e ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } } }
private void setSmtpRcpts ( SMTPProtocol smtp , org . columba . ristretto . message . Address [ ] rcpts ) { for ( org . columba . ristretto . message . Address rcpt : rcpts ) { try { smtp . rcpt ( rcpt ) ; } catch ( SMTPException e ) { logger . error ( "Bad sender address syntax {from:" + rcpt . getMailAddress ( ) + "}" , e ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } } }
private void quit ( SMTPProtocol smtp ) throws SMTPException { try { if ( smtp != null ) { smtp . quit ( ) ; } } catch ( IOException e ) { logger . error ( "Error while closing the smtp connection" ) ; } }
@ Override public void lifeCycleStopped ( LifeCycle event ) { logger . info ( "Application stopped" ) ; }
protected void startApplicationContext ( ) { LOGGER . info ( "starting spring application context..." ) ; config . startApplicationContext ( ) ; LOGGER . info ( "spring application context started" ) ; }
protected void startApplicationContext ( ) { LOGGER . info ( "starting spring application context..." ) ; config . startApplicationContext ( ) ; LOGGER . info ( "spring application context started" ) ; }
protected String getResource ( String resource ) { if ( getResourcesMap ( ) . containsKey ( resource ) ) { return getResourcesMap ( ) . get ( resource ) ; } else { log . error ( "NO file found" + resource ) ; throw new NextProtException ( "Resource " + resource + " not found on a total of " + getResourcesMap ( ) . size ( ) + " resources" ) ; } }
public static void main ( String [ ] args ) { try { new PeffServiceValidatorTask ( args ) . run ( ) ; } catch ( Exception e ) { LOGGER . error ( e . getMessage ( ) + ": exiting app" ) ; e . printStackTrace ( ) ; System . exit ( 1 ) ; } }
@ ResponseStatus ( HttpStatus . FORBIDDEN ) @ ExceptionHandler ( NotAuthorizedException . class ) @ ResponseBody public RestErrorResponse handle ( NotAuthorizedException ex ) { LOGGER . info ( "Not authorized" + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . FORBIDDEN ) @ ExceptionHandler ( ConcurrentRequestsException . class ) @ ResponseBody public RestErrorResponse handle ( ConcurrentRequestsException ex ) { LOGGER . error ( "Too many requests!!!!" ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . NOT_FOUND ) @ ExceptionHandler ( DataAccessException . class ) @ ResponseBody public RestErrorResponse handle ( DataAccessException ex ) { LOGGER . warn ( "Data access exception " + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ ResponseStatus ( HttpStatus . UNAUTHORIZED ) @ ExceptionHandler ( AccessDeniedException . class ) @ ResponseBody public RestErrorResponse handle ( AccessDeniedException ex ) { LOGGER . warn ( "An error occurred: " + ex . getLocalizedMessage ( ) ) ; return getResponseError ( ex ) ; }
@ Override public void clearRepository ( ) { LOGGER . info ( "Cleaning export service repository at path: " + REPOSITORY_PATH ) ; File repo = new File ( REPOSITORY_PATH ) ; if ( repo . exists ( ) ) { File [ ] files = repo . listFiles ( ) ; if ( files != null ) { for ( File file : files ) { file . delete ( ) ; } } } }
public void run ( ) { logger . info ( "JVM shutdown hook called" ) ; shutdown ( ) ; }
public void warn ( final Object ... args ) { if ( logger_ . isWarnEnabled ( ) ) { logger_ . warn ( process ( args ) ) ; } }
@ Override public void error ( final Object message ) { LOG . error ( message ) ; }
@ Override public final String getSrcAttribute ( ) { final String src = getSrcAttributeNormalized ( ) ; if ( ATTRIBUTE_NOT_DEFINED == src ) { return src ; } final HtmlPage page = getHtmlPageOrNull ( ) ; if ( page != null ) { try { return page . getFullyQualifiedUrl ( src ) . toExternalForm ( ) ; } catch ( final MalformedURLException e ) { LOG . warn ( e . getMessage ( ) , e ) ; } } return src ; }
@ Override public void onAllChildrenAddedToPage ( final boolean postponed ) { if ( getOwnerDocument ( ) instanceof XmlPage ) { return ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "Object node added: " + asXml ( ) ) ; } final String clsId = getClassIdAttribute ( ) ; if ( ATTRIBUTE_NOT_DEFINED != clsId && getPage ( ) . getWebClient ( ) . isJavaScriptEngineEnabled ( ) ) { ( ( HTMLObjectElement ) getScriptableObject ( ) ) . setClassid ( clsId ) ; } }
@ Override public void warning ( final String message , final URL url , final String html , final int line , final int column , final String key ) { LOG . warn ( format ( message , url , html , line , column ) ) ; }
@ Override public void closePath ( ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "[" + id_ + "] closePath()" ) ; } if ( subPaths_ . isEmpty ( ) ) { return ; } subPaths_ . get ( subPaths_ . size ( ) - 1 ) . closePath ( ) ; }
private void open ( final OpenMode openMode , final String urlTemplateName , final String [ ] parameterValues ) { String startingUrl = pageUrls . getNamedUrl ( urlTemplateName , parameterValues ) ; LOGGER . debug ( "Opening page at url {}" , startingUrl ) ; openPageAtUrl ( startingUrl ) ; checkUrlPatterns ( openMode ) ; initializePage ( ) ; LOGGER . debug ( "Page opened" ) ; }
private void open ( final OpenMode openMode , final String urlTemplateName , final String [ ] parameterValues ) { String startingUrl = pageUrls . getNamedUrl ( urlTemplateName , parameterValues ) ; LOGGER . debug ( "Opening page at url {}" , startingUrl ) ; openPageAtUrl ( startingUrl ) ; checkUrlPatterns ( openMode ) ; initializePage ( ) ; LOGGER . debug ( "Page opened" ) ; }
public void stepStarted ( ExecutedStepDescription description ) { if ( loggingLevelIsAtLeast ( getLoggingLevel ( ) . VERBOSE ) ) { getLogger ( ) . info ( "STARTING STEP " + description . getTitle ( ) ) ; } }
public void stepPending ( String message ) { if ( loggingLevelIsAtLeast ( getLoggingLevel ( ) . VERBOSE ) ) { getLogger ( ) . info ( "PENDING STEP " + "(" + message + ")" ) ; } }
private Object runSkippedMethod ( Object obj , Method method , Object [ ] args , MethodProxy proxy ) { LOGGER . trace ( "Running test step " + getTestNameFrom ( method , args , false ) ) ; Object result = null ; StepEventBus . getEventBus ( ) . temporarilySuspendWebdriverCalls ( ) ; result = runIfNestedMethodsShouldBeRun ( obj , method , args , proxy ) ; StepEventBus . getEventBus ( ) . reenableWebdriverCalls ( ) ; return result ; }
public void testStarted ( String description ) { int currentTestCount = testCount . getNextTest ( ) ; if ( loggingLevelIsAtLeast ( LoggingLevel . NORMAL ) ) { getLogger ( ) . info ( "TEST NUMBER: {}" , currentTestCount ) ; } }
@ Override public void fireTestIgnored ( Description description ) { log . debug ( "Test ignored: " + description ) ; lastIgnored = description ; if ( ! testStartAlreadyFired ) { super . fireTestStarted ( description ) ; } testStartAlreadyFired = false ; retryAwareRunNotifier . fireTestIgnored ( description ) ; }
@ Step public void enter_name_and_age ( String name , String age ) { LOGGER . info ( "Entering name and age " + name + "/" + age ) ; }
protected Schema < ? > getSchemaAdditionalProperties ( Schema schema ) { Schema < ? > inner = getAdditionalProperties ( schema ) ; if ( inner == null ) { LOGGER . error ( "`{}` (map property) does not have a proper inner type defined. Default to type:string" , schema . getName ( ) ) ; inner = new StringSchema ( ) . description ( "TODO default missing map inner type to string" ) ; schema . setAdditionalProperties ( inner ) ; } return inner ; }
public void postProcessFile ( File file , String fileType ) { LOGGER . debug ( "Post processing file {} ({})" , file , fileType ) ; }
@ Override public String toOperationId ( String operationId ) { if ( isReservedWord ( operationId ) ) { String newOperationId = underscore ( "call_" + operationId ) ; LOGGER . warn ( "{} (reserved word) cannot be used as method name. Renamed to {}" , operationId , newOperationId ) ; return newOperationId ; } return underscore ( operationId ) ; }
@ Override public void processOpts ( ) { super . processOpts ( ) ; if ( additionalProperties . containsKey ( MICROCONTROLLER ) ) { controller = additionalProperties . get ( MICROCONTROLLER ) . toString ( ) ; } addControllerToAdditionalProperties ( ) ; LOGGER . info ( "Generator targeting the following microcontroller: {}" , controller ) ; }
@ Override public String toModelName ( String name ) { if ( ! StringUtils . isEmpty ( modelNamePrefix ) ) { name = modelNamePrefix + "_" + name ; } if ( ! StringUtils . isEmpty ( modelNameSuffix ) ) { name = name + "_" + modelNameSuffix ; } name = sanitizeName ( name ) ; if ( isReservedWord ( name ) ) { LOGGER . warn ( name + " (reserved word) cannot be used as model name. Renamed to " + camelize ( "model_" + name ) ) ; name = "model_" + name ; } return camelize ( name ) ; }
@ Override public void processOpts ( ) { super . processOpts ( ) ; if ( additionalProperties . containsKey ( OUTPUT_NAME ) ) { outputFileName = additionalProperties . get ( OUTPUT_NAME ) . toString ( ) ; } LOGGER . info ( "Output file name [outputFileName={}]" , outputFileName ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "HTTP Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "HTTP Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "HTTP Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
private void logRequest ( HttpRequest request , byte [ ] body ) throws UnsupportedEncodingException { log . info ( "URI: " + request . getURI ( ) ) ; log . info ( "HTTP Method: " + request . getMethod ( ) ) ; log . info ( "HTTP Headers: " + headersToString ( request . getHeaders ( ) ) ) ; log . info ( "Request Body: " + new String ( body , StandardCharsets . UTF_8 ) ) ; }
@ Test ( ) @ MethodOwner ( owner = "qpsdemo" ) public void helloWorld ( ) { LOGGER . info ( "Hello World!" ) ; }
private File getTlsConfigDirectoryByPath ( String path ) { File directory = new File ( path ) ; if ( directory != null && directory . exists ( ) ) { LOGGER . info ( "Directory exists: " + directory . getAbsolutePath ( ) ) ; return directory ; } else { throw new RuntimeException ( "Directory doesn't exist: " + directory . getAbsolutePath ( ) ) ; } }
@ Override public void onConfigurationFailure ( ITestResult result ) { LOGGER . debug ( "AbstractTestListener->onConfigurationFailure" ) ; super . onConfigurationFailure ( result ) ; }
@ Override public void onTestFailure ( ITestResult result ) { LOGGER . debug ( "AbstractTestListener->onTestFailure" ) ; failItem ( result , Messager . TEST_FAILED ) ; afterTest ( result ) ; super . onTestFailure ( result ) ; }
@ Override public void onConfigurationFailure ( ITestResult result ) { LOGGER . debug ( "CarinaListener->onConfigurationFailure" ) ; super . onConfigurationFailure ( result ) ; }
@ Test @ TestRailCases ( testCasesId = TEST_ID ) public void testTestRailList ( ) { ITestResult result = Reporter . getCurrentTestResult ( ) ; Set < String > testRailUdids = getTestRailCasesUuid ( result ) ; Assert . assertTrue ( testRailUdids . contains ( EXPECTED_TEST_ID ) , "TestRail should contain id=" + EXPECTED_TEST_ID ) ; Assert . assertEquals ( testRailUdids . size ( ) , 3 ) ; LOGGER . info ( "TestRail list: " + testRailUdids . toString ( ) ) ; }
public static String setTestName ( String name ) { LOGGER . warn ( "Overridden testName: " + name ) ; testName . set ( name ) ; return testName . get ( ) ; }
public static synchronized void start ( IPerformanceOperation operation , String key ) { String operationKey = operation . getKey ( ) + key ; Map < String , Long > testTimer = getTimer ( ) ; if ( testTimer . containsKey ( operationKey ) ) { LOGGER . error ( "Operation already started: " + operationKey ) ; } else { testTimer . put ( operationKey , Calendar . getInstance ( ) . getTimeInMillis ( ) ) ; } }
public static synchronized void removeTempDir ( ) { if ( tempDirectory != null ) { try { FileUtils . deleteDirectory ( tempDirectory ) ; } catch ( IOException e ) { LOGGER . debug ( "Unable to remove artifacts temp directory!" , e ) ; } } }
private static String getUrl ( WebDriver driver , String name ) { String seleniumHost = Configuration . getSeleniumUrl ( ) . replace ( "wd/hub" , "download/" ) ; WebDriver drv = ( driver instanceof EventFiringWebDriver ) ? ( ( EventFiringWebDriver ) driver ) . getWrappedDriver ( ) : driver ; String sessionId = ( ( RemoteWebDriver ) drv ) . getSessionId ( ) . toString ( ) ; String url = seleniumHost + sessionId + "/" + name ; LOGGER . debug ( "url: " + url ) ; return url ; }
public static void setBuild ( String build ) { R . CONFIG . put ( Parameter . APP_VERSION . getKey ( ) , build ) ; if ( ! build . isEmpty ( ) ) { LOGGER . debug ( "build: " + build ) ; CurrentTestRun . setBuild ( build ) ; } }
public static boolean isDaylightTime ( String tz ) { try { return DateTimeZone . forID ( tz ) . toTimeZone ( ) . observesDaylightTime ( ) ; } catch ( Exception e ) { LOGGER . error ( "Error during observing daylight time for: " + tz , e ) ; return false ; } }
@ SuppressWarnings ( "unchecked" ) public < T > T unmarshall ( String string , Class < T > resultClazz ) { try { return ( T ) getUnmarshaller ( resultClazz ) . unmarshal ( new ByteArrayInputStream ( string . getBytes ( ) ) ) ; } catch ( JAXBException e ) { LOGGER . error ( "Error while unmarshalling!" , e ) ; throw new RuntimeException ( e ) ; } }
private static void collectURL ( ResourceURLFilter f , Set < URL > s , URL u ) { if ( f == null || f . accept ( u ) ) { LOGGER . debug ( "adding resource url by filter: " + u ) ; s . add ( u ) ; } }
public static String stringResponse ( Response response ) { String strResponse = null ; try { strResponse = response . asString ( ) ; } catch ( Throwable thr ) { LOGGER . info ( "Error: " + thr . getMessage ( ) ) ; } return strResponse ; }
public WebDriver getDriver ( ) { if ( driver == null ) { long currentThreadId = Thread . currentThread ( ) . getId ( ) ; LOGGER . error ( "There is no any initialized driver for thread: " + currentThreadId ) ; throw new RuntimeException ( "Driver isn't initialized." ) ; } return driver ; }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . debug ( "Command will be performed with the exception ignoring" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( "Webdriver exception has been fired. One more attempt to execute action." , e ) ; LOGGER . info ( supplier . toString ( ) ) ; return supplier . get ( ) ; } }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . debug ( "Command will be performed with the exception ignoring" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( "Webdriver exception has been fired. One more attempt to execute action." , e ) ; LOGGER . info ( supplier . toString ( ) ) ; return supplier . get ( ) ; } }
public < T > T performIgnoreException ( Supplier < T > supplier ) { try { LOGGER . debug ( "Command will be performed with the exception ignoring" ) ; return supplier . get ( ) ; } catch ( WebDriverException e ) { LOGGER . info ( "Webdriver exception has been fired. One more attempt to execute action." , e ) ; LOGGER . info ( supplier . toString ( ) ) ; return supplier . get ( ) ; } }
public static void switchBackAfterPopup ( WebDriver driver ) { try { Set < String > beforeHandles = windows . get ( ( driver ) . hashCode ( ) ) ; String newWindowHandle = beforeHandles . iterator ( ) . next ( ) ; driver . switchTo ( ) . window ( newWindowHandle ) ; } catch ( Exception e ) { LOGGER . warn ( "Switching to bottom window was not performed!" ) ; } }
public WebDriver getDriver ( ) { if ( driver == null ) { LOGGER . error ( "There is no any initialized driver for ExtendedWebElement: " + getNameWithLocator ( ) ) ; throw new RuntimeException ( "Driver isn't initialized. Review stacktrace to analyze why driver is not populated correctly via reflection!" ) ; } return driver ; }
public void disconnectRemote ( ) { if ( ! isAdbEnabled ) return ; if ( isNull ( ) ) return ; LOGGER . debug ( "adb disconnect " + getRemoteURL ( ) ) ; String [ ] cmd = CmdLine . insertCommandsAfter ( executor . getDefaultCmd ( ) , "disconnect" , getRemoteURL ( ) ) ; executor . execute ( cmd ) ; isAdbEnabled = false ; }
public String getApkPackageName ( String apkFile ) { String packageName = "" ; String [ ] cmd = CmdLine . insertCommandsAfter ( "aapt dump badging" . split ( " " ) , apkFile ) ; List < String > output = executor . execute ( cmd ) ; for ( String line : output ) { if ( line . contains ( "versionCode" ) && line . contains ( "versionName" ) ) { LOGGER . debug ( line ) ; String [ ] outputs = line . split ( "'" ) ; packageName = outputs [ 1 ] ; } } return packageName ; }
@ Override protected void onDestroy ( ) { if ( repository instanceof RepositoryImpl ) { logger . info ( "Shutting down JackRabbit repository..." ) ; ( ( RepositoryImpl ) repository ) . shutdown ( ) ; } super . onDestroy ( ) ; }
@ Override public void run ( ) { try { if ( newBlockType == NewBlockType . BEST_CHAIN ) registration . listener . notifyNewBestBlock ( newStoredBlock ) ; } catch ( VerificationException e ) { log . error ( "Block chain listener threw exception: " , e ) ; } }
public static Context getOrCreate ( NetworkParameters params ) { Context context ; try { context = get ( ) ; } catch ( IllegalStateException e ) { log . warn ( "Implicitly creating context. This is a migration step and this message will eventually go away." ) ; context = new Context ( params ) ; return context ; } if ( context . getParams ( ) != params ) throw new IllegalStateException ( "Context does not match implicit network params: " + context . getParams ( ) + " vs " + params ) ; return context ; }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . info ( "Received alert from peer {}: {}" , this , m . getStatusBar ( ) ) ; } else { log . warn ( "Received alert with invalid signature from peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . info ( "Received alert from peer {}: {}" , this , m . getStatusBar ( ) ) ; } else { log . warn ( "Received alert with invalid signature from peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
protected void processAlert ( AlertMessage m ) { try { if ( m . isSignatureValid ( ) ) { log . info ( "Received alert from peer {}: {}" , this , m . getStatusBar ( ) ) ; } else { log . warn ( "Received alert with invalid signature from peer {}: {}" , this , m . getStatusBar ( ) ) ; } } catch ( Throwable t ) { log . error ( "Failed to check signature: bug in platform libraries?" , t ) ; } }
private void exceptionCaught ( Exception e ) { PeerAddress addr = getAddress ( ) ; String s = addr == null ? "?" : addr . toString ( ) ; if ( e instanceof ConnectException || e instanceof IOException ) { log . info ( s + " - " + e . getMessage ( ) ) ; } else { log . warn ( s + " - " , e ) ; Thread . UncaughtExceptionHandler handler = Threading . uncaughtExceptionHandler ; if ( handler != null ) handler . uncaughtException ( Thread . currentThread ( ) , e ) ; } close ( ) ; }
private void exceptionCaught ( Exception e ) { PeerAddress addr = getAddress ( ) ; String s = addr == null ? "?" : addr . toString ( ) ; if ( e instanceof ConnectException || e instanceof IOException ) { log . info ( s + " - " + e . getMessage ( ) ) ; } else { log . warn ( s + " - " , e ) ; Thread . UncaughtExceptionHandler handler = Threading . uncaughtExceptionHandler ; if ( handler != null ) handler . uncaughtException ( Thread . currentThread ( ) , e ) ; } close ( ) ; }
@ Override protected void timeoutOccurred ( ) { log . warn ( "Timeout occurred for " + handler ) ; closeConnection ( ) ; }
@ Override public void settle ( ) throws IllegalStateException { lock . lock ( ) ; try { checkState ( connectionOpen ) ; step = InitStep . WAITING_FOR_CHANNEL_CLOSE ; log . info ( "Sending a CLOSE message to the server and waiting for response indicating successful settlement." ) ; conn . sendToServer ( Protos . TwoWayChannelMessage . newBuilder ( ) . setType ( Protos . TwoWayChannelMessage . MessageType . CLOSE ) . build ( ) ) ; } finally { lock . unlock ( ) ; } }
@ Override public void onSuccess ( Transaction transaction ) { log . info ( "Successfully broadcast multisig contract {}. Channel now open." , transaction . getHashAsString ( ) ) ; try { wallet . receivePending ( contract , null , true ) ; } catch ( VerificationException e ) { throw new RuntimeException ( e ) ; } stateMachine . transition ( State . READY ) ; future . set ( PaymentChannelServerState . this ) ; }
public void addAndActivateHDChain ( DeterministicKeyChain chain ) { log . info ( "Creating and activating a new HD chain: {}" , chain ) ; for ( ListenerRegistration < KeyChainEventListener > registration : basic . getListeners ( ) ) chain . addEventListener ( registration . listener , registration . executor ) ; if ( lookaheadSize >= 0 ) chain . setLookaheadSize ( lookaheadSize ) ; if ( lookaheadThreshold >= 0 ) chain . setLookaheadThreshold ( lookaheadThreshold ) ; chains . add ( chain ) ; }
@ Override public void onFailure ( Throwable throwable ) { log . error ( "Failed to broadcast key rotation tx" , throwable ) ; }
@ Override public void onCoinsReceived ( Wallet wallet , Transaction tx , Coin prevBalance , Coin newBalance ) { log . info ( "onCoinsReceived 1" ) ; throw new RuntimeException ( "barf" ) ; }
protected < T , E extends Throwable > T callWithRuntimeAndChecking ( final PluginCallback < T , E > cb ) throws E { try { checkPluginIsRunning ( ) ; final Ruby runtime = getRuntime ( ) ; return cb . doCall ( runtime ) ; } catch ( final RuntimeException e ) { log . warn ( "RuntimeException in jruby plugin " , e ) ; throw e ; } }
public void check ( final ServletContext servletContext ) { log . info ( "For Kill Bill Commercial Support, visit http://thebillingproject.com or send an email to support@thebillingproject.com" ) ; if ( shouldSkipUpdateCheck ( ) ) { return ; } final Thread t = new Thread ( ) { @ Override public void run ( ) { try { doCheck ( servletContext ) ; } catch ( final IOException e ) { log . debug ( "Unable to perform update check" , e ) ; } } } ; t . setDaemon ( true ) ; t . start ( ) ; }
public void check ( final ServletContext servletContext ) { log . info ( "For Kill Bill Commercial Support, visit http://thebillingproject.com or send an email to support@thebillingproject.com" ) ; if ( shouldSkipUpdateCheck ( ) ) { return ; } final Thread t = new Thread ( ) { @ Override public void run ( ) { try { doCheck ( servletContext ) ; } catch ( final IOException e ) { log . debug ( "Unable to perform update check" , e ) ; } } } ; t . setDaemon ( true ) ; t . start ( ) ; }
@ LifecycleHandlerType ( LifecycleLevel . LOAD_CATALOG ) public synchronized void loadCatalog ( ) throws ServiceException { if ( ! isInitialized ) { try { if ( config . getCatalogURI ( ) != null && ! config . getCatalogURI ( ) . isEmpty ( ) ) { catalogCache . loadDefaultCatalog ( config . getCatalogURI ( ) ) ; log . info ( "Successfully loaded the default catalog {}" , config . getCatalogURI ( ) ) ; } isInitialized = true ; } catch ( final Exception e ) { throw new ServiceException ( e ) ; } } }
@ AllowConcurrentEvents @ Subscribe public void handlePaymentInfoEvent ( final InvoicePaymentInfoInternalEvent event ) { if ( busDispatcherOptimizer . shouldDispatch ( event ) ) { log . debug ( "Received InvoicePaymentInfo event {}" , event ) ; insertBusEventIntoNotificationQueue ( event . getAccountId ( ) , event ) ; } }
public void startTestFramework ( final TestApiListener testListener , final ClockMock clock , final BusService busService , final SubscriptionBaseService subscriptionBaseService ) throws Exception { log . debug ( "STARTING TEST FRAMEWORK" ) ; resetTestListener ( testListener ) ; resetClockToStartOfTest ( clock ) ; startBusAndRegisterListener ( busService , testListener ) ; restartSubscriptionService ( subscriptionBaseService ) ; log . debug ( "STARTED TEST FRAMEWORK" ) ; }
public void startTestFramework ( final TestApiListener testListener , final ClockMock clock , final BusService busService , final SubscriptionBaseService subscriptionBaseService ) throws Exception { log . debug ( "STARTING TEST FRAMEWORK" ) ; resetTestListener ( testListener ) ; resetClockToStartOfTest ( clock ) ; startBusAndRegisterListener ( busService , testListener ) ; restartSubscriptionService ( subscriptionBaseService ) ; log . debug ( "STARTED TEST FRAMEWORK" ) ; }
public void printEvents ( final List < SubscriptionBaseEvent > events ) { for ( final SubscriptionBaseEvent cur : events ) { log . debug ( "Inspect event " + cur ) ; } }
@ Override public void invalidateCache ( final TenantKey key , final Object cookie , final InternalTenantContext tenantContext ) { log . info ( "Invalidate config cache for tenant {} " , tenantContext . getTenantRecordId ( ) ) ; cacheConfig . clearPerTenantConfig ( tenantContext ) ; }
@ Override public Object execute ( ) throws Throwable { logger . debug ( "Entering API call {}, arguments: {}" , invocation . getMethod ( ) , invocation . getArguments ( ) ) ; final Object proceed = invocation . proceed ( ) ; logger . debug ( "Exiting  API call {}, returning: {}" , invocation . getMethod ( ) , proceed ) ; return proceed ; }
@ Override public Object execute ( ) throws Throwable { logger . debug ( "Entering API call {}, arguments: {}" , invocation . getMethod ( ) , invocation . getArguments ( ) ) ; final Object proceed = invocation . proceed ( ) ; logger . debug ( "Exiting  API call {}, returning: {}" , invocation . getMethod ( ) , proceed ) ; return proceed ; }
@ LifecycleHandlerType ( LifecycleLevel . START_SERVICE ) public void start ( ) { try { createBootNodeInfo ( false ) ; } catch ( JsonProcessingException e ) { logger . error ( "Failed to create bootNodeInfo" , e ) ; } }
private boolean isAuthenticated ( final Response oktaRawResponse ) { try { final Map oktaResponse = mapper . readValue ( oktaRawResponse . getResponseBodyAsStream ( ) , Map . class ) ; if ( "SUCCESS" . equals ( oktaResponse . get ( "status" ) ) ) { return true ; } else { log . warn ( "Okta authentication failed: " + oktaResponse ) ; return false ; } } catch ( final IOException e ) { log . warn ( "Unable to read response from Okta" ) ; throw new AuthenticationException ( e ) ; } }
private boolean isAuthenticated ( final Response oktaRawResponse ) { try { final Map oktaResponse = mapper . readValue ( oktaRawResponse . getResponseBodyAsStream ( ) , Map . class ) ; if ( "SUCCESS" . equals ( oktaResponse . get ( "status" ) ) ) { return true ; } else { log . warn ( "Okta authentication failed: " + oktaResponse ) ; return false ; } } catch ( final IOException e ) { log . warn ( "Unable to read response from Okta" ) ; throw new AuthenticationException ( e ) ; } }
@ Subscribe public void handlePaymentEvents ( final PaymentInfoInternalEvent event ) { log . info ( String . format ( "Got PaymentInfo event %s" , event . toString ( ) ) ) ; assertEqualsNicely ( NextEvent . PAYMENT ) ; notifyIfStackEmpty ( ) ; }
@ Override protected void before ( ) throws Throwable { log . info ( "Starting test container " + this ) ; System . setProperty ( "cuba.unitTestMode" , "true" ) ; initAppComponents ( ) ; initAppProperties ( ) ; for ( Map . Entry < String , String > entry : appProperties . entrySet ( ) ) { AppContext . setProperty ( entry . getKey ( ) , entry . getValue ( ) ) ; } initDataSources ( ) ; initPersistenceConfig ( ) ; initAppContext ( ) ; }
@ Override public void debug ( String msg , Throwable throwable ) { logger . debug ( msg , throwable ) ; }
@ Override public void trace ( String msg , Throwable throwable ) { logger . trace ( msg , throwable ) ; }
@ Override public void unlock ( String name , String id ) { LockInfo lockInfo = locks . remove ( new LockKey ( name , id ) ) ; if ( lockInfo != null ) { log . debug ( "Unlocked " + name + "/" + id ) ; clusterManager . send ( new LockInfo ( null , name , id ) ) ; } }
@ Override public boolean primitiveParameters ( boolean b , int i , long l , double d ) { log . debug ( "primitiveParameters: " + b + ", " + i + ", " + l + ", " + d ) ; return b ; }
@ Override public String start ( ) { try { clusterManager . start ( ) ; return "Done" ; } catch ( Throwable e ) { log . error ( "Unable to start the cluster" , e ) ; return ExceptionUtils . getStackTrace ( e ) ; } }
protected void logError ( Entity entity , Exception e ) { log . warn ( "Unable to log entity {}, id={}" , entity , entity . getId ( ) , e ) ; }
@ Override public void remove ( UserSession session ) { UserSessionInfo usi = removeSessionInfo ( session . getId ( ) ) ; if ( usi != null ) { log . debug ( "Removed session: {}" , usi ) ; if ( ! session . isSystem ( ) ) { usi . lastUsedTs = 0 ; clusterManager . send ( usi ) ; } } }
private void loadLayoutSettings ( DesktopThemeImpl theme , Element element ) { try { String margin = element . attributeValue ( "margin-size" ) ; if ( margin != null ) { theme . setMarginSize ( Integer . valueOf ( margin ) ) ; } String spacing = element . attributeValue ( "spacing-size" ) ; if ( spacing != null ) { theme . setSpacingSize ( Integer . valueOf ( spacing ) ) ; } } catch ( NumberFormatException e ) { log . error ( "Invalid integer value at layout settings: " + e . getMessage ( ) ) ; } }
protected void saveFile ( ) { FileUploadingAPI fileUploading = AppBeans . get ( FileUploadingAPI . NAME ) ; try { fileUploading . putFileIntoStorage ( uploadField . getFileId ( ) , fileDs . getItem ( ) ) ; } catch ( FileStorageException e ) { showNotification ( getMessage ( "fileEditor.unableToSaveFile" ) , NotificationType . ERROR ) ; log . error ( "Unable to save file to middleware" , e ) ; } }
protected void fireItemChanged ( E prevItem ) { if ( ! listenersEnabled ) { return ; } ItemChangeEvent < E > itemChangeEvent = new ItemChangeEvent < > ( this , prevItem , getItemOrNull ( ) ) ; log . trace ( "itemChanged: {}" , itemChangeEvent ) ; events . publish ( ItemChangeEvent . class , itemChangeEvent ) ; }
protected void checkInitialized ( ) { if ( ! initialized ) { synchronized ( this ) { if ( ! initialized ) { log . debug ( "Loading theme constants" ) ; init ( ) ; initialized = true ; } } } }
@ Override public void beforeEach ( ExtensionContext extensionContext ) throws Exception { try { before ( ) ; } catch ( Throwable throwable ) { log . error ( "TestContainer extension initialization failed." , throwable ) ; } }
@ Override public void closeTab ( Component target ) { CubaUI ui = ( CubaUI ) tabSheet . getUI ( ) ; if ( ! ui . isAccessibleForUser ( tabSheet ) ) { LoggerFactory . getLogger ( CubaMainTabSheet . class ) . debug ( "Ignore close tab attempt because TabSheet is inaccessible for user" ) ; return ; } tabSheet . closeTab ( target ) ; }
@ Override public void closeOtherTabs ( Component target ) { CubaUI ui = ( CubaUI ) tabSheet . getUI ( ) ; if ( ! ui . isAccessibleForUser ( tabSheet ) ) { LoggerFactory . getLogger ( CubaTabSheet . class ) . debug ( "Ignore close tab attempt because TabSheet is inaccessible for user" ) ; return ; } tabSheet . closeOtherTabs ( target ) ; }
@ Override public String getStyle ( com . vaadin . v7 . ui . Table source , Object itemId , Object propertyId ) { if ( exceptionHandled ) { return null ; } try { return generateCellStyle ( itemId , propertyId ) ; } catch ( Exception e ) { LoggerFactory . getLogger ( WebAbstractTable . class ) . error ( "Uncaught exception in Table StyleProvider" , e ) ; this . exceptionHandled = true ; return null ; } }
@ Override public String getLocalNodeName ( ) { String hostName ; try { hostName = System . getProperty ( RMI_SERVER_HOSTNAME_SYSTEM_PROPERTY , InetAddress . getLocalHost ( ) . getHostName ( ) ) ; } catch ( UnknownHostException e ) { log . warn ( "Unable to get local hostname" , e ) ; hostName = "<unknown-host>" ; } String jmxPort = System . getProperty ( JMX_PORT_SYSTEM_PROPERTY , "<unknown-port>" ) ; return String . format ( "<local> (%s:%s)" , hostName , jmxPort ) ; }
protected void initializeAnonymousSession ( ) { log . debug ( "Loading anonymous session" ) ; try { this . session = getAnonymousSessionFromService ( ) ; log . debug ( "Anonymous session loaded with id {}" , session . getId ( ) ) ; } catch ( LoginException e ) { throw new RuntimeException ( "Unable to obtain anonymous session from middleware" , e ) ; } }
protected void initializeAnonymousSession ( ) { log . debug ( "Loading anonymous session" ) ; try { this . session = getAnonymousSessionFromService ( ) ; log . debug ( "Anonymous session loaded with id {}" , session . getId ( ) ) ; } catch ( LoginException e ) { throw new RuntimeException ( "Unable to obtain anonymous session from middleware" , e ) ; } }
public void replaceState ( String navigationState , UI ui ) { checkNotNullArgument ( navigationState , "Navigation state cannot be null" ) ; if ( headless ( ) ) { log . debug ( "Unable to replace navigation state in headless mode" ) ; return ; } String state = ! navigationState . isEmpty ( ) ? "#" + navigationState : "" ; Page page = ui . getPage ( ) ; if ( ! state . isEmpty ( ) ) { page . replaceState ( state ) ; } else { page . replaceState ( getEmptyFragmentUri ( page ) ) ; } }
public Object getVariable ( String key ) { Object o = variables . get ( key ) ; if ( o == null ) { Logger . error ( new RuntimeException ( "session variable lookup failed for name: " + key ) ) ; } return o ; }
public static final void warn ( Object message ) { logger . warn ( addURLSuffix ( "WARN  " + message ) ) ; }
private ShortcutInfoDTO unSerializeShortcutInfo ( File jsonFile ) { try { return this . objectMapper . readValue ( jsonFile , ShortcutInfoDTO . class ) ; } catch ( IOException e ) { LOGGER . debug ( "JSON file not found" ) ; return new ShortcutInfoDTO . Builder ( ) . build ( ) ; } }
public int update ( String statement , Object ... params ) { Connection conn = connInTrans . get ( ) ; try { if ( conn == null ) { return queryRunner . update ( statement , params ) ; } else { return queryRunner . update ( conn , statement , params ) ; } } catch ( Exception ex ) { logger . error ( "Update failed. statement={}, params={}" , statement , params , ex ) ; throw ExceptionUtils . wrapIfChecked ( ex ) ; } }
public PullProcessVO pullDataset ( Long datasetId ) { String fullUrl = url + "/datasets/{id}/_pull" ; log . info ( "Request url : " + fullUrl ) ; return restTemplate . postForEntity ( fullUrl , null , PullProcessVO . class , datasetId ) . getBody ( ) ; }
public PullProcessVO pullDataSource ( Long datasourceId ) { String fullUrl = url + "/datasources/{id}/_pull" ; log . info ( "Request url : " + fullUrl ) ; return restTemplate . postForEntity ( fullUrl , null , PullProcessVO . class , datasourceId ) . getBody ( ) ; }
public static JsonNode stringToJson ( String jsonStr ) { try { return objectMapper . readTree ( jsonStr ) ; } catch ( JsonProcessingException e ) { logger . error ( "Error occurs when convert jsonStr: {} to JsonNode: " , jsonStr , e ) ; throw ExceptionUtils . wrapIfChecked ( e ) ; } }
private void sendMseEvent ( LoadSchemaResult loadSchemaResult ) { try { MetadataStatisticsEvent mse = new MetadataStatisticsEvent ( MetadataStatisticsEvent . EventType . FIELD , loadSchemaResult . getGid ( ) , loadSchemaResult . getSnapshotId ( ) ) ; httpClientUtil . doPost ( props . getString ( MSE_URL ) , JSONUtils . toJsonString ( mse ) ) ; } catch ( Exception e ) { logger . warn ( "call mse execute api error: " , e ) ; } }
private void uploadJar ( Long operatorId , File file ) { try { clientUtil . uploadOperatorJar ( operatorId , file ) ; logger . info ( "upload operator jar success, operatorId = {}" , operatorId ) ; } catch ( Exception e ) { logger . error ( "upload operator jar failed, operatorId = {}" , operatorId , e ) ; } }
private void uploadJar ( Long operatorId , File file ) { try { clientUtil . uploadOperatorJar ( operatorId , file ) ; logger . info ( "upload operator jar success, operatorId = {}" , operatorId ) ; } catch ( Exception e ) { logger . error ( "upload operator jar failed, operatorId = {}" , operatorId , e ) ; } }
private boolean isAvailable ( ) { String healthCheck = getBaseUrl ( ) + "/health" ; Call call = okHttpClient . newCall ( new Request . Builder ( ) . url ( healthCheck ) . get ( ) . build ( ) ) ; try ( Response response = call . execute ( ) ) { return response . code ( ) == 200 ; } catch ( IOException e ) { logger . warn ( "Resource {} is not available " , getBaseUrl ( ) ) ; return false ; } }
public boolean submit ( TaskAttempt taskAttempt ) { logger . info ( "submit taskAttemptId = {} to executor" , taskAttempt . getId ( ) ) ; podLifeCycleManager . start ( taskAttempt ) ; return true ; }
public boolean register ( Long taskAttemptId , WorkerEventHandler handler ) { logger . debug ( "register pod event handler,taskAttemptId = {}" , taskAttemptId ) ; registerHandlers . put ( taskAttemptId , handler ) ; return true ; }
@ Override public void onClose ( WatcherException e ) { logger . warn ( "Kubernetes client has been closed" , e ) ; }
public void start ( ) { logger . info ( "start process monitor..." ) ; timer . scheduleAtFixedRate ( new PollingProcessStatus ( ) , 10 , POLLING_PERIOD , TimeUnit . MILLISECONDS ) ; localProcessBackend . watch ( new LocalProcessWatcher ( ) ) ; }
@ Override public boolean unRegister ( Long taskAttemptId ) { logger . debug ( "unRegister worker,taskAttemptId = {}" , taskAttemptId ) ; registerHandlers . remove ( taskAttemptId ) ; return true ; }
@ Override public Integer getCapacity ( TaskAttemptQueue taskAttemptQueue ) { ResourceQueue limitResource = taskAttemptQueue . getResourceQueue ( ) ; ResourceQueue usedResource = getUsedResource ( taskAttemptQueue . getName ( ) ) ; logger . debug ( "queue = {},has {} running process ,limit = {}" , taskAttemptQueue . getName ( ) , usedResource . getWorkerNumbers ( ) , limitResource . getWorkerNumbers ( ) ) ; return limitResource . getWorkerNumbers ( ) - usedResource . getWorkerNumbers ( ) ; }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
private void cancel ( ) { if ( finished ) { return ; } logger . info ( "Trying to cancel current operator." ) ; if ( cancelled ) { logger . warn ( "Operator is already cancelled." ) ; return ; } cancelled = true ; if ( operator != null ) { try { logger . info ( "run operator abort..." ) ; operator . abort ( ) ; waitFinished ( ) ; } catch ( Exception e ) { logger . error ( "Unexpected exception occurred during aborting operator." , e ) ; } } }
@ Override protected CascadeFillIn < InstanceFactory , ? > getFillIn ( AbstractMethod method ) { InstanceFactory instanceFactory = ThisMethodInvocationFactory . getInstance ( method ) ; if ( instanceFactory != null ) { return InstanceFactoryFillIn . getInstance ( instanceFactory ) ; } else { Logger . info ( "no instance factory for" , method ) ; return null ; } }
public static void invokeAndCatchProgramClosedException ( Runnable runnable ) { try { runnable . run ( ) ; } catch ( RuntimeException re ) { if ( isProgramClosedException ( re ) ) { Logger . info ( "ProgramClosedException caught." ) ; } else { throw re ; } } }
@ Override public void writeRuntimeConfig ( LaunchServerRuntimeConfig config ) throws IOException { try ( Writer writer = IOHelper . newWriter ( runtimeConfigFile ) ) { if ( Launcher . gsonManager . configGson != null ) { Launcher . gsonManager . configGson . toJson ( config , writer ) ; } else { LogHelper . error ( "Error writing LaunchServer runtime config file. Gson is null" ) ; } } }
public void prepare ( boolean force ) { try { IOHelper . createParentDirs ( config ) ; genWords ( force ) ; genConfig ( force ) ; } catch ( IOException e ) { LogHelper . error ( e ) ; } }
@ Override public void invoke ( String ... args ) { long size = map . size ( ) ; garbageCollection ( ) ; LogHelper . info ( "Cleared %d entity" , size ) ; }
@ Override public void run ( ) { LogHelper . info ( "Starting netty server socket thread" ) ; nettyServer = new LauncherNettyServer ( server ) ; for ( LaunchServerConfig . NettyBindAddress address : server . config . netty . binds ) { nettyServer . bind ( new InetSocketAddress ( address . address , address . port ) ) ; } }
public static void addJVMClassPath ( Path path ) throws IOException { LogHelper . debug ( "Launcher Agent addJVMClassPath" ) ; inst . appendToSystemClassLoaderSearch ( new JarFile ( path . toFile ( ) ) ) ; }
@ Override public void setConfig ( NewLauncherSettings config ) { settings = config ; if ( settings . consoleUnlockKey != null && ! ConsoleManager . isConsoleUnlock ) { if ( ConsoleManager . checkUnlockKey ( settings . consoleUnlockKey ) ) { ConsoleManager . unlock ( ) ; LogHelper . info ( "Console auto unlocked" ) ; } } }
@ Override void onDisconnect ( ) { LogHelper . info ( "WebSocket client disconnect" ) ; if ( onCloseCallback != null ) onCloseCallback . onClose ( 0 , "unsupported param" , ! isClosed ) ; }
public static void addJVMClassPath ( String path ) throws IOException { LogHelper . debug ( "Load %s" , path ) ; inst . appendToSystemClassLoaderSearch ( new JarFile ( path ) ) ; }
public void notifyItemStatusChanged ( UserOrderItem userOrderItem ) { if ( orderItemStatusChangeListeners != null && userOrderItem != null ) { for ( OrderItemStatusChangeListener listener : orderItemStatusChangeListeners ) { try { listener . onStatusChanged ( userOrderItem ) ; } catch ( Exception ex ) { LOG . error ( ex . toString ( ) , ex ) ; } } } }
@ Override public Page < Article > search ( String queryString , int pageNum , int pageSize ) { try { ArticleSearcher searcher = ArticleSearcherFactory . getSearcher ( ) ; Page < Article > page = searcher . search ( queryString , pageNum , pageSize ) ; if ( page != null ) { return page ; } } catch ( Exception ex ) { LogKit . error ( ex . toString ( ) , ex ) ; } return new Page < > ( new ArrayList < > ( ) , pageNum , pageSize , 0 , 0 ) ; }
@ Override public boolean handleEvent ( final Event abstractEvent ) { if ( ! enabled ) return true ; if ( abstractEvent instanceof AttributeTypeChangedEvent ) return handleAttributeTypeChangeEvent ( ( AttributeTypeChangedEvent ) abstractEvent ) ; if ( abstractEvent instanceof AuditEventTrigger ) return handleAuditEventTrigger ( ( AuditEventTrigger ) abstractEvent ) ; log . error ( "Unexpected event type, verify isWanted() method implementation" ) ; return false ; }
private Map < Long , Map < String , Map < String , AttributeExt > > > getAllAttributes ( Predicate < Long > entityTester ) { Stopwatch w = Stopwatch . createStarted ( ) ; Stream < StoredAttribute > all = attributeDAO . getAll ( ) . stream ( ) . filter ( sa -> entityTester . test ( sa . getEntityId ( ) ) ) ; log . debug ( "getAllAttrs {}" , w . toString ( ) ) ; return mapAttributesByEntities ( all ) ; }
public synchronized void undeployJob ( String id ) { log . info ( "Removing job with id " + id ) ; try { scheduler . deleteJob ( new JobKey ( id , BulkProcessingSupport . JOB_GROUP ) ) ; } catch ( SchedulerException e ) { throw new InternalException ( "Can't undeploy a rule with id " + id , e ) ; } }
@ Override public void invoke ( Entity entity ) { log . info ( "Removing entity " + entity ) ; try { idsMan . removeEntity ( new EntityParam ( entity . getId ( ) ) ) ; } catch ( Exception e ) { log . error ( "Removing entity failed" , e ) ; } }
@ Override public void invoke ( Entity entity ) { log . info ( "Removing entity " + entity ) ; try { idsMan . removeEntity ( new EntityParam ( entity . getId ( ) ) ) ; } catch ( Exception e ) { log . error ( "Removing entity failed" , e ) ; } }
private LoadingCache < String , Map < String , Integer > > initCache ( CapacityLimitDB limitDB ) { return CacheBuilder . newBuilder ( ) . expireAfterAccess ( 120 , TimeUnit . SECONDS ) . build ( new CacheLoader < String , Map < String , Integer > > ( ) { public Map < String , Integer > load ( String name ) { log . trace ( "Get fresh values of capacity limits" ) ; return limitDB . getAll ( ) . stream ( ) . collect ( Collectors . toMap ( CapacityLimit :: getName , CapacityLimit :: getValue ) ) ; } } ) ; }
@ Override public void sendVerificationQuietNoTx ( EntityParam entity , Attribute attribute , boolean force ) { try { sendVerification ( entity , attribute , force ) ; } catch ( Exception e ) { log . warn ( "Can not send a confirmation for the verificable attribute being added " + attribute . getName ( ) , e ) ; } }
private boolean checkSendingLimit ( String mobileToConfirm ) { confirmationReqCache . evictExpiredElements ( ) ; Results results = confirmationReqCache . createQuery ( ) . includeValues ( ) . addCriteria ( Query . VALUE . ilike ( mobileToConfirm ) ) . execute ( ) ; if ( results . size ( ) >= requestLimit ) { log . warn ( "Limit of sent confirmation requests to mobile " + mobileToConfirm + " was reached. (Limit=" + requestLimit + "/24H)" ) ; return false ; } return true ; }
@ Override public void deployInternalEndpointFilter ( String contextPath , FilterHolder filter ) throws EngineException { sharedHandler . addFilter ( filter , contextPath + "/*" , EnumSet . of ( DispatcherType . REQUEST ) ) ; log . debug ( "Deployed internal servlet filter" + filter . getClassName ( ) + " at: " + CONTEXT_PATH + contextPath ) ; }
public void clearScheduledRemovalStatus ( long entityId ) throws IllegalIdentityValueException , IllegalTypeException { EntityInformation info = entityDAO . getByKey ( entityId ) ; if ( info . getState ( ) != EntityState . onlyLoginPermitted ) return ; log . info ( "Removing scheduled removal of an account [as the user is being logged] for entity " + entityId ) ; info . setState ( EntityState . valid ) ; info . setRemovalByUserTime ( null ) ; entityDAO . updateByKey ( entityId , info ) ; }
@ Override public Future < NotificationStatus > sendNotification ( String recipientAddress , Message message ) { NotificationStatus retStatus = new NotificationStatus ( ) ; return execService . getService ( ) . submit ( ( ) -> { try { sendSMS ( recipientAddress , message ) ; } catch ( Exception e ) { log . error ( "SMS notification failed" , e ) ; retStatus . setProblem ( e ) ; } } , retStatus ) ; }
private String getClientIP ( HttpServletRequest httpRequest ) throws IOException { try { return ipDiscovery . getClientIP ( httpRequest ) ; } catch ( Exception e ) { log . error ( "Can not establish client IP" , e ) ; throw new IOException ( "Illegal client IP" ) ; } }
private void addRedirectHandler ( UnityServerConfiguration cfg ) throws ConfigurationException { if ( cfg . isSet ( UnityServerConfiguration . DEFAULT_WEB_PATH ) ) { try { deployHandler ( new RedirectHandler ( cfg . getValue ( UnityServerConfiguration . DEFAULT_WEB_PATH ) ) , "sys:redirect" ) ; } catch ( EngineException e ) { log . error ( "Cannot deploy redirect handler " + e . getMessage ( ) , e ) ; } } }
@ Override public Optional < ByteArray > getUserHandleForUsername ( final String username ) { log . debug ( "getUserHandleForUsername({})" , username ) ; return entityHelper . getUserHandleForUsername ( username ) . map ( uh -> new ByteArray ( FidoUserHandle . fromString ( uh ) . getBytes ( ) ) ) ; }
private boolean isPolicyAgreementWaiting ( OAuthAuthzContext oauthCtx ) { try { return ! policyAgreementsMan . filterAgreementToPresent ( new EntityParam ( InvocationContext . getCurrent ( ) . getLoginSession ( ) . getEntityId ( ) ) , CommonIdPProperties . getPolicyAgreementsConfig ( msg , oauthCtx . getConfig ( ) ) . agreements ) . isEmpty ( ) ; } catch ( EngineException e ) { log . error ( "Unable to determine policy agreements to accept" ) ; } return false ; }
@ Path ( "/group/{groupPath}/meta" ) @ GET public String getGroupMeta ( @ PathParam ( "groupPath" ) String group ) throws EngineException , JsonProcessingException { log . debug ( "getGroupMeta query for {}" , group ) ; if ( ! group . startsWith ( "/" ) ) group = "/" + group ; GroupContents contents = groupsMan . getContents ( group , GroupContents . METADATA ) ; return mapper . writeValueAsString ( contents . getGroup ( ) ) ; }
@ Path ( "/group" ) @ PUT public void updateGroup ( String groupJson ) throws EngineException , JsonProcessingException { log . info ( "updateGroup {}" , groupJson ) ; Group parsedGroup = JsonUtil . parse ( groupJson , Group . class ) ; groupsMan . updateGroup ( parsedGroup . getName ( ) , parsedGroup ) ; }
public Response toResponse ( JsonParseException ex ) { log . error ( "JSON parse error during RESTful API invocation" , ex ) ; return Response . status ( Status . BAD_REQUEST ) . entity ( new JsonError ( ex ) . toString ( ) ) . type ( MediaType . APPLICATION_JSON ) . build ( ) ; }
public Response toResponse ( NullPointerException ex ) { log . error ( "NullPointerException error during RESTful API invocation" , ex ) ; return Response . status ( Status . INTERNAL_SERVER_ERROR ) . type ( MediaType . APPLICATION_JSON ) . build ( ) ; }
private String getClientsPersistentIdValidating ( EntityParam entityId , String expected ) { String persistentId = getClientsPersistentId ( entityId ) ; if ( ! persistentId . equals ( expected ) ) { log . warn ( "Client with persistent id " + persistentId + " is trying to manipulate JWT of " + expected ) ; throw new ClientErrorException ( Status . FORBIDDEN ) ; } return persistentId ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request info:n" + request . getMethod ( ) ) ; log . trace ( "Blocked request params:n" + request . getParameterMap ( ) ) ; log . trace ( "Blocked request contents:n" + sb ) ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request info:n" + request . getMethod ( ) ) ; log . trace ( "Blocked request params:n" + request . getParameterMap ( ) ) ; log . trace ( "Blocked request contents:n" + sb ) ; }
private void dumpRequest ( HttpServletRequest request ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; BufferedReader br = new BufferedReader ( request . getReader ( ) ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) sb . append ( line ) ; log . trace ( "Blocked request info:n" + request . getMethod ( ) ) ; log . trace ( "Blocked request params:n" + request . getParameterMap ( ) ) ; log . trace ( "Blocked request contents:n" + sb ) ; }
private synchronized boolean isRefreshNeeded ( ) { long sinceLastRefresh = lastRefresh == null ? Long . MAX_VALUE : lastRefresh . until ( Instant . now ( ) , ChronoUnit . MILLIS ) ; if ( sinceLastRefresh >= refreshInterval ) { lastRefresh = Instant . now ( ) ; return true ; } else { log . trace ( "Metadata for {} is fresh, refresh needed in {}ms" , source . url , refreshInterval - sinceLastRefresh ) ; return false ; } }
private void notifyConsumer ( MetadataConsumer consumer , EntitiesDescriptorDocument metadata ) { try { log . debug ( "Pushing metadata {} to consumer {}" , source . url , consumer . id ) ; consumer . consumer . accept ( metadata , consumer . id ) ; } catch ( Exception e ) { log . error ( "Metadata consumer failed to accept new metadata" , e ) ; } }
private void notifyConsumer ( MetadataConsumer consumer , EntitiesDescriptorDocument metadata ) { try { log . debug ( "Pushing metadata {} to consumer {}" , source . url , consumer . id ) ; consumer . consumer . accept ( metadata , consumer . id ) ; } catch ( Exception e ) { log . error ( "Metadata consumer failed to accept new metadata" , e ) ; } }
@ Override public ZonedDateTime convertFromString ( String stringRepresentation ) { for ( String format : ACCEPTABLE_FORMATS ) { try { return ZonedDateTime . parse ( stringRepresentation , DateTimeFormatter . ofPattern ( format ) ) ; } catch ( Exception e ) { log . trace ( "Can not parse zoned datetime " + stringRepresentation + " using format: " + format , e ) ; } } throw new InternalException ( "Can not parse zoned datetime " + stringRepresentation + " using standard datetime formats" ) ; }
private T deserializeFromJson ( JsonParser input ) throws IOException { ObjectNode read = input . readValueAsTree ( ) ; try { return fromJsonSingle ( read ) ; } catch ( Exception e ) { log . error ( "Loading dump failed at reading JSON element: " + read ) ; throw e ; } }
private void setupTransactionSession ( ProceedingJoinPoint pjp ) throws Exception { TransactionsState < HzTransactionState > transactionsStack = HzTransactionTL . getState ( ) ; if ( transactionsStack . isEmpty ( ) ) { createNewTransaction ( pjp ) ; } else { log . trace ( "Starting a new not separated subtransaction for {}" , pjp . toShortString ( ) ) ; transactionsStack . push ( new HzTransactionState ( transactionsStack . getCurrent ( ) ) ) ; } }
@ Override protected StoredIdentity fromJsonSingle ( ObjectNode src ) { try { return new StoredIdentity ( new Identity ( src ) ) ; } catch ( IllegalArgumentException e ) { if ( log . isDebugEnabled ( ) ) log . debug ( "Skipping identity without comaprable value: likely transient." , e ) ; else log . info ( "Skipping identity without comaprable value: likely transient. " + src ) ; return null ; } }
@ Override protected Token fromJsonSingle ( ObjectNode src ) { try { return Constants . MAPPER . treeToValue ( src , Token . class ) ; } catch ( JsonProcessingException e ) { log . error ( "Failed to deserialize Token object:" , e ) ; } return null ; }
private static boolean updateThemeProperty ( Properties raw , String property , String endpointName ) { String fullName = "unity.endpoint.web." + property ; if ( raw . get ( fullName ) != null && raw . get ( fullName ) . equals ( "sidebarThemeValo" ) ) { raw . put ( fullName , "unityThemeValo" ) ; log . info ( "Settings " + endpointName + " endpoint configuration " + property + " theme to unityThemeValo" ) ; return true ; } return false ; }
private void updateDatabase ( ) { try { initDB . updateContents ( ) ; } catch ( Exception e ) { log . fatal ( "Update of database contents failed. You have to:n1) Restore DB from backupn" + "2) Use the previous version of Unityn" + "3) Report this problem with the exception following this " + "message to the Unity support mailing list" ) ; throw new InternalException ( "Update of the database contents failed" , e ) ; } }
private AttributeExt getAttribute ( String attributeName , String group ) { Collection < AttributeExt > attributes ; try { attributes = attributesMan . getAttributes ( new EntityParam ( entityId ) , group , attributeName ) ; } catch ( EngineException e ) { log . debug ( "Can not resolve attribute " + attributeName + " for entity" , e ) ; return null ; } if ( attributes . isEmpty ( ) ) return null ; return attributes . iterator ( ) . next ( ) ; }
private boolean isRegistrationEnabled ( ) { try { return registrationFormController . isRegistrationEnabled ( ) ; } catch ( EngineException e ) { LOG . error ( "Failed to determine whether registration is enabled or not on " + "authentication screen." , e ) ; return false ; } }
private void handleUnknownUser ( UnknownRemoteUserException e ) { if ( e . getFormForUser ( ) != null || e . getResult ( ) . isEnableAssociation ( ) ) { log . trace ( "Authentication successful, user unknown, " + "showing unknown user dialog" ) ; setAuthenticationAborted ( ) ; authNPanel . showUnknownUserDialog ( e ) ; } else { log . trace ( "Authentication successful, user unknown, " + "no registration form" ) ; handleError ( msg . getMessage ( "AuthenticationUI.unknownRemoteUser" ) , null ) ; } }
private void handleUnknownUser ( UnknownRemoteUserException e ) { if ( e . getFormForUser ( ) != null || e . getResult ( ) . isEnableAssociation ( ) ) { log . trace ( "Authentication successful, user unknown, " + "showing unknown user dialog" ) ; setAuthenticationAborted ( ) ; authNPanel . showUnknownUserDialog ( e ) ; } else { log . trace ( "Authentication successful, user unknown, " + "no registration form" ) ; handleError ( msg . getMessage ( "AuthenticationUI.unknownRemoteUser" ) , null ) ; } }
private void resendCodeViaEmail ( ) throws TooManyAttempts { try { backend . sendCode ( settings . getEmailSecurityCodeMsgTemplate ( ) , false ) ; } catch ( TooManyAttempts e ) { throw e ; } catch ( Exception e ) { log . warn ( "Credential reset notification failed" , e ) ; NotificationPopup . showError ( msg . getMessage ( "error" ) , msg . getMessage ( "CredentialReset.resetNotPossible" ) ) ; onCancel ( ) ; } }
private PolicyDocumentWithRevision getDoc ( String docId ) { try { return policyDocMan . getPolicyDocument ( Long . valueOf ( docId ) ) ; } catch ( Exception e ) { log . error ( "Unknown policy document id" , e ) ; return null ; } }
@ Override public void onAuthnError ( AuthenticationException e , String authenticatorError ) { log . info ( "External authentication failed, aborting: {}, {}" , e . toString ( ) , authenticatorError ) ; enableSharedComponentsAndHideAuthnProgress ( ) ; String genericError = msg . getMessage ( e . getMessage ( ) ) ; String errorToShow = authenticatorError == null ? genericError : authenticatorError ; NotificationPopup . showError ( errorToShow , "" ) ; }
@ Override public void removeListener ( AuthnResultListener listener ) { final String sessionId = VaadinService . getCurrentRequest ( ) . getWrappedSession ( ) . getId ( ) ; LOG . debug ( "Removing AuthnResultListener: " + sessionId ) ; synchronized ( authnListenerList ) { List < AuthnResultListener > list = authnListenerList . get ( sessionId ) ; if ( list != null ) { list . remove ( listener ) ; if ( list . isEmpty ( ) ) authnListenerList . remove ( sessionId ) ; } } }
void addAuthenticator ( AuthenticatorDefinition authenticator ) throws ControllerException { try { authnMan . createAuthenticator ( authenticator . id , authenticator . type , authenticator . configuration , authenticator . localCredentialName ) ; } catch ( Exception e ) { log . error ( "Can not add authenticator" , e ) ; throw new ControllerException ( msg . getMessage ( "AuthenticatorsController.addError" , authenticator . id ) , e ) ; } }
private String getPolicyDocName ( Long id ) { try { return policyDocMan . getPolicyDocument ( id ) . name ; } catch ( Exception e ) { log . warn ( "Can not get policy document name for id " + id ) ; return String . valueOf ( id ) ; } }
public void deleteGroup ( String projectPath , String groupPath ) throws ControllerException { try { delGroupMan . removeGroup ( projectPath , groupPath ) ; } catch ( Exception e ) { log . warn ( "Can not remove group " + groupPath , e ) ; throw new ServerFaultException ( msg ) ; } }
public Optional < String > getProjectSingUpEnquiryFormLink ( String projectPath ) throws ControllerException { try { return requestMan . getProjectSignUpEnquiryFormLink ( projectPath ) ; } catch ( EngineException e ) { log . warn ( "Can not get project signup enquiry form link " + projectPath , e ) ; throw new ServerFaultException ( msg ) ; } }
private void commitQuietly ( ) { if ( connection != null ) { try { connection . commit ( ) ; } catch ( final SQLException e ) { log . warn ( "Error committing" , e ) ; } } connection = null ; }
public TableDefinition refresh ( final Connection connection , final TableId tableId ) throws SQLException { final TableDefinition dbTable = dialect . describeTable ( connection , tableId ) ; log . info ( "Refreshing metadata for table {} to {}" , tableId , dbTable ) ; cache . put ( dbTable . id ( ) , dbTable ) ; return dbTable ; }
@ Override protected void executeInternal ( ) throws Throwable { System . out . println ( "DemoComponent has been executed" ) ; logger . debug ( "Test debug logging. Congratulation your JAR Module is working" ) ; logger . info ( "This is only for information purposes. Better remove me from the log in Production" ) ; }
@ Override protected void executeInternal ( ) throws Throwable { System . out . println ( "DemoComponent has been executed" ) ; logger . debug ( "Test debug logging. Congratulation your JAR Module is working" ) ; logger . info ( "This is only for information purposes. Better remove me from the log in Production" ) ; }
public boolean deactivateCustomModel ( String fileName ) { try { FileModel customModel = getCustomModel ( fileName ) ; if ( customModel != null ) { cmisApi . authenticateUser ( dataUser . getAdminUser ( ) ) . usingResource ( customModel ) . updateProperty ( "cm:modelActive" , false ) ; return true ; } } catch ( Exception e ) { LOGGER . warn ( "Error Deactivating Custom Model" , e ) ; } return false ; }
private void deleteNode ( UpdateRequestProcessor processor , SolrQueryRequest request , Node node ) throws IOException { LOGGER . debug ( "Node {} is being deleted" , node . getId ( ) ) ; deleteErrorNode ( processor , request , node ) ; deleteNode ( processor , request , node . getId ( ) ) ; LOGGER . debug ( "Node {} deletion correctly sent" , node . getId ( ) ) ; }
private void deleteNode ( UpdateRequestProcessor processor , SolrQueryRequest request , Node node ) throws IOException { LOGGER . debug ( "Node {} is being deleted" , node . getId ( ) ) ; deleteErrorNode ( processor , request , node ) ; deleteNode ( processor , request , node . getId ( ) ) ; LOGGER . debug ( "Node {} deletion correctly sent" , node . getId ( ) ) ; }
private void findCores ( File dir , List < File > cores ) { File [ ] files = dir . listFiles ( ) ; if ( files != null ) { for ( File file : files ) { if ( file . isDirectory ( ) ) { findCores ( file , cores ) ; } else { if ( "core.properties" . equals ( file . getName ( ) ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Found core:" + dir . getAbsolutePath ( ) ) ; } cores . add ( dir ) ; } } } } }
protected void indexAcls ( ) throws AuthenticationException , IOException , JSONException { while ( aclsToIndex . peek ( ) != null ) { Long aclId = aclsToIndex . poll ( ) ; if ( aclId != null ) { Acl acl = new Acl ( 0 , aclId ) ; List < AclReaders > readers = client . getAclReaders ( Collections . singletonList ( acl ) ) ; indexAcl ( readers , false ) ; LOGGER . info ( "[CORE {}] - INDEX ACTION - AclId {} has been indexed" , coreName , aclId ) ; } checkShutdown ( ) ; } }
@ Override protected void onFail ( Throwable failCausedBy ) { LOGGER . warn ( "Content tracker failed due to {}" , failCausedBy . getMessage ( ) , failCausedBy ) ; }
private void purgeNodes ( ) throws IOException , JSONException { while ( nodesToPurge . peek ( ) != null ) { Long nodeId = nodesToPurge . poll ( ) ; if ( nodeId != null ) { this . infoSrv . deleteByNodeId ( nodeId ) ; LOGGER . info ( "PURGE ACTION - Purged nodeId {}" , nodeId ) ; } checkShutdown ( ) ; } }
public static void dismissSolrServers ( ) { try { destroyServers ( ) ; distribTearDown ( ) ; boolean keepTests = Boolean . parseBoolean ( System . getProperty ( "keep.tests" ) ) ; if ( ! keepTests ) FileUtils . deleteDirectory ( testDir ) ; } catch ( Exception e ) { LOGGER . error ( "Failed to shutdown test properly " , e ) ; } }
public void compareSolrResponses ( SolrResponse a , SolrResponse b ) { handle . put ( "QTime" , SKIPVAL ) ; String cmp = compare ( a . getResponse ( ) , b . getResponse ( ) , flags , handle ) ; if ( cmp != null ) { LOGGER . error ( "Mismatched responses:n" + a + "n" + b ) ; Assert . fail ( cmp ) ; } }
@ Override @ Behaviour ( kind = BehaviourKind . CLASS ) public void onCreateNode ( ChildAssociationRef childAssocRef ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( "onCreateNode: " + childAssocRef ) ; } validateAndReset ( childAssocRef . getChildRef ( ) ) ; }
@ Override public boolean handleAuditEntryError ( Long entryId , String errorMsg , Throwable error ) { logger . warn ( errorMsg , error ) ; return true ; }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { if ( log != null ) { log . fatal ( arg0 , arg1 ) ; } }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { log . fatal ( arg0 , arg1 ) ; log2 . fatal ( arg0 , arg1 ) ; }
@ Override public void fatal ( Object arg0 , Throwable arg1 ) { log . fatal ( arg0 , arg1 ) ; log2 . fatal ( arg0 , arg1 ) ; }
public static final void debug ( Log logger , String messageKey , Object ... args ) { logger . debug ( I18NUtil . getMessage ( messageKey , args ) ) ; }
public static final void info ( Log logger , String messageKey , Object ... args ) { logger . info ( I18NUtil . getMessage ( messageKey , args ) ) ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( iae ) ; } return o ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( iae ) ; } return o ; }
public static Object newObject ( String className ) { Object o = null ; try { Class clazz = Class . forName ( className ) ; o = clazz . newInstance ( ) ; } catch ( ClassNotFoundException cnfe ) { logger . debug ( cnfe ) ; } catch ( InstantiationException ie ) { logger . debug ( ie ) ; } catch ( IllegalAccessException iae ) { logger . debug ( iae ) ; } return o ; }
public void run ( ) { vmShuttingDown = true ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "VM shutdown detected by listener " + name ) ; } }
@ Override public void run ( ) { if ( allAwake ) return ; logger . debug ( "Adding thread: " + Thread . currentThread ( ) . getName ( ) ) ; sleeping . put ( Thread . currentThread ( ) . getName ( ) , Thread . currentThread ( ) ) ; try { Thread . sleep ( 30 * 1000 ) ; System . err . println ( "Warning - Thread finished sleeping without wake!" ) ; } catch ( InterruptedException e ) { logger . debug ( "Interrupted thread: " + Thread . currentThread ( ) . getName ( ) ) ; } }
@ Override public void run ( ) { if ( allAwake ) return ; logger . debug ( "Adding thread: " + Thread . currentThread ( ) . getName ( ) ) ; sleeping . put ( Thread . currentThread ( ) . getName ( ) , Thread . currentThread ( ) ) ; try { Thread . sleep ( 30 * 1000 ) ; System . err . println ( "Warning - Thread finished sleeping without wake!" ) ; } catch ( InterruptedException e ) { logger . debug ( "Interrupted thread: " + Thread . currentThread ( ) . getName ( ) ) ; } }
public void remove ( final String tenantId ) { liveLock . writeLock ( ) . lock ( ) ; try { DictionaryRegistry dictionaryRegistry = live . get ( tenantId ) ; if ( dictionaryRegistry != null ) { live . remove ( tenantId ) ; dictionaryRegistry . remove ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Removed dictionary register for tenant " + tenantId ) ; } } } finally { liveLock . writeLock ( ) . unlock ( ) ; } }
public static void clearCurrentSecurityContext ( ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( "Removing the current security information for thread: " + Thread . currentThread ( ) . getName ( ) ) ; } ContextHolder . setContext ( null ) ; InMemoryTicketComponentImpl . clearCurrentSecurityContext ( ) ; NDC . remove ( ) ; TenantContextHolder . clearTenantDomain ( ) ; }
protected void redirectToLoginPage ( HttpServletRequest req , HttpServletResponse res ) throws IOException { if ( getLogger ( ) . isTraceEnabled ( ) ) { getLogger ( ) . trace ( "redirectToLoginPage..." ) ; } if ( hasLoginPage ( ) ) res . sendRedirect ( req . getContextPath ( ) + "/faces" + getLoginPage ( ) ) ; }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
protected void getSite ( String siteId , String ticket ) throws Exception { String url = WEBSCRIPT_ENDPOINT + URL_SITES + "/" + siteId ; String response = callGetWebScript ( url , ticket ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getSite:" + siteId ) ; logger . debug ( "-------" ) ; logger . debug ( url ) ; logger . debug ( response ) ; } }
public void contextInitialized ( ServletContextEvent sce ) { try { ServletContext servletContext = sce . getServletContext ( ) ; WebApplicationContextLoader . getApplicationContext ( servletContext , configLocations , classLocations ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "contextInitialized " + sce ) ; } } catch ( Throwable t ) { logger . error ( "Failed to start Jetty server: " + t ) ; throw new AlfrescoRuntimeException ( "Failed to start Jetty server" , t ) ; } }
public void contextInitialized ( ServletContextEvent sce ) { try { ServletContext servletContext = sce . getServletContext ( ) ; WebApplicationContextLoader . getApplicationContext ( servletContext , configLocations , classLocations ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "contextInitialized " + sce ) ; } } catch ( Throwable t ) { logger . error ( "Failed to start Jetty server: " + t ) ; throw new AlfrescoRuntimeException ( "Failed to start Jetty server" , t ) ; } }
public NodeRef getNodeRef ( NodeRef pathRootNodeRef , String path ) throws FileNotFoundException { List < NodeRef > nodeRefs = getNodeRefs ( pathRootNodeRef , path ) ; if ( nodeRefs . size ( ) == 0 ) { throw new FileNotFoundException ( path ) ; } else if ( nodeRefs . size ( ) > 1 ) { logger . warn ( "Multiple matching nodes: n" + "   search root: " + pathRootNodeRef + "n" + "   path: " + path ) ; } NodeRef nodeRef = nodeRefs . get ( 0 ) ; return nodeRef ; }
public long seekFile ( SrvSession sess , TreeConnection tree , NetworkFile file , long pos , int typ ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "seek File" ) ; } if ( file . isDirectory ( ) ) { throw new AccessDeniedException ( ) ; } return file . seekFile ( pos , typ ) ; }
public void deleteEmptyFile ( NodeRef rootNode , String path ) { try { NodeRef target = getCifsHelper ( ) . getNodeRef ( rootNode , path ) ; if ( target != null ) { if ( nodeService . hasAspect ( target , ContentModel . ASPECT_NO_CONTENT ) ) { nodeService . deleteNode ( target ) ; } } } catch ( IOException ne ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Unable to delete empty file:" + path , ne ) ; } } }
public int readFile ( byte [ ] buffer , int length , int position , long fileOffset ) throws IOException { openContent ( false , false ) ; ByteBuffer byteBuffer = ByteBuffer . wrap ( buffer , position , length ) ; int count = channel . read ( byteBuffer , fileOffset ) ; if ( count < 0 ) { count = 0 ; } if ( getFileState ( ) != null ) getFileState ( ) . updateAccessDateTime ( ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( "Read file=" + this + " read=" + count ) ; return count ; }
@ Override public void addLock ( NodeRef nodeRef ) { if ( lockEnabled ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "lock nodeRef:" + nodeRef ) ; } getLockService ( ) . lock ( nodeRef , LockType . WRITE_LOCK , getTimeToExpire ( ) , Lifetime . EPHEMERAL , LOCK_KEEPER_KEY ) ; lockKeeperTransactionalCache . put ( nodeRef , new KeeperInfo ( AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ) ; } }
public void startMonitor ( ) { m_stateTable = m_filesysCtx . getStateCache ( ) ; m_thread = new Thread ( this ) ; m_thread . setName ( "NodeMonitor_" + m_filesysCtx . getDeviceName ( ) ) ; m_thread . setDaemon ( true ) ; m_thread . start ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "NodeMonitor started, " + m_thread . getName ( ) ) ; } }
@ Override public FileInfo getFileInformation ( SrvSession sess , TreeConnection tree , String path ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "getFileInformation:" + path ) ; } FileFilterMode . setClient ( ClientHelper . getClient ( sess ) ) ; try { FileInfo info = diskInterface . getFileInformation ( sess , tree , path ) ; return info ; } finally { FileFilterMode . clearClient ( ) ; } }
public void closeFile ( ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Close OpenOffice file, " + getName ( ) + ", delayed close count=" + getDelayedCloseCount ( ) + ", writes=" + getWriteCount ( ) + ", modified=" + isModified ( ) ) ; logger . debug ( "  Open count=" + getOpenCount ( ) + ", fstate open=" + getFileState ( ) . getOpenCount ( ) ) ; } super . closeFile ( ) ; }
public void closeFile ( ) throws IOException { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Close OpenOffice file, " + getName ( ) + ", delayed close count=" + getDelayedCloseCount ( ) + ", writes=" + getWriteCount ( ) + ", modified=" + isModified ( ) ) ; logger . debug ( "  Open count=" + getOpenCount ( ) + ", fstate open=" + getFileState ( ) . getOpenCount ( ) ) ; } super . closeFile ( ) ; }
private ResultCallback deleteFileCallbackCommand ( ) { return new ResultCallback ( ) { @ Override public void execute ( Object result ) { if ( result instanceof NodeRef ) { logger . debug ( "got node ref of deleted node" ) ; originalNodeRef = ( NodeRef ) result ; } } @ Override public AlfrescoTransactionSupport . TxnReadState getTransactionRequired ( ) { return AlfrescoTransactionSupport . TxnReadState . TXN_NONE ; } } ; }
@ Override protected boolean evaluateImpl ( ActionCondition actionCondition , NodeRef actionedUponNodeRef ) { logger . error ( "Evaluating composite condition.  Should not be called." ) ; return false ; }
protected void removeFromScheduler ( ScheduledPersistedActionImpl schedule ) { if ( schedule . getPersistedAtNodeRef ( ) == null ) return ; try { scheduler . deleteJob ( new JobKey ( schedule . getPersistedAtNodeRef ( ) . toString ( ) , SCHEDULER_GROUP ) ) ; } catch ( SchedulerException e ) { log . warn ( e ) ; } }
@ Override Void doWork ( ) { authenticationService . invalidateUserSession ( username ) ; log . info ( "User invalidated: " + username ) ; return null ; }
public void guessMimetype ( String filename ) { if ( mimetypeService == null ) { logger . warn ( "MimetypeService not supplied, but required for content guessing" ) ; return ; } if ( isClosed ( ) ) { doGuessMimetype ( filename ) ; } else { guessingOnCloseListener . guessMimetype = true ; guessingOnCloseListener . filename = filename ; } }
public boolean delete ( String contentUrl ) throws ContentIOException { boolean deleted = true ; List < ContentStore > stores = getAllStores ( ) ; for ( ContentStore store : stores ) { if ( store . isWriteSupported ( ) ) { deleted &= store . delete ( contentUrl ) ; } } if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Deleted content URL from stores: n" + "   Stores:  " + stores . size ( ) + "n" + "   Deleted: " + deleted ) ; } return deleted ; }
private String acquireLock ( JobLockRefreshCallback lockCallback ) { String lockToken = jobLockService . getLock ( LOCK_QNAME , LOCK_TTL ) ; jobLockService . refreshLock ( lockToken , LOCK_QNAME , LOCK_TTL , lockCallback ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "lock acquired: " + LOCK_QNAME + ": " + lockToken ) ; } return lockToken ; }
private OverwritePolicy removeOverwritePolicy ( Map < String , Serializable > map , String key , OverwritePolicy defaultValue ) { Serializable value = map . remove ( key ) ; if ( value == null ) { return defaultValue ; } try { return OverwritePolicy . valueOf ( ( String ) value ) ; } catch ( IllegalArgumentException | ClassCastException e ) { logger . error ( key + "=" + value + " is invalid" ) ; return null ; } }
@ Override public M2Model getM2Model ( final NodeRef modelNodeRef ) { ContentReader reader = contentService . getReader ( modelNodeRef , ContentModel . PROP_CONTENT ) ; if ( reader == null ) { return null ; } InputStream in = reader . getContentInputStream ( ) ; try { return M2Model . createModel ( in ) ; } finally { if ( in != null ) { try { in . close ( ) ; } catch ( IOException e ) { logger . error ( "Failed to close input stream for " + modelNodeRef ) ; } } } }
public Void execute ( ) throws Throwable { return TenantUtil . runAsSystemTenant ( new TenantRunAsWork < Void > ( ) { public Void doWork ( ) { dictionaryDAO . init ( ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "afterCommit: Dictionary destroyed [" + AlfrescoTransactionSupport . getTransactionId ( ) + "]" ) ; } return null ; } } , tenantName ) ; }
@ Override public Void execute ( ) throws Throwable { try { if ( qnameDAO . getQName ( className ) != null ) { qnameDAO . deleteQName ( className ) ; } throw new ModelNotInUseException ( "Class " + className + " not in use" ) ; } catch ( DataIntegrityViolationException e ) { logger . debug ( e ) ; throw new ModelInUseException ( "Cannot delete model, class " + className + " is in use" ) ; } }
@ Override protected AuditApplicationEntity getAuditApplicationById ( Long id ) { Map < String , Object > params = new HashMap < String , Object > ( 11 ) ; params . put ( "id" , id ) ; AuditApplicationEntity entity = template . selectOne ( SELECT_APPLICATION_BY_ID , params ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Searched for audit application ID " + id + " and found: " + entity ) ; } return entity ; }
@ Override public int deleteByKey ( Long key ) { deletePropertyRoot ( key ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Deleted property: n" + "   ID: " + key ) ; } return 1 ; }
@ Override public void cleanupUnusedValuesV2 ( ) { try { scriptExecutor . exec ( false , "alfresco/dbscripts/utility/${db.script.dialect}" , "CleanAlfPropTablesV2.sql" ) ; } catch ( RuntimeException e ) { logger . error ( "The cleanup script failed: " , e ) ; throw e ; } finally { clearCaches ( ) ; } }
public NodeRef getOrCreateDowloadContainer ( ) { NodeRef downloadsContainer = getContainer ( ) ; if ( downloadsContainer == null ) { if ( log . isInfoEnabled ( ) ) log . info ( "Lazy creating the Downloads System Container " ) ; downloadsContainer = SystemNodeUtils . getOrCreateSystemChildContainer ( getContainerQName ( ) , nodeService , repositoryHelper ) . getFirst ( ) ; } return downloadsContainer ; }
@ Override protected void updateAssociations ( NodeService nodeService ) { List < AssociationRef > existingAssocs = nodeService . getTargetAssocs ( sourceNodeRef , assocQName ) ; for ( AssociationRef assoc : existingAssocs ) { if ( assoc . getTargetRef ( ) . equals ( targetNodeRef ) ) { if ( logger . isWarnEnabled ( ) ) { logger . warn ( "Attempt to add existing association prevented. " + assoc ) ; } return ; } } nodeService . createAssociation ( sourceNodeRef , targetNodeRef , assocQName ) ; }
public void shutdown ( ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( "shutting down." ) ; } scheduler . shutdown ( ) ; }
@ Override public List < FileInfo > listFolders ( NodeRef contextNodeRef ) { List < FileInfo > results = listSimple ( contextNodeRef , false , true ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "List for folders: n" + "   context: " + contextNodeRef + "n" + "   results: " + results ) ; } return results ; }
@ Override public List < FileInfo > listDeepFolders ( NodeRef contextNodeRef , SubFolderFilter filter ) { List < NodeRef > nodeRefs = listSimpleDeep ( contextNodeRef , false , true , filter ) ; List < FileInfo > results = toFileInfo ( nodeRefs ) ; if ( logger . isTraceEnabled ( ) ) { logger . trace ( "Deep search for files: n" + "   context: " + contextNodeRef + "n" + "   results: " + results . size ( ) ) ; } return results ; }
@ Override public void delete ( NodeRef nodeRef ) { nodeService . deleteNode ( nodeRef ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Deleted: n" + "   node: " + nodeRef ) ; } }
public void onRemoveAspect ( NodeRef nodeRef , QName aspectTypeQName ) { if ( ! storesToIgnore . contains ( nodeRef . getStoreRef ( ) . toString ( ) ) ) { if ( aspectTypeQName . equals ( ContentModel . ASPECT_INCOMPLETE ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Ignoring aspect removal: " + ContentModel . ASPECT_INCOMPLETE ) ; } } save ( nodeRef ) ; } }
private String getUrl ( String url , String propName ) { if ( url == null ) { logger . warn ( "URL for the property [" + propName + "] is not configured." ) ; return "" ; } if ( url . endsWith ( "/" ) ) { url = url . substring ( 0 , url . length ( ) - 1 ) ; } return UrlUtil . replaceShareUrlPlaceholder ( url , sysAdminParams ) ; }
private boolean isOldRenditionInCorrectLocation ( ) { boolean result = isOldRenditionInCorrectLocationWithoutLog ( ) ; if ( logger . isDebugEnabled ( ) ) { StringBuilder msg = new StringBuilder ( ) ; msg . append ( "The old rendition was " ) ; if ( result == false ) { msg . append ( "not " ) ; } msg . append ( "in the correct location" ) ; logger . debug ( msg . toString ( ) ) ; } return result ; }
protected void checkSourceNodeExists ( NodeRef actionedUponNodeRef ) { if ( nodeService . exists ( actionedUponNodeRef ) == false ) { String msg = "Cannot execute action as node does not exist: " + actionedUponNodeRef ; logger . warn ( msg ) ; throw new RenditionServiceException ( msg ) ; } }
public Object execute ( ) throws Throwable { if ( logger . isDebugEnabled ( ) ) logger . debug ( "Exception - writing replication def reports" ) ; replicationDefinitionPersister . saveReplicationDefinition ( replicationDef ) ; return null ; }
@ Override public Void doWork ( ) throws Exception { return retryingTransactionHelper . doInTransaction ( new RetryingTransactionCallback < Void > ( ) { public Void execute ( ) throws Exception { deleteFacet ( facetId ) ; logger . info ( "Deleted [" + facetId + "] node, as the filter has been removed from the config file!" ) ; return null ; } } , false ) ; }
private void logReturnedUser ( String userId ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Returning user:" + AuthenticationUtil . maskUsername ( userId ) ) ; } }
private void split ( Set < NodeRef > toSplit ) { for ( NodeRef nodeRef : toSplit ) { String userName = ( String ) nodeService . getProperty ( nodeRef , ContentModel . PROP_USERNAME ) ; String newUserName = userName + GUID . generate ( ) ; nodeService . setProperty ( nodeRef , ContentModel . PROP_USERNAME , userName + GUID . generate ( ) ) ; logger . info ( "   New person object: " + newUserName ) ; } }
@ Override protected void onBootstrap ( ApplicationEvent event ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Shutdown backstop onBootstrap" ) ; } }
public void processChunk ( Set < ContentData > data ) { checkCancel ( transfer . getTransferId ( ) ) ; logger . debug ( "send chunk to transmitter" ) ; for ( ContentData file : data ) { counter ++ ; eventProcessor . sendContent ( file , fRange , counter ) ; } transmitter . sendContent ( transfer , data ) ; }
@ Override public RepoUsage getUsage ( ) { checkTxnState ( TxnReadState . TXN_READ_ONLY ) ; restrictionsReadLock . lock ( ) ; try { RepoUsage usage = getUsageImpl ( ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Retrieved repo usage: " + usage ) ; } return usage ; } finally { restrictionsReadLock . unlock ( ) ; } }
@ Override @ Extend ( extensionAPI = VersionServiceExtension . class , traitAPI = VersionServiceTrait . class ) public void revert ( NodeRef nodeRef , Version version ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } revert ( nodeRef , version , true ) ; }
@ Override @ Extend ( extensionAPI = VersionServiceExtension . class , traitAPI = VersionServiceTrait . class ) public void revert ( NodeRef nodeRef , Version version ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } revert ( nodeRef , version , true ) ; }
@ Override public StoreRef getVersionStoreReference ( ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } return new StoreRef ( StoreRef . PROTOCOL_WORKSPACE , VersionModel . STORE_ID ) ; }
@ Override public StoreRef getVersionStoreReference ( ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( "Run as user " + AuthenticationUtil . getRunAsUser ( ) ) ; logger . debug ( "Fully authenticated " + AuthenticationUtil . getFullyAuthenticatedUser ( ) ) ; } return new StoreRef ( StoreRef . PROTOCOL_WORKSPACE , VersionModel . STORE_ID ) ; }
public List < WorkflowInstance > getActiveWorkflows ( String workflowDefinitionId ) { try { return getWorkflows ( new WorkflowInstanceQuery ( workflowDefinitionId , true ) ) ; } catch ( ActivitiException ae ) { String message = messageService . getMessage ( ERR_GET_ACTIVE_WORKFLOW_INSTS , workflowDefinitionId ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( message , ae ) ; } throw new WorkflowException ( message , ae ) ; } }
@ Override public Void execute ( ) throws Throwable { ClassPathResource fileResource = new ClassPathResource ( "filesys/ContentDiskDriverTest1.docx" ) ; assertNotNull ( "unable to find test resource filesys/ContentDiskDriverTest1.docx" , fileResource ) ; writeResourceToNetworkFile ( fileResource , testContext . firstFileHandle ) ; logger . debug ( "close the file, firstFileHandle" ) ; driver . closeFile ( testSession , testConnection , testContext . firstFileHandle ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "refresh locks" ) ; lockKeeper . refreshAllLocks ( ) ; return null ; }
protected void createSite ( String siteId , boolean isPublic ) throws Exception { siteService . createSite ( "myPreset" , siteId , "myTitle" , "myDescription" , ( isPublic ? SiteVisibility . PUBLIC : SiteVisibility . PRIVATE ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( "createdSite: " + siteId ) ; } }
public Void execute ( ) throws Throwable { log . debug ( "Adding versionable aspect." ) ; ScriptNode sn = new ScriptNode ( testNode , SERVICE_REGISTRY ) ; sn . addAspect ( "cm:versionable" ) ; return null ; }
@ Override public boolean isActive ( ) { isActiveCount ++ ; logger . debug ( "TestCallback.isActive => " + isActive + " (" + isActiveCount + ")" ) ; return isActive ; }
@ Override public void lockReleased ( ) { logger . debug ( "TestCallback.lockReleased" ) ; released = true ; }
public Void execute ( ) throws Throwable { log . debug ( "About to delete the ruled folder: " + folder1 ) ; NODE_SERVICE . deleteNode ( folder1 ) ; return null ; }
public Void execute ( ) throws Throwable { log . debug ( "About to delete site." ) ; AUTHENTICATION_COMPONENT . getCurrentUserName ( ) ; SITE_SERVICE . deleteSite ( siteShortName ) ; log . debug ( "Site deleted." ) ; return null ; }
public Void execute ( ) throws Throwable { log . debug ( "About to delete site." ) ; AUTHENTICATION_COMPONENT . getCurrentUserName ( ) ; SITE_SERVICE . deleteSite ( siteShortName ) ; log . debug ( "Site deleted." ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "Second transfer" ) ; TransferDefinition definition = new TransferDefinition ( ) ; Set < NodeRef > nodes = new HashSet < NodeRef > ( ) ; nodes . add ( testContext . contentNodeRef ) ; definition . setNodes ( nodes ) ; transferService . transfer ( targetName , definition ) ; return null ; }
@ Override public Void execute ( ) throws Throwable { logger . debug ( "Step 7 - delete node A3" ) ; nodeService . deleteNode ( testData . A3NodeRef ) ; return null ; }
@ Test public void testDefaultSyspath ( ) throws Exception { NodeRef vf = createVirtualizedFolder ( testRootFolder . getNodeRef ( ) , "SystemVirtualizationMethodTest_testDefaultSyspath" , null ) ; assertFalse ( systemVirtualizationMethod . canVirtualize ( environment , vf ) ) ; try { systemVirtualizationMethod . virtualize ( environment , vf ) ; fail ( "Should not be able to virtualize non-virtualizable nodes." ) ; } catch ( VirtualizationException e ) { logger . info ( e ) ; } }
@ Test public void testNonVirtualizable ( ) throws Exception { NodeRef aNodeRef = createVirtualizedFolder ( testRootFolder . getNodeRef ( ) , "TestVirtualStoreImpl_createVirtualizedFolder" , null ) ; assertFalse ( smartStore . canVirtualize ( aNodeRef ) ) ; try { smartStore . virtualize ( aNodeRef ) ; fail ( "Should not be able to virtualize non-virtualizable nodes." ) ; } catch ( VirtualizationException e ) { logger . info ( e ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Iterating through Schema objects:" ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( "    " + dbo ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Iterating through Schema objects:" ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( "    " + dbo ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } }
private void dumpSchema ( ) { if ( log . isDebugEnabled ( ) ) { log . debug ( "Iterating through Schema objects:" ) ; } int i = 0 ; for ( DbObject dbo : getSchema ( ) ) { i ++ ; if ( log . isDebugEnabled ( ) ) { log . debug ( "    " + dbo ) ; } } if ( log . isDebugEnabled ( ) ) { log . debug ( "Schema object contains " + i + " objects." ) ; } }
protected OperatingSystem parseOperatingSystem ( Server from ) { try { return Iterables . find ( images . get ( ) , new FindImageForServer ( from ) ) . getOperatingSystem ( ) ; } catch ( NoSuchElementException e ) { logger . debug ( "could not find a matching image for server %s in location %s" , from , location . get ( ) ) ; } return null ; }
protected ExecResponse runCommand ( String command ) { ExecResponse returnVal ; logger . debug ( ">> running [%s] as %s@%s" , command . replace ( node . getCredentials ( ) . getPassword ( ) != null ? node . getCredentials ( ) . getPassword ( ) : "XXXXX" , "XXXXX" ) , ssh . getUsername ( ) , ssh . getHostAddress ( ) ) ; returnVal = ssh . exec ( command ) ; return returnVal ; }
public T apply ( HttpResponse from ) { InputStream gson = from . getPayload ( ) . getInput ( ) ; try { return apply ( gson ) ; } catch ( Exception e ) { StringBuilder message = new StringBuilder ( ) ; message . append ( "Error parsing input" ) ; logger . error ( e , message . toString ( ) ) ; throw new HttpResponseException ( message . toString ( ) + "n" + from , null , from , e ) ; } finally { releasePayload ( from ) ; } }
public void imposeBackoffExponentialDelay ( long period , long maxPeriod , int pow , int failureCount , int max , String commandDescription ) { long delayMs = ( long ) ( period * Math . pow ( failureCount , pow ) ) ; delayMs = delayMs > maxPeriod ? maxPeriod : delayMs ; logger . debug ( "Retry %d/%d: delaying for %d ms: %s" , failureCount , max , delayMs , commandDescription ) ; try { Thread . sleep ( delayMs ) ; } catch ( InterruptedException e ) { Throwables . propagate ( e ) ; } }
@ Override public Set < String > get ( ) { String regionString = config . apply ( configKey ) ; if ( regionString == null ) { logger . debug ( "no %s configured for provider %s" , configKey , provider ) ; return ImmutableSet . of ( ) ; } else { return ImmutableSet . copyOf ( Splitter . on ( ',' ) . split ( regionString ) ) ; } }
private Function < HttpResponse , ? > getTransformer ( String commandName , HttpCommand command ) { HttpRequest request = command . getCurrentRequest ( ) ; Function < HttpResponse , ? > transformer = transformerForRequest . apply ( request ) ; logger . trace ( "<< response from %s is parsed by %s" , commandName , transformer . getClass ( ) . getSimpleName ( ) ) ; return transformer ; }
@ Override protected void logDebug ( String message ) { logger . debug ( message ) ; }
@ Override public void clear ( ) { if ( ssh != null && ssh . isConnected ( ) ) { try { ssh . disconnect ( ) ; } catch ( AssertionError e ) { } catch ( IOException e ) { logger . debug ( "<< exception disconnecting from %s: %s" , e , e . getMessage ( ) ) ; } ssh = null ; } }
protected Image parseImage ( Server from ) { Image image = null ; try { image = Iterables . find ( images . get ( ) , new FindImageForServer ( from ) ) ; } catch ( NoSuchElementException e ) { logger . debug ( "could not find a matching image for server %s" , from ) ; } return image ; }
public boolean apply ( Volume volume ) { logger . trace ( "looking for state on volume %s" , volume ) ; volume = client . getVolume ( volume . getId ( ) ) ; if ( volume == null ) return false ; logger . trace ( "%s: looking for volume state %s: currently: %s" , volume . getId ( ) , Volume . State . UNMOUNTED , volume . getState ( ) ) ; return volume . getState ( ) == Volume . State . UNMOUNTED ; }
public boolean apply ( Volume volume ) { logger . trace ( "looking for state on volume %s" , volume ) ; volume = client . getVolume ( volume . getId ( ) ) ; if ( volume == null ) return false ; logger . trace ( "%s: looking for volume state %s: currently: %s" , volume . getId ( ) , Volume . State . UNMOUNTED , volume . getState ( ) ) ; return volume . getState ( ) == Volume . State . UNMOUNTED ; }
@ Override public boolean apply ( final String networkDomainId ) { checkNotNull ( networkDomainId , "networkDomainId" ) ; logger . trace ( "looking for state on network domain %s" , networkDomainId ) ; final NetworkDomain networkDomain = networkApi . getNetworkDomain ( networkDomainId ) ; final boolean isDeleted = networkDomain == null && state == State . DELETED ; return isDeleted || ( networkDomain != null && networkDomain . state ( ) == state ) ; }
@ Override public boolean apply ( final String customerImageId ) { checkNotNull ( customerImageId , "customerImageId" ) ; logger . trace ( "looking for state on customer image %s" , customerImageId ) ; final CustomerImage customerImage = serverImageApi . getCustomerImage ( customerImageId ) ; final boolean isDeleted = customerImage == null && state == State . DELETED ; return isDeleted || ( customerImage != null && customerImage . state ( ) == state ) ; }
@ Override public List < Image > call ( ) throws Exception { logger . trace ( "<< fetching images.." ) ; Iterable < Image > filteredImages = Iterables . filter ( api . imageApi ( ) . getList ( new DepthOptions ( ) . depth ( 1 ) ) , new Predicate < Image > ( ) { @ Override public boolean apply ( Image image ) { return image . properties ( ) . imageType ( ) == Image . Type . HDD ; } } ) ; logger . trace ( ">> images fetched." ) ; return ImmutableList . copyOf ( filteredImages ) ; }
@ Override public List < Image > call ( ) throws Exception { logger . trace ( "<< fetching images.." ) ; Iterable < Image > filteredImages = Iterables . filter ( api . imageApi ( ) . getList ( new DepthOptions ( ) . depth ( 1 ) ) , new Predicate < Image > ( ) { @ Override public boolean apply ( Image image ) { return image . properties ( ) . imageType ( ) == Image . Type . HDD ; } } ) ; logger . trace ( ">> images fetched." ) ; return ImmutableList . copyOf ( filteredImages ) ; }
@ Override public void rebootNode ( String id ) { String virtualMachineId = id ; String job = client . getVirtualMachineApi ( ) . rebootVirtualMachine ( virtualMachineId ) ; if ( job != null ) { logger . debug ( ">> rebooting virtualMachine(%s) job(%s)" , virtualMachineId , job ) ; awaitCompletion ( job ) ; } }
@ Override public void resumeNode ( String id ) { String virtualMachineId = id ; String job = client . getVirtualMachineApi ( ) . startVirtualMachine ( id ) ; if ( job != null ) { logger . debug ( ">> starting virtualMachine(%s) job(%s)" , virtualMachineId , job ) ; awaitCompletion ( job ) ; } }
@ Override public Set < ? extends NodeMetadata > listNodesDetailsMatching ( Predicate < ? super NodeMetadata > filter ) { checkNotNull ( filter , "filter" ) ; logger . trace ( ">> listing node details matching(%s)" , filter ) ; Set < ? extends NodeMetadata > set = newLinkedHashSet ( listNodesStrategy . listDetailsOnNodesMatching ( filter ) ) ; logger . trace ( "<< list(%d)" , set . size ( ) ) ; return set ; }
@ Override public Set < ? extends NodeMetadata > listNodesDetailsMatching ( Predicate < ? super NodeMetadata > filter ) { checkNotNull ( filter , "filter" ) ; logger . trace ( ">> listing node details matching(%s)" , filter ) ; Set < ? extends NodeMetadata > set = newLinkedHashSet ( listNodesStrategy . listDetailsOnNodesMatching ( filter ) ) ; logger . trace ( "<< list(%d)" , set . size ( ) ) ; return set ; }
private void cleanupAutoGeneratedKeyPairs ( Set < Integer > generatedSshKeyIds ) { logger . debug ( ">> cleaning up auto-generated key pairs..." ) ; for ( Integer sshKeyId : generatedSshKeyIds ) { try { api . keyApi ( ) . delete ( sshKeyId ) ; } catch ( Exception ex ) { logger . warn ( ">> could not delete key pair %s: %s" , sshKeyId , ex . getMessage ( ) ) ; } } }
private void cleanupAutoGeneratedKeyPairs ( Set < Integer > generatedSshKeyIds ) { logger . debug ( ">> cleaning up auto-generated key pairs..." ) ; for ( Integer sshKeyId : generatedSshKeyIds ) { try { api . keyApi ( ) . delete ( sshKeyId ) ; } catch ( Exception ex ) { logger . warn ( ">> could not delete key pair %s: %s" , sshKeyId , ex . getMessage ( ) ) ; } } }
@ SuppressWarnings ( "serial" ) private void write ( ) { try { if ( ! file . exists ( ) ) { logger . info ( "Creating saved clients list in " + file ) ; file . createNewFile ( ) ; } FileWriter out = new FileWriter ( file ) ; gson . toJson ( clients , new TypeToken < Map < String , RegisteredClient > > ( ) { } . getType ( ) , out ) ; out . close ( ) ; } catch ( IOException e ) { logger . error ( "Could not write to output file" , e ) ; } }
@ SuppressWarnings ( "serial" ) private void write ( ) { try { if ( ! file . exists ( ) ) { logger . info ( "Creating saved clients list in " + file ) ; file . createNewFile ( ) ; } FileWriter out = new FileWriter ( file ) ; gson . toJson ( clients , new TypeToken < Map < String , RegisteredClient > > ( ) { } . getType ( ) , out ) ; out . close ( ) ; } catch ( IOException e ) { logger . error ( "Could not write to output file" , e ) ; } }
@ Override public void signJwt ( SignedJWT jwt , JWSAlgorithm alg ) { JWSSigner signer = null ; for ( JWSSigner s : signers . values ( ) ) { if ( s . supportedJWSAlgorithms ( ) . contains ( alg ) ) { signer = s ; break ; } } if ( signer == null ) { logger . error ( "No matching algirthm found for alg=" + alg ) ; } try { jwt . sign ( signer ) ; } catch ( JOSEException e ) { logger . error ( "Failed to sign JWT, error was: " , e ) ; } }
@ Override public void signJwt ( SignedJWT jwt , JWSAlgorithm alg ) { JWSSigner signer = null ; for ( JWSSigner s : signers . values ( ) ) { if ( s . supportedJWSAlgorithms ( ) . contains ( alg ) ) { signer = s ; break ; } } if ( signer == null ) { logger . error ( "No matching algirthm found for alg=" + alg ) ; } try { jwt . sign ( signer ) ; } catch ( JOSEException e ) { logger . error ( "Failed to sign JWT, error was: " , e ) ; } }
private OAuth2RefreshTokenEntity clearExpiredRefreshToken ( OAuth2RefreshTokenEntity token ) { if ( token == null ) { return null ; } else if ( token . isExpired ( ) ) { logger . debug ( "Clearing expired refresh token: " + token . getValue ( ) ) ; revokeRefreshToken ( token ) ; return null ; } else { return token ; } }
private void writeBlacklistedSites ( JsonWriter writer ) throws IOException { for ( BlacklistedSite blSite : blSiteRepository . getAll ( ) ) { writer . beginObject ( ) ; writer . name ( ID ) . value ( blSite . getId ( ) ) ; writer . name ( URI ) . value ( blSite . getUri ( ) ) ; writer . endObject ( ) ; logger . debug ( "Wrote blacklisted site {}" , blSite . getId ( ) ) ; } logger . info ( "Done writing blacklisted sites" ) ; }
private void writeBlacklistedSites ( JsonWriter writer ) throws IOException { for ( BlacklistedSite blSite : blSiteRepository . getAll ( ) ) { writer . beginObject ( ) ; writer . name ( ID ) . value ( blSite . getId ( ) ) ; writer . name ( URI ) . value ( blSite . getUri ( ) ) ; writer . endObject ( ) ; logger . debug ( "Wrote blacklisted site {}" , blSite . getId ( ) ) ; } logger . info ( "Done writing blacklisted sites" ) ; }
@ Override protected int execute ( String [ ] args ) throws Exception { Configuration conf = getConf ( ) ; conf . set ( StageConstants . PROP_BATCH_ID , getBatchId ( ) ) ; conf . set ( StageConstants . PROP_FLOW_ID , getFlowId ( ) ) ; LOG . info ( MessageFormat . format ( "Initializing Job: batchId={0}, flowId={1}, executionId={2}, stageId={3}" , getBatchId ( ) , getFlowId ( ) , getExecutionId ( ) , getStageId ( ) ) ) ; Job job = createJob ( conf ) ; return submit ( job ) ; }
@ Override public boolean run ( Job job ) throws IOException , InterruptedException , ClassNotFoundException { job . submit ( ) ; LOG . info ( MessageFormat . format ( "starting job using {0}: {1} ({2})" , this , job . getJobID ( ) , job . getJobName ( ) ) ) ; return job . waitForCompletion ( true ) ; }
@ Override public void write ( T model ) throws IOException { if ( requireGenerateHeader ) { requireGenerateHeader = false ; writeHeader ( ) ; } if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( String . format ( "writing record: path=%s, object=%s" , path , model ) ) ; } for ( FieldDriver < T , ? > field : fields ) { writer . putField ( fill ( model , field ) ) ; } try { writer . putEndOfRecord ( ) ; } catch ( UnmappableOutputException e ) { handleUnmappable ( model , e . getEntries ( ) ) ; } }
public static boolean isValid ( String name ) { if ( checkSyntax ( name ) == false ) { return false ; } try { Models . toName ( Models . getModelFactory ( ) , name ) ; return true ; } catch ( IllegalArgumentException e ) { LOG . trace ( "invalid class name: {}" , name , e ) ; return false ; } }
public static boolean isValid ( String pattern ) { try { DecimalFormat format = new DecimalFormat ( ) ; format . applyPattern ( pattern ) ; return true ; } catch ( IllegalArgumentException e ) { LOG . trace ( "invalid decimal pattern: {}" , pattern , e ) ; return false ; } }
private static void closeQuiet ( Object object ) { if ( object instanceof Closeable ) { try { ( ( Closeable ) object ) . close ( ) ; } catch ( IOException e ) { LOG . warn ( MessageFormat . format ( Messages . getString ( "GenerateCreateTable.errorFailedToClose" ) , object ) , e ) ; } } }
public static < T > byte [ ] serialize ( Class < ? extends T > type , T object ) { ObjectMapper mapper = mapper ( ) ; try { byte [ ] bytes = mapper . writerWithDefaultPrettyPrinter ( ) . forType ( type ) . writeValueAsBytes ( object ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( new String ( bytes , StandardCharsets . UTF_8 ) ) ; } return bytes ; } catch ( JsonProcessingException e ) { throw new AssertionError ( e ) ; } }
public boolean isSymlink ( FileSystem fs , FileStatus file ) { try { return isSymlink0 ( fs , file ) ; } catch ( Exception e ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( MessageFormat . format ( "Failed to resolve symlink" , file . getPath ( ) ) , e ) ; } return false ; } }
private static void handle ( CommandExecutionException e ) { LOG . error ( "error occurred while executing command" , e ) ; }
private Optional < FileStatus > stat ( Path path ) { try { return Optional . of ( dataSourceParameter . getHadoopFileSystem ( path ) . getFileStatus ( path ) ) ; } catch ( FileNotFoundException e ) { LOG . trace ( "not found: {}" , path , e ) ; return Optional . empty ( ) ; } catch ( IOException e ) { throw new CommandConfigurationException ( MessageFormat . format ( "error occurred while resolving Hadoop path: {0}" , path ) , e ) ; } }
private void message ( Diagnostic . Kind kind , Element element , String pattern , Object ... arguments ) { assert kind != null ; assert element != null ; assert pattern != null ; assert arguments != null ; String message = arguments . length == 0 ? pattern : MessageFormat . format ( pattern , arguments ) ; if ( kind == Diagnostic . Kind . NOTE ) { LOG . debug ( message ) ; } else { environment . getProcessingEnvironment ( ) . getMessager ( ) . printMessage ( kind , message , element ) ; } }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
@ Test public void log_format_multi ( ) { Logger logger = Logger . get ( LoggerTest . class ) ; logger . trace ( "trace: -{}-{}-{}-" , 1 , 2 , 3 ) ; logger . debug ( "debug: -{}-{}-{}-" , 4 , 5 , 6 ) ; logger . info ( "info: -{}-{}-{}-" , 7 , 8 , 9 ) ; logger . warn ( "warn: -{}-{}-{}-" , 10 , 11 , 12 ) ; logger . error ( "error: -{}-{}-{}-" , 13 , 14 , 15 ) ; }
public void truncate ( ExporterDescription description ) throws IOException { LOG . info ( MessageFormat . format ( Messages . getString ( "BatchTestTool.infoCleaningOutput" ) , description . getClass ( ) . getName ( ) ) ) ; TestModerator moderator = new TestModerator ( getTestTools ( ) , this ) ; moderator . truncate ( description ) ; }
private static void clean ( ) { try { FileSystem . closeAll ( ) ; } catch ( IOException e ) { LOG . warn ( "error occurred while cleaning up Hadoop file systems" , e ) ; } }
@ Override protected void handle ( IOException exception ) throws IOException { exceptions . record ( exception ) ; WGLOG . error ( exception , "E05002" , script . getName ( ) , script . getSourceScript ( ) . getResourceName ( ) , script . getDrainScript ( ) . getResourceName ( ) ) ; }
@ Override public ResourceMirror create ( String sessionId , ParameterList arguments ) throws IOException { if ( sessionId == null ) { throw new IllegalArgumentException ( "sessionId must not be null" ) ; } if ( arguments == null ) { throw new IllegalArgumentException ( "arguments must not be null" ) ; } LOG . debug ( "Creating Hadoop FS resource {} for session {}" , hfsProfile . getResourceName ( ) , sessionId ) ; return new HadoopFsMirror ( configuration , hfsProfile , arguments ) ; }
@ Override public ResourceMirror create ( String sessionId , ParameterList arguments ) throws IOException { if ( sessionId == null ) { throw new IllegalArgumentException ( "sessionId must not be null" ) ; } if ( arguments == null ) { throw new IllegalArgumentException ( "arguments must not be null" ) ; } LOG . debug ( "Creating Hadoop FS via JSch resource {} for session {}" , sshProfile . getResourceName ( ) , sessionId ) ; return new JschHadoopFsMirror ( configuration , sshProfile , arguments ) ; }
public static FileList . Reader createReader ( InputStream input ) throws IOException { if ( input == null ) { throw new IllegalArgumentException ( "input must not be null" ) ; } LOG . debug ( "Creating a new file list reader" ) ; byte [ ] dropped = FileListUtil . dropPreamble ( input , PREAMBLE_MARGIN ) ; if ( dropped . length >= 1 ) { WGLOG . warn ( "W19002" , new String ( dropped , Charset . defaultCharset ( ) ) ) ; } return new Reader ( input ) ; }
public static FileList . Reader createReader ( InputStream input ) throws IOException { if ( input == null ) { throw new IllegalArgumentException ( "input must not be null" ) ; } LOG . debug ( "Creating a new file list reader" ) ; byte [ ] dropped = FileListUtil . dropPreamble ( input , PREAMBLE_MARGIN ) ; if ( dropped . length >= 1 ) { WGLOG . warn ( "W19002" , new String ( dropped , Charset . defaultCharset ( ) ) ) ; } return new Reader ( input ) ; }
private static void extractCompressionCodec ( Configuration configuration , ResourceProfile profile ) { assert configuration != null ; assert profile != null ; String compressionCodecString = extract ( profile , KEY_COMPRESSION , false ) ; if ( compressionCodecString != null ) { WGLOG . warn ( "W10001" , profile . getName ( ) , KEY_COMPRESSION , compressionCodecString ) ; } }
private PreparedStatement prepareStatement ( ) throws SQLException { String sql = createSql ( ) ; LOG . debug ( "Preparing SQL: {}" , sql ) ; return connection . prepareStatement ( sql ) ; }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting file: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . info ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting file: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . info ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private void delete ( File path ) { assert path != null ; LOG . info ( "Deleting file: {}" , path . getAbsolutePath ( ) ) ; if ( path . delete ( ) ) { LOG . info ( "Deleted file: {}" , path . getAbsolutePath ( ) ) ; } else { LOG . info ( "Failed to delete file: {}" , path . getAbsolutePath ( ) ) ; } }
private static void addArgument ( Map < String , String > results , String key , String value ) { assert results != null ; assert key != null ; assert value != null ; if ( results . containsKey ( key ) ) { WGLOG . warn ( "W99003" , key , value ) ; } else { results . put ( key , value ) ; } }
public static void main ( String ... args ) { CommandLineUtil . prepareLogContext ( ) ; CommandLineUtil . prepareRuntimeContext ( ) ; WGLOG . info ( "I01000" ) ; long start = System . currentTimeMillis ( ) ; int status = execute ( args ) ; long end = System . currentTimeMillis ( ) ; WGLOG . info ( "I01999" , status , end - start ) ; System . exit ( status ) ; }
public static void main ( String ... args ) { CommandLineUtil . prepareLogContext ( ) ; CommandLineUtil . prepareRuntimeContext ( ) ; WGLOG . info ( "I01000" ) ; long start = System . currentTimeMillis ( ) ; int status = execute ( args ) ; long end = System . currentTimeMillis ( ) ; WGLOG . info ( "I01999" , status , end - start ) ; System . exit ( status ) ; }
static int exec ( String ... args ) { if ( args . length == 0 ) { LOG . warn ( "there are no files to delete" ) ; return - 1 ; } boolean sawError = false ; Configuration conf = new Configuration ( ) ; for ( String arg : args ) { try { delete ( conf , new Path ( arg ) ) ; } catch ( IOException e ) { LOG . error ( MessageFormat . format ( "failed to delete file: {0}" , arg ) , e ) ; sawError = true ; } } return sawError ? 1 : 0 ; }
static int exec ( String ... args ) { if ( args . length == 0 ) { LOG . warn ( "there are no files to delete" ) ; return - 1 ; } boolean sawError = false ; Configuration conf = new Configuration ( ) ; for ( String arg : args ) { try { delete ( conf , new Path ( arg ) ) ; } catch ( IOException e ) { LOG . error ( MessageFormat . format ( "failed to delete file: {0}" , arg ) , e ) ; sawError = true ; } } return sawError ? 1 : 0 ; }
@ Override public void execute ( ExecutionMonitor monitor , ExecutionContext context , T script ) throws InterruptedException , IOException { ExecutionScriptHandler < T > target = resolve ( context , script ) ; assert target != null ; YSLOG . info ( "I01002" , target . getHandlerId ( ) , context . getBatchId ( ) , context . getFlowId ( ) , context . getPhase ( ) , context . getExecutionId ( ) , script . getId ( ) ) ; target . execute ( monitor , context , script ) ; }
public static String getHostname ( ) { if ( Netshot . hostname == null ) { try { Process process = Runtime . getRuntime ( ) . exec ( "hostname" ) ; BufferedReader stdInput = new BufferedReader ( new InputStreamReader ( process . getInputStream ( ) ) ) ; Netshot . hostname = stdInput . readLine ( ) ; } catch ( IOException e ) { logger . error ( "Error while getting local machine hostname" , e ) ; } if ( Netshot . hostname == null ) { Netshot . hostname = "unknown" ; } } return Netshot . hostname ; }
public static void init ( ) { if ( Netshot . getConfig ( "netshot.tftpserver.disabled" , "true" ) . equals ( "true" ) ) { logger . warn ( "The TFTP server is disabled." ) ; return ; } nsTftpServer = new TftpServer ( ) ; nsTftpServer . start ( ) ; }
@ Override public void info ( String message ) { snmpLogger . warn ( "[JSINFO] {}" , message ) ; }
@ Override public void disconnect ( ) { try { if ( channel != null ) { channel . disconnect ( ) ; } if ( session != null ) { session . disconnect ( ) ; } } catch ( Exception e ) { logger . warn ( "Error on SSH disconnect." , e ) ; } }
@ Override public void createDirectory ( Path dir , FileAttribute < ? > ... attrs ) throws IOException { logger . warn ( "Denying creation of directory {}" , dir ) ; throw new SecurityException ( "Creation of directory " + dir + " is denied." ) ; }
@ Override public void stop ( ) { for ( Method method : o . getClass ( ) . getMethods ( ) ) { if ( method . getAnnotation ( LifecycleStop . class ) != null ) { log . info ( "Invoking stop method[%s] on object[%s]." , method , o ) ; try { method . invoke ( o ) ; } catch ( Exception e ) { log . error ( e , "Exception when stopping method[%s] on object[%s]" , method , o ) ; } } } }
@ Override public void stop ( ) { for ( Method method : o . getClass ( ) . getMethods ( ) ) { if ( method . getAnnotation ( LifecycleStop . class ) != null ) { log . info ( "Invoking stop method[%s] on object[%s]." , method , o ) ; try { method . invoke ( o ) ; } catch ( Exception e ) { log . error ( e , "Exception when stopping method[%s] on object[%s]" , method , o ) ; } } } }
@ Override public void start ( ) throws Exception { log . info ( "Starting object[%s]" , o ) ; startMethod . invoke ( o ) ; }
public void error ( Throwable t , String message , Object ... formatArgs ) { log . error ( StringUtils . safeFormat ( message , formatArgs ) , t ) ; }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter [%s]." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]" , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter [%s]." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]" , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override @ LifecycleStop public void close ( ) throws IOException { boolean fail = false ; log . info ( "Closing Composing Emitter." ) ; for ( Map . Entry < String , Emitter > e : emitters . entrySet ( ) ) { try { log . info ( "Closing emitter [%s]." , e . getKey ( ) ) ; e . getValue ( ) . close ( ) ; } catch ( IOException ex ) { log . error ( ex , "Failed to close emitter [%s]" , e . getKey ( ) ) ; fail = true ; } } if ( fail ) { throw new IOException ( "failed to close one or more emitters" ) ; } }
@ Override public void handle ( Exception exception ) { if ( exceptionCount % 1000 == 0 ) { log . error ( exception , "Error sending metric to StatsD." ) ; } exceptionCount += 1 ; }
@ Override public void close ( ChannelFuture resource ) { log . trace ( "Closing" ) ; resource . awaitUninterruptibly ( ) . getChannel ( ) . close ( ) ; }
private Integer getGeneralizedPatternID ( OWLAxiom axiom ) { try { selectGeneralizedPatternIdPs . setString ( 1 , render ( axiom ) ) ; try ( ResultSet rs = selectGeneralizedPatternIdPs . executeQuery ( ) ) { if ( rs . next ( ) ) { return rs . getInt ( 1 ) ; } } } catch ( SQLException e ) { LOGGER . error ( "Failed to get pattern ID." , e ) ; } return null ; }
private synchronized void addOntologyImport ( URI physicalURI1 , OWLOntology ontology1 , URI physicalURI2 , OWLOntology ontology2 ) { Integer ontologyID1 = getOntologyID ( physicalURI1 , ontology1 ) ; Integer ontologyID2 = getOntologyID ( physicalURI2 , ontology2 ) ; try { insertOntologyImportPs . setInt ( 1 , ontologyID1 ) ; insertOntologyImportPs . setInt ( 2 , ontologyID2 ) ; insertOntologyImportPs . execute ( ) ; } catch ( SQLException e ) { LOGGER . error ( "Failed to insert ontology." , e ) ; } }
@ Override public SortedSet < OWLIndividual > getIndividualsImpl ( OWLClassExpression ce ) { Set < OWLNamedIndividual > individuals ; logger . trace ( "getIndividuals for " + ce ) ; try { individuals = reasoner . getInstances ( ce , false ) . getFlattened ( ) ; } catch ( UnsupportedOperationException e ) { if ( useFallbackReasoner ) { individuals = fallbackReasoner . getInstances ( ce , false ) . getFlattened ( ) ; } else { throw e ; } } return new TreeSet < > ( individuals ) ; }
@ SuppressWarnings ( "unused" ) private void makeNegativeExamplesFromRange ( String role , int sparqlResultSetLimit ) { logger . debug ( "making Negative Examples from Range of : " + role ) ; fromRange . addAll ( sparqltasks . getRangeInstances ( role , sparqlResultSetLimit ) ) ; fromRange . removeAll ( fullPositiveSet ) ; logger . debug ( "|-neg Example size from Range: " + fromRange . size ( ) ) ; }
@ SuppressWarnings ( "unused" ) private void makeNegativeExamplesFromRange ( String role , int sparqlResultSetLimit ) { logger . debug ( "making Negative Examples from Range of : " + role ) ; fromRange . addAll ( sparqltasks . getRangeInstances ( role , sparqlResultSetLimit ) ) ; fromRange . removeAll ( fullPositiveSet ) ; logger . debug ( "|-neg Example size from Range: " + fromRange . size ( ) ) ; }
private List < String > getResultSplitted ( String sparqlQuery ) { Query query = QueryFactory . create ( sparqlQuery ) ; logger . trace ( "Getting result set splitted forn{}" , query ) ; List < Query > queries = QueryRewriter . split ( query ) ; List < String > resources = getResult ( queries . remove ( 0 ) . toString ( ) ) ; queries . stream ( ) . map ( q -> getResult ( q . toString ( ) ) ) . forEach ( resources :: retainAll ) ; return resources ; }
@ Override public void init ( ) throws ComponentInitException { if ( edge == null ) { String msg = "Underlying EDGE class not instantiated" ; logger . error ( msg ) ; throw new ComponentInitException ( msg ) ; } logger . debug ( "Initializing EDGE" ) ; fullyInitialized = false ; super . init ( ) ; }
@ Override public void init ( ) throws ComponentInitException { if ( edge == null ) { String msg = "Underlying EDGE class not instantiated" ; logger . error ( msg ) ; throw new ComponentInitException ( msg ) ; } logger . debug ( "Initializing EDGE" ) ; fullyInitialized = false ; super . init ( ) ; }
private Set < Set < OWLAxiom > > computeExplanations ( OWLOntology ontology ) { logger . info ( "Computing explanations..." ) ; long startTime = System . currentTimeMillis ( ) ; boolean useGlassBox = true ; PelletExplanation expGen = new PelletExplanation ( ontology , useGlassBox ) ; Set < Set < OWLAxiom > > explanations = expGen . getInconsistencyExplanations ( maxNrOfExplanations ) ; logger . info ( "...done in " + ( System . currentTimeMillis ( ) - startTime ) + "ms." ) ; return explanations ; }
private Set < Set < OWLAxiom > > computeExplanations ( OWLOntology ontology ) { logger . info ( "Computing explanations..." ) ; long startTime = System . currentTimeMillis ( ) ; boolean useGlassBox = true ; PelletExplanation expGen = new PelletExplanation ( ontology , useGlassBox ) ; Set < Set < OWLAxiom > > explanations = expGen . getInconsistencyExplanations ( maxNrOfExplanations ) ; logger . info ( "...done in " + ( System . currentTimeMillis ( ) - startTime ) + "ms." ) ; return explanations ; }
public int getSymLinkDepth ( ) { int value = 0 ; try { value = Integer . parseInt ( line . getOptionValue ( ARGUMENT . SYM_LINK_DEPTH , "0" ) ) ; if ( value < 0 ) { value = 0 ; } } catch ( NumberFormatException ex ) { LOGGER . debug ( "Symbolic link was not a number" ) ; } return value ; }
private boolean checkEnabled ( ) { try { return getSettings ( ) . getBoolean ( Settings . KEYS . ANALYZER_CENTRAL_ENABLED ) ; } catch ( InvalidSettingException ise ) { LOGGER . warn ( "Invalid setting. Disabling the Central analyzer" ) ; } return false ; }
@ Override public void prepareAnalyzer ( Engine engine ) throws InitializationException { try { loadHintRules ( ) ; } catch ( HintParseException ex ) { LOGGER . debug ( "Unable to parse hint file" , ex ) ; throw new InitializationException ( "Unable to parse the hint file" , ex ) ; } }
public static boolean isH2Connection ( Settings configuration ) { final String connStr ; try { connStr = configuration . getConnectionString ( Settings . KEYS . DB_CONNECTION_STRING , Settings . KEYS . DB_FILE_NAME ) ; } catch ( IOException ex ) { LOGGER . debug ( "Unable to get connectionn string" , ex ) ; return false ; } return isH2Connection ( connStr ) ; }
private void given ( CharSequence s , int wanted , int got ) { red . append ( s ) ; given += got ; LOGGER . trace ( "Given: [" + wanted + "," + got + "]-" + s ) ; }
public synchronized void cleanup ( boolean deleteTemporary ) { if ( deleteTemporary && tempDirectory != null && tempDirectory . exists ( ) ) { LOGGER . debug ( "Deleting ALL temporary files from `{}`" , tempDirectory . toString ( ) ) ; FileUtils . delete ( tempDirectory ) ; tempDirectory = null ; } }
public void toStop ( ) { toStop = true ; logrThread . interrupt ( ) ; try { logrThread . join ( ) ; } catch ( InterruptedException e ) { logger . error ( e . getMessage ( ) , e ) ; } }
@ ExceptionHandler ( ServiceException . class ) public AjaxResult < Void > handleServiceException ( ServiceException e , HttpServletRequest request ) { log . error ( e . getMessage ( ) , e ) ; Integer code = e . getCode ( ) ; return StringUtils . isNotNull ( code ) ? AjaxResult . error ( code , e . getMessage ( ) ) : AjaxResult . error ( e . getMessage ( ) ) ; }
public void associateEnvironmentToJndi ( JNDIResourceModel resource , EnvironmentReferenceModel ref ) { LOG . info ( "Associating JNDI: " + resource + " to Environmental Ref: " + ref . getName ( ) + ", " + ref . getReferenceId ( ) + ", " + ref . getReferenceType ( ) ) ; if ( ref . getJndiReference ( ) == null ) { ref . setJndiReference ( resource ) ; } jndiResourceService . associateTypeJndiResource ( resource , ref . getReferenceType ( ) ) ; }
@ Override public void perform ( GraphRewrite event , EvaluationContext context , ArchiveModel archive ) { LOG . info ( "Deleting archive files: " + archive . getArchiveName ( ) ) ; FileUtils . deleteQuietly ( new File ( archive . getUnzippedDirectory ( ) ) ) ; }
@ Override public void perform ( GraphRewrite event , EvaluationContext context , JavaTypeReferenceModel payload ) { firstRuleMatchCount ++ ; log . info ( "First rule matched: " + payload . getFile ( ) . getFilePath ( ) ) ; }
private void installOldAddonVersion ( String currentUiVersion ) { RemoveRequest remove = manager . remove ( AddonId . from ( WINDUP_UI_ADDON_NAME , currentUiVersion ) ) ; remove . perform ( ) ; final AddonId olderAddonId = AddonId . from ( WINDUP_UI_ADDON_NAME , WINDUP_OLD_VERSION ) ; log . info ( "Downgrading to " + olderAddonId + ". This may take a while to download." ) ; InstallRequest install = manager . install ( olderAddonId ) ; install . perform ( ) ; }
public void end ( ) { if ( this . startTime == 0 ) { LOG . info ( "Called end with key: " + this . key + " without ever calling begin" ) ; return ; } this . totalNanos += ( System . nanoTime ( ) - startTime ) ; this . startTime = 0 ; this . numberOfExecutions ++ ; }
private ArrayList getRoleValue ( String relationId , String roleName ) { Logger logger = getLogger ( ) ; try { Object [ ] params = { relationId , roleName } ; String [ ] signature = { "java.lang.String" , "java.lang.String" } ; return ( ( ArrayList ) ( m_server . invoke ( m_relationObjectName , "getRole" , params , signature ) ) ) ; } catch ( Exception ex ) { logger . error ( "Unable to get the list of roles for ID: " + relationId ) ; return null ; } }
@ Override protected void logWarning ( String description , String message ) { log . debug ( description ) ; log . debug ( message ) ; }
@ Override protected void logWarning ( String description , String message ) { log . debug ( description ) ; log . debug ( message ) ; }
@ GET @ Timed @ Produces ( APPLICATION_JSON_WITH_CHARSET ) public String list ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph , @ QueryParam ( "limit" ) @ DefaultValue ( "100" ) long limit ) { LOG . debug ( "Graph [{}] list targets" , graph ) ; HugeGraph g = graph ( manager , graph ) ; List < HugeTarget > targets = manager . authManager ( ) . listAllTargets ( limit ) ; return manager . serializer ( g ) . writeAuthElements ( "targets" , targets ) ; }
@ DELETE @ Timed @ Path ( "{id}" ) public void delete ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph , @ PathParam ( "id" ) long id ) { LOG . debug ( "Graph [{}] delete task: {}" , graph , id ) ; TaskScheduler scheduler = graph ( manager , graph ) . taskScheduler ( ) ; HugeTask < ? > task = scheduler . delete ( IdGenerator . of ( id ) ) ; E . checkArgument ( task != null , "There is no task with id '%s'" , id ) ; }
@ GET @ Timed @ Produces ( APPLICATION_JSON_WITH_CHARSET ) public Map < String , Object > list ( @ Context GraphManager manager , @ PathParam ( "graph" ) String graph ) { LOG . debug ( "Graph [{}] get variables" , graph ) ; HugeGraph g = graph ( manager , graph ) ; return g . variables ( ) . asMap ( ) ; }
@ Override public void close ( ) { LOG . debug ( "Store close: {}" , this . store ) ; this . sessions . close ( ) ; }
private SysTransaction openSystemTransaction ( ) throws HugeException { this . checkGraphNotClosed ( ) ; try { return new SysTransaction ( this . params , loadSystemStore ( ) ) ; } catch ( BackendException e ) { String message = "Failed to open system transaction" ; LOG . error ( "{}" , message , e ) ; throw new HugeException ( message ) ; } }
protected final void notifyAndWaitEvent ( String event ) { Future < ? > future = this . storeEventHub . notify ( event , this ) ; try { future . get ( ) ; } catch ( Throwable e ) { LOG . warn ( "Error when waiting for event execution: {}" , event , e ) ; } }
public boolean close ( ) { Pair < Integer , Integer > result = Pair . of ( - 1 , - 1 ) ; try { result = this . closeSession ( ) ; } finally { if ( result . getLeft ( ) == 0 ) { this . doClose ( ) ; } } LOG . debug ( "Now(after close({})) session count is: {}, " + "current session reference is: {}" , this , result . getLeft ( ) , result . getRight ( ) ) ; return result . getLeft ( ) == 0 ; }
@ Override public Iterator < BackendEntry > query ( Query query ) { InMemoryDBTable table = this . table ( InMemoryDBTable . tableType ( query ) ) ; Iterator < BackendEntry > rs = table . query ( null , query ) ; LOG . debug ( "[store {}] has result({}) for query: {}" , this . store , rs . hasNext ( ) , query ) ; return rs ; }
@ Override public synchronized BackendStore loadSchemaStore ( final String name ) { if ( this . schemaStore == null ) { LOG . info ( "Init raft backend schema store" ) ; BackendStore store = this . provider . loadSchemaStore ( name ) ; this . checkNonSharedStore ( store ) ; this . schemaStore = new RaftBackendStore ( store , this . context ) ; this . context . addStore ( StoreType . SCHEMA , this . schemaStore ) ; } return this . schemaStore ; }
@ Override public void run ( Status status ) { if ( status . isOk ( ) ) { this . complete ( status , ( ) -> null ) ; } else { LOG . error ( "Failed to apply command: {}" , status ) ; String msg = "Failed to apply command in raft node with error: " + status . getErrorMsg ( ) ; this . failure ( status , new BackendException ( msg ) ) ; } }
@ Override public void onLeaderStart ( long term ) { LOG . info ( "The node {} become to leader" , this . context . endpoint ( ) ) ; this . node ( ) . onLeaderInfoChange ( this . context . endpoint ( ) , true ) ; super . onLeaderStart ( term ) ; }
@ Watched ( prefix = "tx" ) @ Override public void rollback ( ) throws BackendException { LOG . debug ( "Transaction rollback()..." ) ; this . reset ( ) ; if ( this . committing2Backend ) { this . committing2Backend = false ; this . store . rollbackTx ( ) ; } }
private HugeVertex parseEntry ( BackendEntry entry ) { try { HugeVertex vertex = this . serializer . readVertex ( graph ( ) , entry ) ; assert vertex != null ; return vertex ; } catch ( ForbiddenException | SecurityException e ) { throw e ; } catch ( Throwable e ) { LOG . error ( "Failed to parse entry: {}" , entry , e ) ; if ( this . ignoreInvalidEntry ) { return null ; } throw e ; } }
public boolean fail ( Throwable e ) { E . checkNotNull ( e , "exception" ) ; if ( ! ( this . cancelled ( ) && HugeException . isInterrupted ( e ) ) ) { LOG . warn ( "An exception occurred when running task: {}" , this . id ( ) , e ) ; if ( this . result ( TaskStatus . FAILED , e . toString ( ) ) ) { return true ; } } return false ; }
private void scheduleOrExecuteJob ( ) { try { for ( TaskScheduler entry : this . schedulers . values ( ) ) { StandardTaskScheduler scheduler = ( StandardTaskScheduler ) entry ; synchronized ( scheduler ) { this . scheduleOrExecuteJobForGraph ( scheduler ) ; } } } catch ( Throwable e ) { LOG . error ( "Exception occurred when schedule job" , e ) ; } }
public void start ( String name ) { this . ending = false ; this . exception = null ; if ( this . executor == null ) { return ; } LOG . info ( "Starting {} workers[{}] with queue size {}..." , this . workers , name , this . queueSize ) ; for ( int i = 0 ; i < this . workers ; i ++ ) { this . executor . submit ( new ContextCallable < > ( this :: runAndDone ) ) ; } }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer stopped" ) ; }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer stopped" ) ; }
public static void main ( String [ ] args ) throws Exception { if ( args . length != 1 ) { String msg = "HugeRestServer can only accept one config files" ; LOG . error ( msg ) ; throw new HugeException ( msg ) ; } try { start ( args [ 0 ] ) ; } catch ( Exception e ) { LOG . error ( "HugeRestServer error:" , e ) ; throw e ; } LOG . info ( "HugeRestServer stopped" ) ; }
public static void showFeatures ( final HugeGraph graph ) { LOG . info ( "SupportsPersistence: {}" , graph . features ( ) . graph ( ) . supportsPersistence ( ) ) ; }
public static void main ( String [ ] args ) throws Exception { LOG . info ( "TaskExample start!" ) ; HugeGraph graph = ExampleUtil . loadGraph ( ) ; testTask ( graph ) ; graph . close ( ) ; HugeFactory . shutdown ( 30L ) ; }
protected void truncateTable ( Session session ) { LOG . debug ( "Truncate table: {}" , this . table ( ) ) ; String sql = this . buildTruncateTemplate ( ) ; try { session . execute ( sql ) ; } catch ( SQLException e ) { throw new BackendException ( "Failed to truncate table with '%s'" , e , sql ) ; } }
@ Override public void close ( ) { LOG . debug ( "Store close: {}" , this . store ) ; this . checkOpened ( ) ; this . closeSessions ( ) ; }
private void markDataError ( String s ) { log . debug ( s ) ; dataErrors . add ( s ) ; }
public void Verify ( ) { List < Document > docs = getAllDocs ( ) ; for ( Document doc : docs ) { try { org . apache . lucene . document . Document ldoc = this . getLuceneDoc ( doc . getUniqueId ( ) ) ; if ( ldoc == null ) { log . warn ( "Some serious error: For document " + doc + " no lucene doc found" ) ; } } catch ( IOException e ) { e . printStackTrace ( ) ; } } }
public String getFromEmailAddress ( ) { if ( from != null && from . length > 0 ) { if ( from . length > 1 ) { log . warn ( "WARNING!: Multiple from addresses in message (" + from . length + "): " + Util . join ( from , ", " ) + " Message: " + this ) ; for ( Address f : from ) log . warn ( f ) ; } if ( from [ 0 ] instanceof InternetAddress ) return ( ( InternetAddress ) from [ 0 ] ) . getAddress ( ) . toLowerCase ( ) ; else return "<NOT INTERNET ADDRESS>" ; } return "<NO FROM EMAIL ADDRESS!?>" ; }
static private Directory createDirectory ( String baseDir , String name ) throws IOException { File f = new File ( baseDir ) ; f . mkdir ( ) ; String index_dir = baseDir + File . separator + INDEX_BASE_DIR_NAME ; f = new File ( index_dir ) ; boolean b = f . mkdir ( ) ; if ( ! f . exists ( ) || ! f . isDirectory ( ) ) { log . warn ( "Unable to create directory: " + index_dir ) ; return null ; } return FSDirectory . open ( new File ( index_dir + File . separator + name ) . toPath ( ) ) ; }
void setupForWrite ( ) throws IOException { log . info ( "setting up index for write access" ) ; setupDirectory ( ) ; if ( iwriter == null ) iwriter = openIndexWriter ( directory ) ; if ( iwriter_blob == null ) iwriter_blob = openIndexWriter ( directory_blob ) ; dirNameToDocIdMap = new LinkedHashMap < > ( ) ; }
public static Set < String > getTopAdjectives ( ) { if ( adjectives == null ) { adjectives = getCanonicalizedEntriesInFile ( adjFile ) ; log . info ( "Read " + adjectives . size ( ) + " entries from " + adjFile ) ; return adjectives ; } return adjectives ; }
public static Span [ ] tokenizeSentenceAsSpan ( String text ) { try { return sentenceDetector . sentPosDetect ( text ) ; } catch ( IllegalArgumentException e ) { log . warn ( "Cannot tokenize: " + text ) ; e . printStackTrace ( ) ; return null ; } }
public static Archive getArchive ( Multimap < String , String > params ) { String archiveID = JSPHelper . getParam ( params , "archiveID" ) ; if ( archiveID == null ) { log . debug ( "No archive ID parameter passed from the client" ) ; return null ; } return ArchiveReaderWriter . getArchiveForArchiveID ( archiveID ) ; }
public Annotation [ ] getAnnotations ( ) { if ( model != null && this . refreshOnGet ) { try { Annotation [ ] refresh = findAnnotationPropertyValues ( SpdxRdfConstants . SPDX_NAMESPACE , SpdxRdfConstants . PROP_ANNOTATION ) ; if ( refresh == null || ! arraysEquivalent ( refresh , this . annotations , true ) ) { this . annotations = refresh ; } } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Invalid annotations in the model" , e ) ; } } return annotations ; }
public Relationship [ ] getRelationships ( ) { if ( model != null && this . refreshOnGet ) { try { Relationship [ ] refresh = findRelationshipPropertyValues ( SpdxRdfConstants . SPDX_NAMESPACE , SpdxRdfConstants . PROP_RELATIONSHIP ) ; if ( refresh != null && ! arraysEquivalent ( refresh , this . relationships , true ) ) { this . relationships = refresh ; } } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Invalid relationships in the model" , e ) ; } } return relationships ; }
@ Override public ReferenceType clone ( ) { try { return new ReferenceType ( this . referenceTypeUri , this . contextualExample , this . documentation , this . externalReferenceSite ) ; } catch ( InvalidSPDXAnalysisException e ) { logger . error ( "Error cloning reference type" , e ) ; throw new AssertionError ( "Clone should never cause an Invalid SPDX Exception" , e ) ; } }
@ Override public void sessionNegotiationCompleted ( boolean success , String msg ) { logger . info ( "*********** Got callback from ZRTP: " + success + ", " + msg ) ; if ( success ) { if ( sender != null ) { sender . setZRTP ( null ) ; } if ( receiver != null ) { receiver . setZRTP ( null ) ; } String sas = zrtp . getSasString ( ) ; callSecured ( sas ) ; } else { logger . info ( "*** ZRTP failure - call proceeding un-encrypted ***" ) ; } }
@ Override public void sessionNegotiationCompleted ( boolean success , String msg ) { logger . info ( "*********** Got callback from ZRTP: " + success + ", " + msg ) ; if ( success ) { if ( sender != null ) { sender . setZRTP ( null ) ; } if ( receiver != null ) { receiver . setZRTP ( null ) ; } String sas = zrtp . getSasString ( ) ; callSecured ( sas ) ; } else { logger . info ( "*** ZRTP failure - call proceeding un-encrypted ***" ) ; } }
@ Override public void processDeliverSm ( DeliverSm deliverSm ) throws ProcessRequestException { try { fireAcceptDeliverSm ( deliverSm ) ; } catch ( ProcessRequestException e ) { throw e ; } catch ( Exception e ) { String msg = "Invalid runtime exception thrown when processing deliver_sm" ; logger . error ( msg , e ) ; throw new ProcessRequestException ( msg , SMPPConstant . STAT_ESME_RX_T_APPN ) ; } }
@ Override public void sendDataSmResp ( DataSmResult dataSmResult , int sequenceNumber ) throws IOException { try { pduSender ( ) . sendDataSmResp ( out , sequenceNumber , dataSmResult . getMessageId ( ) , dataSmResult . getOptionalParameters ( ) ) ; } catch ( PDUStringException e ) { logger . error ( "Failed sending data_sm_resp" , e ) ; } }
private void fireAcceptCancelSm ( CancelSm cancelSm ) throws ProcessRequestException { if ( messageReceiverListener != null ) { messageReceiverListener . onAcceptCancelSm ( cancelSm , this ) ; } else { logger . warn ( MESSAGE_RECEIVER_LISTENER_IS_NULL , "cancel_sm" ) ; throw new ProcessRequestException ( NO_MESSAGE_RECEIVER_LISTENER_REGISTERED , SMPPConstant . STAT_ESME_RX_R_APPN ) ; } }
private QueryBroadcastSmResult fireAcceptQueryBroadcastSm ( QueryBroadcastSm queryBroadcastSm ) throws ProcessRequestException { if ( messageReceiverListener != null ) { return messageReceiverListener . onAcceptQueryBroadcastSm ( queryBroadcastSm , this ) ; } logger . warn ( MESSAGE_RECEIVER_LISTENER_IS_NULL , "query_broadcast_sm" ) ; throw new ProcessRequestException ( NO_MESSAGE_RECEIVER_LISTENER_REGISTERED , SMPPConstant . STAT_ESME_RX_R_APPN ) ; }
@ Override public void sendBindResp ( String systemId , InterfaceVersion interfaceVersion , BindType bindType , int sequenceNumber ) throws IOException { sessionContext . bound ( bindType ) ; try { pduSender ( ) . sendBindResp ( out , bindType . responseCommandId ( ) , sequenceNumber , systemId , interfaceVersion ) ; } catch ( PDUStringException e ) { logger . error ( "Failed sending bind response" , e ) ; } }
@ Override public void processReplaceSm ( ReplaceSm replaceSm ) throws ProcessRequestException { try { fireAcceptReplaceSm ( replaceSm ) ; } catch ( Exception e ) { String msg = "Invalid runtime exception thrown when processing replace_sm" ; logger . error ( msg , e ) ; throw new ProcessRequestException ( msg , SMPPConstant . STAT_ESME_RSYSERR ) ; } }
private void notifyNoActivity ( ) { logger . debug ( "No activity notified, sending enquire_link" ) ; enquireLinkSender . enquireLink ( ) ; }
@ Override public void run ( ) { logger . info ( "Starting PDUReaderWorker" ) ; while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . debug ( "{} stopped" , this . getName ( ) ) ; }
@ Override public void run ( ) { logger . info ( "Starting PDUReaderWorker" ) ; while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . debug ( "{} stopped" , this . getName ( ) ) ; }
@ Override public void run ( ) { logger . info ( "Starting PDUReaderWorker" ) ; while ( isReadPdu ( ) ) { readPDU ( ) ; } close ( ) ; pduExecutor . shutdown ( ) ; try { pduExecutor . awaitTermination ( getTransactionTimer ( ) , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { logger . warn ( "Interrupted while waiting for PDU executor pool to finish" ) ; Thread . currentThread ( ) . interrupt ( ) ; } logger . debug ( "{} stopped" , this . getName ( ) ) ; }
public void processUnbindResp ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { PendingResponse < Command > pendingResp = responseHandler . removeSentItem ( pduHeader . getSequenceNumber ( ) ) ; if ( pendingResp != null ) { UnbindResp resp = pduDecomposer . unbindResp ( pdu ) ; pendingResp . done ( resp ) ; } else { logger . error ( "No request found for {}" , pduHeader ) ; } }
@ Override public void processDeliverSm ( Command pduHeader , byte [ ] pdu , OutboundServerResponseHandler responseHandler ) throws IOException { logger . info ( "Received deliver_sm in OUTBOUND state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override public void processEnquireLinkResp ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { PendingResponse < Command > pendingResp = responseHandler . removeSentItem ( pduHeader . getSequenceNumber ( ) ) ; if ( pendingResp != null ) { EnquireLinkResp resp = pduDecomposer . enquireLinkResp ( pdu ) ; pendingResp . done ( resp ) ; } else { logger . error ( "No request found for {}" , pduHeader ) ; } }
@ Override public void processUnbind ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { logger . info ( "Received unbind in OUTBOUND state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override public void processUnbind ( Command pduHeader , byte [ ] pdu , BaseResponseHandler responseHandler ) throws IOException { logger . info ( "Received unbind in OPEN state, send negative response" ) ; responseHandler . sendNegativeResponse ( pduHeader . getCommandId ( ) , SMPPConstant . STAT_ESME_RINVBNDSTS , pduHeader . getSequenceNumber ( ) ) ; }
@ Override protected void doGet ( final HttpServletRequest request , final HttpServletResponse response ) throws IOException { try { handlePonyResource ( request , response ) ; } catch ( final IOException e ) { log . error ( "Cannot stream request" , e ) ; } }
public static void main ( String [ ] args ) { try { mainHelper ( args ) ; } catch ( ArgumentParserException exception ) { exception . getParser ( ) . handleError ( exception ) ; System . exit ( 1 ) ; } catch ( Throwable exception ) { LOGGER . error ( "" , exception ) ; System . exit ( 1 ) ; } }
@ Override public void close ( ) throws IOException { inputStream . close ( ) ; LOGGER . debug ( "<close> close invoked on ObjectInputStreamFilter" ) ; }
private void logAndPropagateException ( IOException e ) { LOGGER . error ( e . getMessage ( ) , e ) ; throw new UncheckedIOException ( e ) ; }
public int deleteCoexpressionsProfile ( String experimentAccession ) { LOGGER . info ( "deleteCoexpressions for experiment {}" , experimentAccession ) ; return jdbcTemplate . update ( "DELETE FROM RNASEQ_BSLN_CE_PROFILES WHERE EXPERIMENT=?" , experimentAccession ) ; }
@ Override public void onTestFailure ( ITestResult result ) { LOGGER . debug ( "CarinaListener->onTestFailure" ) ; String errorMessage = getFailureReason ( result ) ; takeScreenshot ( result , "TEST FAILED - " + errorMessage ) ; onTestFinish ( result ) ; super . onTestFailure ( result ) ; }
@ Override public void onTestSkipped ( ITestResult result ) { LOGGER . debug ( "CarinaListener->onTestSkipped" ) ; onTestFinish ( result ) ; super . onTestSkipped ( result ) ; }
@ Test @ QTestCases ( id = TEST_ID ) @ QTestCases ( id = FIRST_TEST_ID ) public void testQTestMix ( ) { ITestResult result = Reporter . getCurrentTestResult ( ) ; Set < String > QTestUdids = getQTestCasesUuid ( result ) ; Assert . assertTrue ( QTestUdids . contains ( VERIFICATION_PREFIX + FIRST_TEST_ID ) , "QTest should contain id=" + FIRST_TEST_ID ) ; LOGGER . info ( "QTest list: " + QTestUdids . toString ( ) ) ; Assert . assertEquals ( QTestUdids . size ( ) , 4 ) ; }
public static String getSeleniumUrl ( ) { String value = Configuration . get ( Parameter . SELENIUM_URL ) ; if ( value . isEmpty ( ) ) { String deprecatedValue = Configuration . get ( Parameter . SELENIUM_HOST ) ; if ( ! deprecatedValue . isEmpty ( ) ) { LOGGER . warn ( Parameter . SELENIUM_HOST . getKey ( ) + " configuration parameter is deprecated. " + "Please, start using " + Parameter . SELENIUM_URL + " instead!" ) ; value = deprecatedValue ; } } return value ; }
public String marshall ( Object jaxbElement ) { try { final StringWriter w = new StringWriter ( ) ; getMarshaller ( jaxbElement . getClass ( ) ) . marshal ( jaxbElement , w ) ; return w . toString ( ) ; } catch ( JAXBException e ) { LOGGER . error ( e . getMessage ( ) , e ) ; throw new RuntimeException ( e ) ; } }
public static void setInputSetName ( Configuration conf , String setname ) { log . info ( "setting " + INPUT_SETNAME + " to " + setname ) ; conf . set ( INPUT_SETNAME , setname ) ; }
public static void setOutputNamespace ( Configuration conf , String namespace ) { log . info ( "setting " + OUTPUT_NAMESPACE + " to " + namespace ) ; conf . set ( OUTPUT_NAMESPACE , namespace ) ; }
@ AfterSuite public static void cleanup ( ) { try { aerospike . close ( ) ; } catch ( Exception e ) { LOG . error ( "Error while closing Aerospike client connection" , e ) ; } }
static Pair < Session , String > trySessionForLocation ( String location , CassandraDeepJobConfig conf , Boolean balanced ) { try { return getSession ( location , conf , balanced ) ; } catch ( Exception e ) { LOG . warn ( "Could not connect to {}, possible loss of data-locality. Delegating connection to java driver" , location , conf . getHost ( ) ) ; return getSession ( conf . getHost ( ) , conf , true ) ; } }
@ Override public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) { LOG . error ( cause . getMessage ( ) ) ; ctx . close ( ) ; }
private void openLocalDiscoveryClient ( ) { logger . info ( "Using ElasticSearch AutoDiscovery mode" ) ; Node node = NodeBuilder . nodeBuilder ( ) . client ( true ) . local ( true ) . node ( ) ; if ( client != null ) { client . close ( ) ; } client = node . client ( ) ; }
public void onNotice ( String target , IRCUser user , String msg ) { logger . debug ( "User {}  noticed {} to {}." , user . getNick ( ) , msg , target ) ; headers . put ( IRCConstants . HEADER_TYPE , "notice" ) ; headers . putAll ( getUser ( user ) ) ; headers . put ( IRCConstants . HEADER_TARGET , target ) ; send ( msg , headers ) ; }
@ Override public void onPSubscribe ( String pattern , int subscribedChannels ) { log . info ( "onPSubscribe (Pattern: " + pattern + ")" ) ; }
@ Override public void scenario ( Scenario scenario ) { logger . info ( "Got to scenario {} " , scenario . getName ( ) ) ; this . scenario = scenario ; }
@ Bean public SaveToCassandraOperationsService saveToCassandraOperationsService ( ) { log . debug ( "Creating Spring Bean for SaveToCassandraOperationsService" ) ; return new SaveToCassandraOperationsService ( cassandraSession ( ) ) ; }
@ Bean @ Lazy public DB mongoDB ( ) { log . debug ( "Creating Spring Bean for mongoDB" ) ; return mongoClient ( ) . getDB ( STREAMING . STREAMING_KEYSPACE_NAME ) ; }
@ Override public void afterBulk ( long executionId , BulkRequest request , BulkResponse response ) { log . debug ( "Executed elastic search bulk composed of {} actions" , request . numberOfActions ( ) ) ; }
@ Before public void setUp ( ) throws Exception { LOGGER . debug ( "Initializing required classes" ) ; service = new SolrOperationsService ( HOSTS , HOSTS , DATA_FOLDER . getRoot ( ) . getAbsolutePath ( ) , IS_CLOUD ) ; }
@ Test public void testStreamsExist ( ) throws Exception { LOGGER . debug ( "Checking if Streams has been created properly" ) ; assertNotNull ( sm . getStreamDefinition ( OrdersQueries . STREAM_ORDERS ) ) ; assertNotNull ( sm . getStreamDefinition ( OrdersQueries . STREAM_LINES ) ) ; }
@ Override public void receive ( Event [ ] events ) { for ( Event event : events ) { if ( event instanceof InEvent && event . getData ( 6 ) . toString ( ) . equals ( "lines-1" ) ) { count . getAndIncrement ( ) ; LOGGER . debug ( "Found event: " + event . toString ( ) ) ; } } }
@ Around ( value = "print()" ) public void printSnippets ( ProceedingJoinPoint pjp ) throws Throwable { if ( ! undefinedSteps . isEmpty ( ) ) { logger . error ( "The following steps are undefined:" ) ; for ( String undefinedStep : undefinedSteps ) { logger . error ( "    {}" , undefinedStep ) ; } } }
@ Around ( value = "print()" ) public void printSnippets ( ProceedingJoinPoint pjp ) throws Throwable { if ( ! undefinedSteps . isEmpty ( ) ) { logger . error ( "The following steps are undefined:" ) ; for ( String undefinedStep : undefinedSteps ) { logger . error ( "    {}" , undefinedStep ) ; } } }
@ Given ( "^I get current date and time and save the value in environment variable '(.+?)'$" ) public void getCurrentDateTime ( String envVar ) { DateFormat dateFormat = new SimpleDateFormat ( "yyyy/MM/dd HH:mm:ss" ) ; Date date = new Date ( ) ; dateFormat . setTimeZone ( TimeZone . getTimeZone ( "Europe/Madrid" ) ) ; ThreadProperty . set ( envVar , dateFormat . format ( date ) ) ; commonspec . getLogger ( ) . debug ( "Current Date: {}" , dateFormat . format ( date ) ) ; }
@ Then ( "^the service response must contain the text '(.*?)'$" ) public void assertResponseMessage ( String expectedText ) throws SecurityException , IllegalArgumentException { Pattern pattern = CommonG . matchesOrContains ( expectedText ) ; try { assertThat ( commonspec . getResponse ( ) . getResponse ( ) ) . containsPattern ( pattern ) ; } catch ( AssertionError e ) { commonspec . getLogger ( ) . warn ( "Response: {}" , commonspec . getResponse ( ) . getResponse ( ) ) ; throw e ; } }
@ AfterSuite ( alwaysRun = true ) public void afterGSuite ( ITestContext context ) { logger . info ( "Done executing this test-run." ) ; }
public void createKeyspace ( String keyspace ) { Map < String , String > replicationSimpleOneExtra = new HashMap < > ( ) ; replicationSimpleOneExtra . put ( "'class'" , "'SimpleStrategy'" ) ; replicationSimpleOneExtra . put ( "'replication_factor'" , "1" ) ; String query = this . cassandraqueryUtils . createKeyspaceQuery ( true , keyspace , this . cassandraqueryUtils . createKeyspaceReplication ( replicationSimpleOneExtra ) , "" ) ; LOGGER . debug ( query ) ; executeQuery ( query ) ; }
public void createTableWithData ( String table , Map < String , String > colums , ArrayList < String > pk ) { String query = this . cassandraqueryUtils . createTable ( table , colums , pk ) ; LOGGER . debug ( query ) ; executeQuery ( query ) ; }
public void getPKCS8Certificate ( String certPath , String certValue ) throws Exception { this . getFullCertificate ( certPath , certValue ) ; String key = baseOutputSecretPath + certValue + ".key" ; String commandConvertToPK8 = "openssl pkcs8 -topk8 -inform PEM -outform DER -in " + key + " -out " + baseOutputSecretPath + certValue + ".pk8 -nocrypt" ; logger . debug ( "Converting certificate to PK8: " + commandConvertToPK8 ) ; comm . runLocalCommand ( commandConvertToPK8 ) ; }
public void reportArchitecture ( File file ) { try { ServiceProvider . getInstance ( ) . getDefineService ( ) . reportArchitecture ( file . getAbsolutePath ( ) ) ; } catch ( Exception e ) { if ( ServiceProvider . getInstance ( ) . getControlService ( ) . isGuiEnabled ( ) ) { ServiceProvider . getInstance ( ) . getControlService ( ) . showErrorMessage ( "Unable to create report: " + e . getMessage ( ) ) ; } else { logger . error ( "Unable to create report: " + e . getMessage ( ) ) ; } } }
public void addSUDefinition ( SoftwareUnitDefinition unit ) { if ( ! mappedSUunits . contains ( unit ) && ! this . hasSoftwareUnitDirectly ( unit . getName ( ) ) ) { mappedSUunits . add ( unit ) ; } else { logger . info ( "This software unit has already been added!" ) ; } }
public void initGui ( boolean isUsedAsException ) { try { removeAll ( ) ; setLayout ( createRuleDetailsLayout ( ) ) ; setBorder ( BorderFactory . createEmptyBorder ( 0 , 0 , 0 , 0 ) ) ; setIsUsedAsException ( isUsedAsException ) ; initDetails ( ) ; initViolationTypes ( ) ; } catch ( Exception e ) { logger . error ( e . getMessage ( ) ) ; } }
public void moveLayerDown ( long layerId ) { try { if ( layerId != - 1 ) { moduleService . moveLayerDown ( layerId ) ; this . notifyObservers ( ) ; } } catch ( Exception e ) { logger . error ( "moveLayerDown() - exception: " + e . getMessage ( ) ) ; UiDialogs . errorDialog ( getDefinitionPanel ( ) , e . getMessage ( ) ) ; } }
@ Override public void update ( Observable o , Object arg ) { logger . info ( "update(" + o + ", " + arg + ")" ) ; long moduleId = getSelectedModuleId ( ) ; notifyObservers ( moduleId ) ; }
@ Override public void done ( ) { try { drawingView = get ( ) ; graphicsFrame . attachDrawingViewAndShowDrawing ( drawingView ) ; } catch ( InterruptedException ignore ) { } catch ( java . util . concurrent . ExecutionException e ) { logger . error ( " Exception: " + e . getMessage ( ) ) ; } }
@ Override public void loadWorkspaceData ( Element workspaceData ) { try { task . importValidationWorkspace ( workspaceData ) ; } catch ( DatatypeConfigurationException e ) { logger . error ( "Error exporting the workspace: " + e . getMessage ( ) , e ) ; } notifyServiceListeners ( ) ; }
private void setViolationTypeFactory ( String language ) { this . violationtypefactory = new ViolationTypeFactory ( ) . getViolationTypeFactory ( language , configuration ) ; if ( violationtypefactory == null ) { logger . debug ( "Warning language does not exists: " + language ) ; } }
@ AfterClass public static void tearDown ( ) { workspaceController . closeWorkspace ( ) ; logger . info ( String . format ( "Finished: Define SarServices Test" ) ) ; }
private void notifyUserDataRelayReceived ( UserDataRelayMessage relayMessage ) { logger . info ( connectionInterface . toString ( ) + "User Data Relay received from {} >> {}." , relayMessage . getSourceInterface ( ) . getDescription ( ) , relayMessage . getData ( ) != null ? HexUtils . prettyHexString ( relayMessage . getData ( ) ) : "" ) ; notifyUserDataRelayReceived ( relayMessage , true ) ; notifyUserDataRelayReceived ( relayMessage , false ) ; }
public void purge ( ) { if ( getInputStream ( ) != null ) { try { byte [ ] availableBytes = new byte [ getInputStream ( ) . available ( ) ] ; if ( getInputStream ( ) . available ( ) > 0 ) getInputStream ( ) . read ( availableBytes , 0 , getInputStream ( ) . available ( ) ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } } }
@ Override public byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; try { os . write ( srpStep . getID ( ) ) ; os . write ( data ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return os . toByteArray ( ) ; }
@ Override protected byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream data = new ByteArrayOutputStream ( ) ; try { data . write ( sourceAddress64 . getValue ( ) ) ; data . write ( sourceAddress16 . getValue ( ) ) ; data . write ( ByteUtils . stringToByteArray ( command ) ) ; data . write ( status . getId ( ) ) ; if ( commandValue != null ) data . write ( commandValue ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return data . toByteArray ( ) ; }
@ Override protected byte [ ] getAPIPacketSpecificData ( ) { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; try { os . write ( requestID ) ; os . write ( 0x00 ) ; if ( responseData != null ) os . write ( responseData ) ; } catch ( IOException e ) { logger . error ( e . getMessage ( ) , e ) ; } return os . toByteArray ( ) ; }
public void shutdown ( ) { log . info ( "************ TEST CLIENT JAVA APP EXITING" ) ; server . stop ( ) ; System . exit ( 0 ) ; }
public String testOp ( String p1 , int p2 ) { log . info ( "testOp called with: " + p1 + " " + p2 ) ; return innerService . join ( p1 , p2 ) ; }
@ Override public void beforeRuleFlowGroupDeactivated ( RuleFlowGroupDeactivatedEvent event ) { log . debug ( event ) ; }
public void init ( ) { backend = IspnCacheManager . getCacheManager ( ) . getCache ( "backend" ) ; if ( backend == null ) { log . error ( "Ispn backend cache not found. Check configuration." ) ; throw new RuntimeException ( "backend cache not found" ) ; } queryFactory = Search . getQueryFactory ( backend ) ; }
public static void print ( String s ) { logger . debug ( s ) ; }
public void run ( ) { int retryCounter = 0 ; while ( retryCounter < jobMaxRetries ) { try { this . install ( ) ; System . exit ( 0 ) ; } catch ( InterruptedException e ) { logger . warn ( "Aborting installation" ) ; System . exit ( 1 ) ; } catch ( Exception e ) { retryCounter ++ ; logger . error ( "Schema installer failed on retry " + retryCounter + " of " + jobMaxRetries + ", retry again." ) ; if ( retryCounter >= jobMaxRetries ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } } } }
public void run ( ) { int retryCounter = 0 ; while ( retryCounter < jobMaxRetries ) { try { this . install ( ) ; System . exit ( 0 ) ; } catch ( InterruptedException e ) { logger . warn ( "Aborting installation" ) ; System . exit ( 1 ) ; } catch ( Exception e ) { retryCounter ++ ; logger . error ( "Schema installer failed on retry " + retryCounter + " of " + jobMaxRetries + ", retry again." ) ; if ( retryCounter >= jobMaxRetries ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } } } }
private void logVersion ( ) { logger . info ( "Hawkular Metrics Schema Installer v{}" , VersionUtil . getVersion ( ) ) ; }
private void deleteRecording ( ColumbusCcsdsPacket commandPacket ) { transmitRealtimeTM ( ackPacket ( commandPacket , 1 , 0 ) ) ; byte [ ] fileNameArray = commandPacket . getUserDataBuffer ( ) . array ( ) ; String fileName = new String ( fileNameArray , 16 , fileNameArray . length - 22 ) ; log . info ( "Command DELETE_RECORDING for file {}" , fileName ) ; deleteLosDataFile ( fileName ) ; transmitRealtimeTM ( ackPacket ( commandPacket , 2 , 0 ) ) ; }
private void criticalTc1 ( ColumbusCcsdsPacket commandPacket ) { transmitRealtimeTM ( ackPacket ( commandPacket , 1 , 0 ) ) ; log . info ( "Command CRITICAL_TC1" ) ; transmitRealtimeTM ( ackPacket ( commandPacket , 2 , 0 ) ) ; }
public void sendImmediate ( SimulatorCcsdsPacket packet ) { if ( connected ) { try { socket . getOutputStream ( ) . write ( packet . getBytes ( ) ) ; } catch ( IOException e1 ) { log . error ( "Error while sending {} packet" , name , e1 ) ; connect ( ) ; } } }
private void saveFile ( ) { try { File f = new File ( dataDir , sanitize ( metadata . getDestinationFilename ( ) ) ) ; try ( FileOutputStream fw = new FileOutputStream ( f ) ) { fw . write ( cfdpDataFile . getData ( ) ) ; log . info ( "CFDP file saved in {}" , f . getAbsolutePath ( ) ) ; } } catch ( IOException e ) { e . printStackTrace ( ) ; } }
private void switchBatteryOff ( PusTcPacket commandPacket ) { transmitRealtimeTM ( ack ( commandPacket , 3 ) ) ; int batNum = commandPacket . getUserDataBuffer ( ) . get ( 0 ) ; log . info ( "CMD: BATERRY OFF {}" , batNum ) ; executor . schedule ( ( ) -> { powerDataHandler . setBatteryOff ( batNum ) ; transmitRealtimeTM ( ack ( commandPacket , 7 ) ) ; } , 500 , TimeUnit . MILLISECONDS ) ; }
public synchronized void connect ( ConnectedClient s ) throws ProcessorException { log . debug ( "Processor {} has one more user: {}" , name , s ) ; if ( quitting ) { throw new ProcessorException ( "This processor has been closed" ) ; } connectedClients . add ( s ) ; }
protected void onInactivityTimerExpiration ( ) { log . warn ( "TXID{} inactivity timer expired, state: {}" , cfdpTransactionId , inTxState ) ; switch ( inTxState ) { case RECEIVING_DATA : handleFault ( ConditionCode . INACTIVITY_DETECTED ) ; break ; case FIN : case COMPLETED : log . error ( "TXID{} Illegal state" , cfdpTransactionId ) ; break ; } }
protected void onInactivityTimerExpiration ( ) { log . warn ( "TXID{} inactivity timer expired, state: {}" , cfdpTransactionId , inTxState ) ; switch ( inTxState ) { case RECEIVING_DATA : handleFault ( ConditionCode . INACTIVITY_DETECTED ) ; break ; case FIN : case COMPLETED : log . error ( "TXID{} Illegal state" , cfdpTransactionId ) ; break ; } }
@ Override protected void cancel ( ConditionCode code ) { if ( inTxState == InTxState . RECEIVING_DATA ) { if ( needsFinish ) { finish ( code ) ; } else { complete ( code ) ; } } else { log . debug ( "TXID{} ignoring cancel, wrong state" , cfdpTransactionId ) ; } }
@ Override public TransferDirection getDirection ( ) { String str = tuple . getColumn ( COL_DIRECTION ) ; try { return TransferDirection . valueOf ( str ) ; } catch ( IllegalArgumentException e ) { log . warn ( "Unknown transfer direction {} retrieved from archive" , str ) ; } return null ; }
public void unregisterClient ( int id ) { ConnectedClient client = clients . remove ( id ) ; if ( client == null ) { return ; } Processor processor = client . getProcessor ( ) ; if ( processor != null ) { processor . disconnect ( client ) ; } try { managementListeners . forEach ( l -> l . clientUnregistered ( client ) ) ; } catch ( Exception e ) { log . warn ( "Got exception when unregistering a client" , e ) ; } }
@ Override public void startProvidingAll ( ) { log . debug ( "requested to provide all" ) ; executor . submit ( ( ) -> { for ( Parameter p : params ) { subscribedParams . add ( p ) ; } } ) ; }
private void sendToExecutor ( int idx ) { executor . submit ( ( ) -> { try { PGSegment seg = segments [ idx ] ; long t0 = System . nanoTime ( ) ; parameterArchive . writeToArchive ( seg ) ; long d = System . nanoTime ( ) - t0 ; log . debug ( "Wrote segment {} to archive in {} millisec" , seg , d / 1000_000 ) ; } catch ( RocksDBException | IOException e ) { log . error ( "Error writing segment to the parameter archive" , e ) ; } segments [ idx ] = null ; } ) ; }
private void sendToExecutor ( int idx ) { executor . submit ( ( ) -> { try { PGSegment seg = segments [ idx ] ; long t0 = System . nanoTime ( ) ; parameterArchive . writeToArchive ( seg ) ; long d = System . nanoTime ( ) - t0 ; log . debug ( "Wrote segment {} to archive in {} millisec" , seg , d / 1000_000 ) ; } catch ( RocksDBException | IOException e ) { log . error ( "Error writing segment to the parameter archive" , e ) ; } segments [ idx ] = null ; } ) ; }
private int abortWriteFileFull ( int txStartPos ) { fileFull = true ; buf . position ( txStartPos ) ; doForceWrite ( ) ; log . debug ( "File {} full, numTx: {}" , path , hdr2 . numTx ( ) ) ; return - 1 ; }
private LinearAdjusment readLinearAdjusment ( ) throws XMLStreamException { log . trace ( XTCE_LINEAR_ADJUSTMENT ) ; StartElement startElement = checkStartElementPreconditions ( ) ; double intercept = readDoubleAttribute ( "intercept" , startElement , 0.0 ) ; double slope = readDoubleAttribute ( "slope" , startElement , 1.0 ) ; return new LinearAdjusment ( intercept , slope ) ; }
private void readArgumentList ( SpaceSystem spaceSystem , MetaCommand mc ) throws XMLStreamException { log . trace ( XTCE_ARGUMENT_LIST ) ; checkStartElementPreconditions ( ) ; while ( true ) { xmlEvent = xmlEventReader . nextEvent ( ) ; if ( isStartElementWithName ( XTCE_ARGUMENT ) ) { Argument arg = readArgument ( spaceSystem ) ; mc . addArgument ( arg ) ; } else if ( isEndElementWithName ( XTCE_ARGUMENT_LIST ) ) { return ; } } }
private void addInputArgumentInstanceRef ( SpaceSystem spaceSystem , CustomAlgorithm algo , MetaCommand metaCmd ) throws XMLStreamException { log . trace ( XTCE_INPUT_ARGUMENT_INSTANCE_REF ) ; String inputName = readAttribute ( "inputName" , xmlEvent . asStartElement ( ) , null ) ; ArgumentInstanceRef argRef = readArgumentInstanceRef ( spaceSystem , metaCmd ) ; InputParameter inputParameter = new InputParameter ( argRef , inputName ) ; algo . addInput ( inputParameter ) ; }
protected void manageWatcher ( BundleContext context ) { if ( context != null && ( isDev ( ) || getBooleanWithDefault ( "application.watch-configuration" , false ) ) && watcher != null ) { LOGGER . info ( "Enabling the watching of the configuration file" ) ; watcher . add ( configFile . getParentFile ( ) , true ) ; registration = context . registerService ( Deployer . class , new ConfigurationDeployer ( ) , null ) ; } }
@ Override public void unregister ( Module module ) { if ( module == null ) { return ; } LOGGER . info ( "Removing Jackson module {}" , module . getModuleName ( ) ) ; synchronized ( lock ) { if ( modules . remove ( module ) ) { rebuildMappers ( ) ; } } }
public static Object create ( ActionParameter argument , Context context , ParameterFactories engine ) { RouteParameterHandler handler = BINDINGS . get ( argument . getSource ( ) ) ; if ( handler != null ) { return handler . create ( argument , context , engine ) ; } else { LoggerFactory . getLogger ( Bindings . class ) . warn ( "Unsupported route parameter in method : {}" , argument . getSource ( ) . name ( ) ) ; return null ; } }
@ Override public long length ( ) { if ( rendered == null ) { try { _render ( ) ; } catch ( RenderableException e ) { LoggerFactory . getLogger ( RenderableJsonP . class ) . warn ( "Cannot render JSON object {}" , node , e ) ; return - 1 ; } } return rendered . length ; }
public static void configureRegistry ( NodeManager node , Log log , String npmRegistryUrl ) { try { node . factory ( ) . getNpmRunner ( node . proxy ( ) ) . execute ( "config set registry " + npmRegistryUrl ) ; } catch ( TaskRunnerException e ) { log . error ( "Error during the configuration of NPM registry with the url " + npmRegistryUrl + " - check log" , e ) ; } }
@ Override public Result call ( Route route , RequestContext context ) throws Exception { final long begin = System . currentTimeMillis ( ) ; try { return context . proceed ( ) ; } finally { final long end = System . currentTimeMillis ( ) ; LOGGER . info ( "Time spent to reply to {} {} : {} ms" , route . getHttpMethod ( ) , context . context ( ) . path ( ) , ( end - begin ) ) ; } }
@ Override public Result call ( Logged configuration , RequestContext context ) throws Exception { logger . info ( "Invoking " + context . context ( ) . request ( ) . method ( ) + " " + context . context ( ) . request ( ) . uri ( ) ) ; long begin = System . currentTimeMillis ( ) ; Result r = context . proceed ( ) ; long end = System . currentTimeMillis ( ) ; if ( configuration . duration ( ) ) { logger . info ( "Result computed in " + ( end - begin ) + " ms" ) ; } return r ; }
@ Override public Result call ( Logged configuration , RequestContext context ) throws Exception { logger . info ( "Invoking " + context . context ( ) . request ( ) . method ( ) + " " + context . context ( ) . request ( ) . uri ( ) ) ; long begin = System . currentTimeMillis ( ) ; Result r = context . proceed ( ) ; long end = System . currentTimeMillis ( ) ; if ( configuration . duration ( ) ) { logger . info ( "Result computed in " + ( end - begin ) + " ms" ) ; } return r ; }
@ Override public Result call ( final Route route , final RequestContext context ) throws Exception { URI redirectedURI = rewriteURI ( context . request ( ) ) ; logger . debug ( "Redirecting request - rewriting {} to {}" , context . request ( ) . uri ( ) , redirectedURI ) ; if ( redirectedURI == null ) { return onRewriteFailed ( context ) ; } return Results . redirect ( redirectedURI . toString ( ) ) ; }
public void processTrip ( Trip trip , Iterable < StopTime > orderedStopTimes ) { if ( ++ nTripsProcessed % 100000 == 0 ) { LOG . info ( "trip {}" , human ( nTripsProcessed ) ) ; } TripPatternKey key = new TripPatternKey ( trip . route_id ) ; for ( StopTime st : orderedStopTimes ) { key . addStopTime ( st ) ; } tripsForPattern . put ( key , trip ) ; }
static void createSchema ( Connection connection , String schemaName ) { try { Statement statement = connection . createStatement ( ) ; statement . execute ( "create schema " + schemaName ) ; LOG . info ( "Created new feed schema: {}" , statement ) ; } catch ( Exception ex ) { LOG . error ( "Exception while registering new feed namespace in feeds table: {}" , ex . getMessage ( ) ) ; DbUtils . closeQuietly ( connection ) ; } }
static void createSchema ( Connection connection , String schemaName ) { try { Statement statement = connection . createStatement ( ) ; statement . execute ( "create schema " + schemaName ) ; LOG . info ( "Created new feed schema: {}" , statement ) ; } catch ( Exception ex ) { LOG . error ( "Exception while registering new feed namespace in feeds table: {}" , ex . getMessage ( ) ) ; DbUtils . closeQuietly ( connection ) ; } }
public Field getFieldForName ( String name ) { int index = getFieldIndex ( name ) ; if ( index >= 0 ) return fields [ index ] ; LOG . warn ( "Unrecognized header {}. Treating it as a proprietary string field." , name ) ; return new StringField ( name , UNKNOWN ) ; }
public void complete ( ValidationResult validationResult ) { for ( TripValidator tripValidator : tripValidators ) { LOG . info ( "Running complete stage for {}" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; tripValidator . complete ( validationResult ) ; LOG . info ( "{} finished" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; } }
public void complete ( ValidationResult validationResult ) { for ( TripValidator tripValidator : tripValidators ) { LOG . info ( "Running complete stage for {}" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; tripValidator . complete ( validationResult ) ; LOG . info ( "{} finished" , tripValidator . getClass ( ) . getSimpleName ( ) ) ; } }
public void openOSM ( File file ) { osm = new OSM ( file . getPath ( ) ) ; LOG . info ( "Read OSM" ) ; }
public State getState ( double lat , double lon ) { Split split = streetLayer . findSplit ( lat , lon , StreetLayer . LINK_RADIUS_METERS , streetMode ) ; if ( split == null ) { LOG . info ( "No street was found near the specified origin point of {}, {}." , lat , lon ) ; return null ; } return getState ( split ) ; }
private ResponseEntity < LoadBankAccountsResponse > createLoadBankAccountsResponse ( List < BankAccountEntity > bankAccounts ) { LoadBankAccountsResponse response = new LoadBankAccountsResponse ( ) ; response . setBankAccounts ( bankAccountMapper . toBankAccountTOs ( bankAccounts ) ) ; log . debug ( "process finished < return bank account list" ) ; return new ResponseEntity < > ( response , HttpStatus . OK ) ; }
protected List < AbsoluteLocation < ResolvedResource > > getAllFilesInPrivate ( UserIDAuth owner ) { try ( Stream < AbsoluteLocation < ResolvedResource > > ls = listPrivate . list ( ListRequest . forDefaultPrivate ( owner , "./" ) ) ) { List < AbsoluteLocation < ResolvedResource > > files = ls . collect ( Collectors . toList ( ) ) ; log . info ( "{} has {} in PRIVATE" , owner . getUserID ( ) , files ) ; return files ; } }
@ SneakyThrows private < T > T readProfile ( AbsoluteLocation resource , Class < T > clazz ) { try ( InputStream is = readService . read ( access . withSystemAccess ( resource ) ) ) { log . debug ( "read profile {}" , resource . location ( ) ) ; return serde . fromJson ( new String ( ByteStreams . toByteArray ( is ) ) , clazz ) ; } }
@ Override public Function < Uri , Uri > decryptor ( UserIDAuth forUser ) { AuthPathEncryptionSecretKey pathEncryptionSecretKey = privateKeyService . pathEncryptionSecretKey ( forUser ) ; return encryptedPath -> { Uri decrypt = symmetricPathEncryptionService . decrypt ( pathEncryptionSecretKey , encryptedPath ) ; log . debug ( "decrypted path {} for user {} path {}" , decrypt , forUser . getUserID ( ) , encryptedPath ) ; return decrypt ; } ; }
@ SneakyThrows @ Override public InputStream read ( AbsoluteLocation path ) { log . debug ( "Read file request: {}" , path . location ( ) ) ; Path filePath = resolve ( path . location ( ) . getRawPath ( ) , false ) ; return MoreFiles . asByteSource ( filePath , StandardOpenOption . READ ) . openStream ( ) ; }
private void initiateMultiPartIfNeeded ( ) { if ( multiPartUploadResult == null ) { log . debug ( "Initiate multi part" ) ; multiPartUploadResult = amazonS3 . initiateMultipartUpload ( new InitiateMultipartUploadRequest ( bucketName , objectName ) ) ; } }
private List < PartETag > getMultiPartsUploadResults ( ) throws ExecutionException , InterruptedException { List < PartETag > result = new ArrayList < > ( partCounter ) ; for ( int i = 0 ; i < partCounter ; i ++ ) { UploadPartResult partResult = completionService . take ( ) . get ( ) ; result . add ( partResult . getPartETag ( ) ) ; log . debug ( "Get upload part #{} from {}" , i , partCounter ) ; } return result ; }
private boolean isAisConsentChecksumCorrect ( ConsentEntity entity , ChecksumCalculatingService calculatingService ) { byte [ ] checksumFromDb = entity . getChecksum ( ) ; if ( checksumFromDb != null && wasStatusHoldBefore ( entity ) && ! calculatingService . verifyConsentWithChecksum ( mapToAisConsent ( entity ) , checksumFromDb ) ) { log . warn ( "AIS consent checksum verification failed! AIS consent ID: [{}]. Contact ASPSP for details." , entity . getExternalId ( ) ) ; return false ; } return true ; }
